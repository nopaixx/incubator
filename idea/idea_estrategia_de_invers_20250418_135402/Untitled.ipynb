{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8685a425-a62e-4d04-a592-d417adeee3ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando estrategia de factores adaptativos market-neutral...\n",
      "Cargando datos...\n",
      "Tabla encontrada. Filas: 504\n",
      "Encabezados de tabla: ['Symbol', 'Security', 'GICS Sector', 'GICS Sub-Industry', 'Headquarters Location', 'Date added', 'CIK', 'Founded']\n",
      "Usando columna 0 para tickers y columna 2 para sectores\n",
      "Tickers extra√≠dos: 503\n",
      "Comenzando descarga de datos para 503 tickers en lotes de 100\n",
      "Descargando lote 1 con 100 tickers\n",
      "Lote 1: Datos descargados, shape: (753, 500)\n",
      "Tickers en datos descargados: 100\n",
      "Procesado correctamente: MMM\n",
      "Procesado correctamente: AOS\n",
      "Procesado correctamente: ABT\n",
      "Procesado correctamente: ABBV\n",
      "Procesado correctamente: ACN\n",
      "Procesado correctamente: ADBE\n",
      "Procesado correctamente: AMD\n",
      "Procesado correctamente: AES\n",
      "Procesado correctamente: AFL\n",
      "Procesado correctamente: A\n",
      "Procesado correctamente: APD\n",
      "Procesado correctamente: ABNB\n",
      "Procesado correctamente: AKAM\n",
      "Procesado correctamente: ALB\n",
      "Procesado correctamente: ARE\n",
      "Procesado correctamente: ALGN\n",
      "Procesado correctamente: ALLE\n",
      "Procesado correctamente: LNT\n",
      "Procesado correctamente: ALL\n",
      "Procesado correctamente: GOOGL\n",
      "Procesado correctamente: GOOG\n",
      "Procesado correctamente: MO\n",
      "Procesado correctamente: AMZN\n",
      "Procesado correctamente: AMCR\n",
      "Procesado correctamente: AEE\n",
      "Procesado correctamente: AEP\n",
      "Procesado correctamente: AXP\n",
      "Procesado correctamente: AIG\n",
      "Procesado correctamente: AMT\n",
      "Procesado correctamente: AWK\n",
      "Procesado correctamente: AMP\n",
      "Procesado correctamente: AME\n",
      "Procesado correctamente: AMGN\n",
      "Procesado correctamente: APH\n",
      "Procesado correctamente: ADI\n",
      "Procesado correctamente: ANSS\n",
      "Procesado correctamente: AON\n",
      "Procesado correctamente: APA\n",
      "Procesado correctamente: APO\n",
      "Procesado correctamente: AAPL\n",
      "Procesado correctamente: AMAT\n",
      "Procesado correctamente: APTV\n",
      "Procesado correctamente: ACGL\n",
      "Procesado correctamente: ADM\n",
      "Procesado correctamente: ANET\n",
      "Procesado correctamente: AJG\n",
      "Procesado correctamente: AIZ\n",
      "Procesado correctamente: T\n",
      "Procesado correctamente: ATO\n",
      "Procesado correctamente: ADSK\n",
      "Procesado correctamente: ADP\n",
      "Procesado correctamente: AZO\n",
      "Procesado correctamente: AVB\n",
      "Procesado correctamente: AVY\n",
      "Procesado correctamente: AXON\n",
      "Procesado correctamente: BKR\n",
      "Procesado correctamente: BALL\n",
      "Procesado correctamente: BAC\n",
      "Procesado correctamente: BAX\n",
      "Procesado correctamente: BDX\n",
      "Procesado correctamente: BRK-B\n",
      "Procesado correctamente: BBY\n",
      "Procesado correctamente: TECH\n",
      "Procesado correctamente: BIIB\n",
      "Procesado correctamente: BLK\n",
      "Procesado correctamente: BX\n",
      "Procesado correctamente: BK\n",
      "Procesado correctamente: BA\n",
      "Procesado correctamente: BKNG\n",
      "Procesado correctamente: BSX\n",
      "Procesado correctamente: BMY\n",
      "Procesado correctamente: AVGO\n",
      "Procesado correctamente: BR\n",
      "Procesado correctamente: BRO\n",
      "Procesado correctamente: BF-B\n",
      "Procesado correctamente: BLDR\n",
      "Procesado correctamente: BG\n",
      "Procesado correctamente: BXP\n",
      "Procesado correctamente: CHRW\n",
      "Procesado correctamente: CDNS\n",
      "Procesado correctamente: CZR\n",
      "Procesado correctamente: CPT\n",
      "Procesado correctamente: CPB\n",
      "Procesado correctamente: COF\n",
      "Procesado correctamente: CAH\n",
      "Procesado correctamente: KMX\n",
      "Procesado correctamente: CCL\n",
      "Procesado correctamente: CARR\n",
      "Procesado correctamente: CAT\n",
      "Procesado correctamente: CBOE\n",
      "Procesado correctamente: CBRE\n",
      "Procesado correctamente: CDW\n",
      "Procesado correctamente: COR\n",
      "Procesado correctamente: CNC\n",
      "Procesado correctamente: CNP\n",
      "Procesado correctamente: CF\n",
      "Procesado correctamente: CRL\n",
      "Procesado correctamente: SCHW\n",
      "Procesado correctamente: ^GSPC\n",
      "Procesado correctamente: ^VIX\n",
      "Descargando lote 2 con 100 tickers\n",
      "Lote 2: Datos descargados, shape: (753, 500)\n",
      "Tickers en datos descargados: 100\n",
      "Procesado correctamente: CMG\n",
      "Procesado correctamente: CB\n",
      "Procesado correctamente: CHD\n",
      "Procesado correctamente: CI\n",
      "Procesado correctamente: CINF\n",
      "Procesado correctamente: CTAS\n",
      "Procesado correctamente: CSCO\n",
      "Procesado correctamente: C\n",
      "Procesado correctamente: CFG\n",
      "Procesado correctamente: CLX\n",
      "Procesado correctamente: CME\n",
      "Procesado correctamente: CMS\n",
      "Procesado correctamente: KO\n",
      "Procesado correctamente: CTSH\n",
      "Procesado correctamente: CL\n",
      "Procesado correctamente: CMCSA\n",
      "Procesado correctamente: CAG\n",
      "Procesado correctamente: COP\n",
      "Procesado correctamente: ED\n",
      "Procesado correctamente: STZ\n",
      "Procesado correctamente: CEG\n",
      "Procesado correctamente: COO\n",
      "Procesado correctamente: CPRT\n",
      "Procesado correctamente: GLW\n",
      "Procesado correctamente: CPAY\n",
      "Procesado correctamente: CTVA\n",
      "Procesado correctamente: CSGP\n",
      "Procesado correctamente: COST\n",
      "Procesado correctamente: CTRA\n",
      "Procesado correctamente: CRWD\n",
      "Procesado correctamente: CCI\n",
      "Procesado correctamente: CSX\n",
      "Procesado correctamente: CMI\n",
      "Procesado correctamente: CVS\n",
      "Procesado correctamente: DHR\n",
      "Procesado correctamente: DRI\n",
      "Procesado correctamente: DVA\n",
      "Procesado correctamente: DAY\n",
      "Procesado correctamente: DECK\n",
      "Procesado correctamente: DE\n",
      "Procesado correctamente: DELL\n",
      "Procesado correctamente: DAL\n",
      "Procesado correctamente: DVN\n",
      "Procesado correctamente: DXCM\n",
      "Procesado correctamente: FANG\n",
      "Procesado correctamente: DLR\n",
      "Procesado correctamente: DFS\n",
      "Procesado correctamente: DG\n",
      "Procesado correctamente: DLTR\n",
      "Procesado correctamente: D\n",
      "Procesado correctamente: DPZ\n",
      "Procesado correctamente: DASH\n",
      "Procesado correctamente: DOV\n",
      "Procesado correctamente: DOW\n",
      "Procesado correctamente: DHI\n",
      "Procesado correctamente: DTE\n",
      "Procesado correctamente: DUK\n",
      "Procesado correctamente: DD\n",
      "Procesado correctamente: EMN\n",
      "Procesado correctamente: ETN\n",
      "Procesado correctamente: EBAY\n",
      "Procesado correctamente: ECL\n",
      "Procesado correctamente: EIX\n",
      "Procesado correctamente: EW\n",
      "Procesado correctamente: EA\n",
      "Procesado correctamente: ELV\n",
      "Procesado correctamente: EMR\n",
      "Procesado correctamente: ENPH\n",
      "Procesado correctamente: ETR\n",
      "Procesado correctamente: EOG\n",
      "Procesado correctamente: EPAM\n",
      "Procesado correctamente: EQT\n",
      "Procesado correctamente: EFX\n",
      "Procesado correctamente: EQIX\n",
      "Procesado correctamente: EQR\n",
      "Procesado correctamente: ERIE\n",
      "Procesado correctamente: ESS\n",
      "Procesado correctamente: EL\n",
      "Procesado correctamente: EG\n",
      "Procesado correctamente: EVRG\n",
      "Procesado correctamente: ES\n",
      "Procesado correctamente: EXC\n",
      "Procesado correctamente: EXE\n",
      "Procesado correctamente: EXPE\n",
      "Procesado correctamente: EXPD\n",
      "Procesado correctamente: EXR\n",
      "Procesado correctamente: XOM\n",
      "Procesado correctamente: FFIV\n",
      "Procesado correctamente: FDS\n",
      "Procesado correctamente: FICO\n",
      "Procesado correctamente: FAST\n",
      "Procesado correctamente: FRT\n",
      "Procesado correctamente: FDX\n",
      "Procesado correctamente: FIS\n",
      "Procesado correctamente: FITB\n",
      "Procesado correctamente: FSLR\n",
      "Procesado correctamente: FE\n",
      "Procesado correctamente: FI\n",
      "Procesado correctamente: F\n",
      "Procesado correctamente: FTNT\n",
      "Descargando lote 3 con 100 tickers\n",
      "Lote 3: Datos descargados, shape: (753, 501)\n",
      "Tickers en datos descargados: 100\n",
      "Procesado correctamente: FTV\n",
      "Procesado correctamente: FOXA\n",
      "Procesado correctamente: FOX\n",
      "Procesado correctamente: BEN\n",
      "Procesado correctamente: FCX\n",
      "Procesado correctamente: GRMN\n",
      "Procesado correctamente: IT\n",
      "Procesado correctamente: GE\n",
      "Procesado correctamente: GEHC\n",
      "Procesado correctamente: GEV\n",
      "Procesado correctamente: GEN\n",
      "Procesado correctamente: GNRC\n",
      "Procesado correctamente: GD\n",
      "Procesado correctamente: GIS\n",
      "Procesado correctamente: GM\n",
      "Procesado correctamente: GPC\n",
      "Procesado correctamente: GILD\n",
      "Procesado correctamente: GPN\n",
      "Procesado correctamente: GL\n",
      "Procesado correctamente: GDDY\n",
      "Procesado correctamente: GS\n",
      "Procesado correctamente: HAL\n",
      "Procesado correctamente: HIG\n",
      "Procesado correctamente: HAS\n",
      "Procesado correctamente: HCA\n",
      "Procesado correctamente: DOC\n",
      "Procesado correctamente: HSIC\n",
      "Procesado correctamente: HSY\n",
      "Procesado correctamente: HES\n",
      "Procesado correctamente: HPE\n",
      "Procesado correctamente: HLT\n",
      "Procesado correctamente: HOLX\n",
      "Procesado correctamente: HD\n",
      "Procesado correctamente: HON\n",
      "Procesado correctamente: HRL\n",
      "Procesado correctamente: HST\n",
      "Procesado correctamente: HWM\n",
      "Procesado correctamente: HPQ\n",
      "Procesado correctamente: HUBB\n",
      "Procesado correctamente: HUM\n",
      "Procesado correctamente: HBAN\n",
      "Procesado correctamente: HII\n",
      "Procesado correctamente: IBM\n",
      "Procesado correctamente: IEX\n",
      "Procesado correctamente: IDXX\n",
      "Procesado correctamente: ITW\n",
      "Procesado correctamente: INCY\n",
      "Procesado correctamente: IR\n",
      "Procesado correctamente: PODD\n",
      "Procesado correctamente: INTC\n",
      "Procesado correctamente: ICE\n",
      "Procesado correctamente: IFF\n",
      "Procesado correctamente: IP\n",
      "Procesado correctamente: IPG\n",
      "Procesado correctamente: INTU\n",
      "Procesado correctamente: ISRG\n",
      "Procesado correctamente: IVZ\n",
      "Procesado correctamente: INVH\n",
      "Procesado correctamente: IQV\n",
      "Procesado correctamente: IRM\n",
      "Procesado correctamente: JBHT\n",
      "Procesado correctamente: JBL\n",
      "Procesado correctamente: JKHY\n",
      "Procesado correctamente: J\n",
      "Procesado correctamente: JNJ\n",
      "Procesado correctamente: JCI\n",
      "Procesado correctamente: JPM\n",
      "Procesado correctamente: JNPR\n",
      "Procesado correctamente: K\n",
      "Procesado correctamente: KVUE\n",
      "Procesado correctamente: KDP\n",
      "Procesado correctamente: KEY\n",
      "Procesado correctamente: KEYS\n",
      "Procesado correctamente: KMB\n",
      "Procesado correctamente: KIM\n",
      "Procesado correctamente: KMI\n",
      "Procesado correctamente: KKR\n",
      "Procesado correctamente: KLAC\n",
      "Procesado correctamente: KHC\n",
      "Procesado correctamente: KR\n",
      "Procesado correctamente: LHX\n",
      "Procesado correctamente: LH\n",
      "Procesado correctamente: LRCX\n",
      "Procesado correctamente: LW\n",
      "Procesado correctamente: LVS\n",
      "Procesado correctamente: LDOS\n",
      "Procesado correctamente: LEN\n",
      "Procesado correctamente: LII\n",
      "Procesado correctamente: LLY\n",
      "Procesado correctamente: LIN\n",
      "Procesado correctamente: LYV\n",
      "Procesado correctamente: LKQ\n",
      "Procesado correctamente: LMT\n",
      "Procesado correctamente: L\n",
      "Procesado correctamente: LOW\n",
      "Procesado correctamente: LULU\n",
      "Procesado correctamente: LYB\n",
      "Procesado correctamente: MTB\n",
      "Procesado correctamente: MPC\n",
      "Procesado correctamente: MKTX\n",
      "Descargando lote 4 con 100 tickers\n",
      "Lote 4: Datos descargados, shape: (753, 500)\n",
      "Tickers en datos descargados: 100\n",
      "Procesado correctamente: MAR\n",
      "Procesado correctamente: MMC\n",
      "Procesado correctamente: MLM\n",
      "Procesado correctamente: MAS\n",
      "Procesado correctamente: MA\n",
      "Procesado correctamente: MTCH\n",
      "Procesado correctamente: MKC\n",
      "Procesado correctamente: MCD\n",
      "Procesado correctamente: MCK\n",
      "Procesado correctamente: MDT\n",
      "Procesado correctamente: MRK\n",
      "Procesado correctamente: META\n",
      "Procesado correctamente: MET\n",
      "Procesado correctamente: MTD\n",
      "Procesado correctamente: MGM\n",
      "Procesado correctamente: MCHP\n",
      "Procesado correctamente: MU\n",
      "Procesado correctamente: MSFT\n",
      "Procesado correctamente: MAA\n",
      "Procesado correctamente: MRNA\n",
      "Procesado correctamente: MHK\n",
      "Procesado correctamente: MOH\n",
      "Procesado correctamente: TAP\n",
      "Procesado correctamente: MDLZ\n",
      "Procesado correctamente: MPWR\n",
      "Procesado correctamente: MNST\n",
      "Procesado correctamente: MCO\n",
      "Procesado correctamente: MS\n",
      "Procesado correctamente: MOS\n",
      "Procesado correctamente: MSI\n",
      "Procesado correctamente: MSCI\n",
      "Procesado correctamente: NDAQ\n",
      "Procesado correctamente: NTAP\n",
      "Procesado correctamente: NFLX\n",
      "Procesado correctamente: NEM\n",
      "Procesado correctamente: NWSA\n",
      "Procesado correctamente: NWS\n",
      "Procesado correctamente: NEE\n",
      "Procesado correctamente: NKE\n",
      "Procesado correctamente: NI\n",
      "Procesado correctamente: NDSN\n",
      "Procesado correctamente: NSC\n",
      "Procesado correctamente: NTRS\n",
      "Procesado correctamente: NOC\n",
      "Procesado correctamente: NCLH\n",
      "Procesado correctamente: NRG\n",
      "Procesado correctamente: NUE\n",
      "Procesado correctamente: NVDA\n",
      "Procesado correctamente: NVR\n",
      "Procesado correctamente: NXPI\n",
      "Procesado correctamente: ORLY\n",
      "Procesado correctamente: OXY\n",
      "Procesado correctamente: ODFL\n",
      "Procesado correctamente: OMC\n",
      "Procesado correctamente: ON\n",
      "Procesado correctamente: OKE\n",
      "Procesado correctamente: ORCL\n",
      "Procesado correctamente: OTIS\n",
      "Procesado correctamente: PCAR\n",
      "Procesado correctamente: PKG\n",
      "Procesado correctamente: PLTR\n",
      "Procesado correctamente: PANW\n",
      "Procesado correctamente: PARA\n",
      "Procesado correctamente: PH\n",
      "Procesado correctamente: PAYX\n",
      "Procesado correctamente: PAYC\n",
      "Procesado correctamente: PYPL\n",
      "Procesado correctamente: PNR\n",
      "Procesado correctamente: PEP\n",
      "Procesado correctamente: PFE\n",
      "Procesado correctamente: PCG\n",
      "Procesado correctamente: PM\n",
      "Procesado correctamente: PSX\n",
      "Procesado correctamente: PNW\n",
      "Procesado correctamente: PNC\n",
      "Procesado correctamente: POOL\n",
      "Procesado correctamente: PPG\n",
      "Procesado correctamente: PPL\n",
      "Procesado correctamente: PFG\n",
      "Procesado correctamente: PG\n",
      "Procesado correctamente: PGR\n",
      "Procesado correctamente: PLD\n",
      "Procesado correctamente: PRU\n",
      "Procesado correctamente: PEG\n",
      "Procesado correctamente: PTC\n",
      "Procesado correctamente: PSA\n",
      "Procesado correctamente: PHM\n",
      "Procesado correctamente: PWR\n",
      "Procesado correctamente: QCOM\n",
      "Procesado correctamente: DGX\n",
      "Procesado correctamente: RL\n",
      "Procesado correctamente: RJF\n",
      "Procesado correctamente: RTX\n",
      "Procesado correctamente: O\n",
      "Procesado correctamente: REG\n",
      "Procesado correctamente: REGN\n",
      "Procesado correctamente: RF\n",
      "Procesado correctamente: RSG\n",
      "Procesado correctamente: RMD\n",
      "Procesado correctamente: RVTY\n",
      "Descargando lote 5 con 100 tickers\n",
      "Lote 5: Datos descargados, shape: (753, 502)\n",
      "Tickers en datos descargados: 100\n",
      "Procesado correctamente: ROK\n",
      "Procesado correctamente: ROL\n",
      "Procesado correctamente: ROP\n",
      "Procesado correctamente: ROST\n",
      "Procesado correctamente: RCL\n",
      "Procesado correctamente: SPGI\n",
      "Procesado correctamente: CRM\n",
      "Procesado correctamente: SBAC\n",
      "Procesado correctamente: SLB\n",
      "Procesado correctamente: STX\n",
      "Procesado correctamente: SRE\n",
      "Procesado correctamente: NOW\n",
      "Procesado correctamente: SHW\n",
      "Procesado correctamente: SPG\n",
      "Procesado correctamente: SWKS\n",
      "Procesado correctamente: SJM\n",
      "Procesado correctamente: SW\n",
      "Procesado correctamente: SNA\n",
      "Procesado correctamente: SOLV\n",
      "Procesado correctamente: SO\n",
      "Procesado correctamente: LUV\n",
      "Procesado correctamente: SWK\n",
      "Procesado correctamente: SBUX\n",
      "Procesado correctamente: STT\n",
      "Procesado correctamente: STLD\n",
      "Procesado correctamente: STE\n",
      "Procesado correctamente: SYK\n",
      "Procesado correctamente: SMCI\n",
      "Procesado correctamente: SYF\n",
      "Procesado correctamente: SNPS\n",
      "Procesado correctamente: SYY\n",
      "Procesado correctamente: TMUS\n",
      "Procesado correctamente: TROW\n",
      "Procesado correctamente: TTWO\n",
      "Procesado correctamente: TPR\n",
      "Procesado correctamente: TRGP\n",
      "Procesado correctamente: TGT\n",
      "Procesado correctamente: TEL\n",
      "Procesado correctamente: TDY\n",
      "Procesado correctamente: TER\n",
      "Procesado correctamente: TSLA\n",
      "Procesado correctamente: TXN\n",
      "Procesado correctamente: TPL\n",
      "Procesado correctamente: TXT\n",
      "Procesado correctamente: TMO\n",
      "Procesado correctamente: TJX\n",
      "Procesado correctamente: TKO\n",
      "Procesado correctamente: TSCO\n",
      "Procesado correctamente: TT\n",
      "Procesado correctamente: TDG\n",
      "Procesado correctamente: TRV\n",
      "Procesado correctamente: TRMB\n",
      "Procesado correctamente: TFC\n",
      "Procesado correctamente: TYL\n",
      "Procesado correctamente: TSN\n",
      "Procesado correctamente: USB\n",
      "Procesado correctamente: UBER\n",
      "Procesado correctamente: UDR\n",
      "Procesado correctamente: ULTA\n",
      "Procesado correctamente: UNP\n",
      "Procesado correctamente: UAL\n",
      "Procesado correctamente: UPS\n",
      "Procesado correctamente: URI\n",
      "Procesado correctamente: UNH\n",
      "Procesado correctamente: UHS\n",
      "Procesado correctamente: VLO\n",
      "Procesado correctamente: VTR\n",
      "Procesado correctamente: VLTO\n",
      "Procesado correctamente: VRSN\n",
      "Procesado correctamente: VRSK\n",
      "Procesado correctamente: VZ\n",
      "Procesado correctamente: VRTX\n",
      "Procesado correctamente: VTRS\n",
      "Procesado correctamente: VICI\n",
      "Procesado correctamente: V\n",
      "Procesado correctamente: VST\n",
      "Procesado correctamente: VMC\n",
      "Procesado correctamente: WRB\n",
      "Procesado correctamente: GWW\n",
      "Procesado correctamente: WAB\n",
      "Procesado correctamente: WBA\n",
      "Procesado correctamente: WMT\n",
      "Procesado correctamente: DIS\n",
      "Procesado correctamente: WBD\n",
      "Procesado correctamente: WM\n",
      "Procesado correctamente: WAT\n",
      "Procesado correctamente: WEC\n",
      "Procesado correctamente: WFC\n",
      "Procesado correctamente: WELL\n",
      "Procesado correctamente: WST\n",
      "Procesado correctamente: WDC\n",
      "Procesado correctamente: WY\n",
      "Procesado correctamente: WSM\n",
      "Procesado correctamente: WMB\n",
      "Procesado correctamente: WTW\n",
      "Procesado correctamente: WDAY\n",
      "Procesado correctamente: WYNN\n",
      "Procesado correctamente: XEL\n",
      "Procesado correctamente: XYL\n",
      "Procesado correctamente: YUM\n",
      "Descargando lote 6 con 3 tickers\n",
      "Lote 6: Datos descargados, shape: (753, 15)\n",
      "Tickers en datos descargados: 3\n",
      "Procesado correctamente: ZBRA\n",
      "Procesado correctamente: ZBH\n",
      "Procesado correctamente: ZTS\n",
      "Descarga completa. Tickers con datos: 503\n",
      "Datos cargados: 501 acciones\n",
      "Calculando factores...\n",
      "Factores calculados correctamente\n",
      "Identificando reg√≠menes de mercado...\n",
      "Historial de reg√≠menes calculado: {'transition': 417, 'low_vol': 224, 'high_vol': 112}\n",
      "Analizando rendimiento de factores...\n",
      "Rendimiento de factores calculado correctamente\n",
      "Ejecutando backtest...\n",
      "Pesos de factores optimizados correctamente\n",
      "Backtest completado. Sharpe Ratio: 0.20, Max Drawdown: -38.08%\n",
      "Estrategia completada con √©xito. Resultados guardados en ./artifacts/results/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Crear directorios para resultados\n",
    "os.makedirs('./artifacts/results', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/figures', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/data', exist_ok=True)\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    filename='./artifacts/errors.txt',\n",
    "    level=logging.ERROR,\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Suprimir advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AdaptiveFactorStrategy:\n",
    "    def __init__(self, start_date='2010-01-01', end_date=None, lookback_period=252, \n",
    "                 rebalance_freq=21, max_stock_weight=0.05, max_sector_weight=0.20):\n",
    "        \"\"\"\n",
    "        Inicializa la estrategia de factores adaptativos market-neutral.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Fecha de inicio para los datos\n",
    "            end_date: Fecha de fin para los datos (None = hoy)\n",
    "            lookback_period: Per√≠odo de lookback para c√°lculos (d√≠as de trading)\n",
    "            rebalance_freq: Frecuencia de rebalanceo (d√≠as de trading)\n",
    "            max_stock_weight: Peso m√°ximo por acci√≥n\n",
    "            max_sector_weight: Peso m√°ximo por sector\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date if end_date else datetime.now().strftime('%Y-%m-%d')\n",
    "        self.lookback_period = lookback_period\n",
    "        self.rebalance_freq = rebalance_freq\n",
    "        self.max_stock_weight = max_stock_weight\n",
    "        self.max_sector_weight = max_sector_weight\n",
    "        \n",
    "        # Par√°metros para identificaci√≥n de reg√≠menes\n",
    "        self.regime_lookback = 63  # ~3 meses\n",
    "        self.vix_high_threshold = 25\n",
    "        self.vol_high_threshold = 0.20  # Anualizado\n",
    "        \n",
    "        # Par√°metros para circuit breakers\n",
    "        self.max_factor_drawdown = 0.15\n",
    "        self.drawdown_recovery_threshold = 0.05\n",
    "        \n",
    "        # Inicializar datos\n",
    "        self.sp500_tickers = None\n",
    "        self.market_data = None\n",
    "        self.stock_data = None\n",
    "        self.sector_data = None\n",
    "        self.vix_data = None\n",
    "        self.factor_data = {}\n",
    "        self.factor_performance = {}\n",
    "        self.factor_weights = {}\n",
    "        self.regime_history = None\n",
    "        self.portfolio_history = None\n",
    "        \n",
    "        # Factores a utilizar\n",
    "        self.factors = [\n",
    "            'momentum', 'value', 'quality', 'low_vol', \n",
    "            'size', 'growth', 'dividend', 'profitability'\n",
    "        ]\n",
    "        \n",
    "        # Inicializar pesos de factores por r√©gimen\n",
    "        self.init_factor_weights()\n",
    "    \n",
    "    def init_factor_weights(self):\n",
    "        \"\"\"Inicializa los pesos de factores por r√©gimen con valores predeterminados.\"\"\"\n",
    "        # Pesos iniciales por r√©gimen (ser√°n optimizados)\n",
    "        regimes = ['low_vol', 'high_vol', 'transition']\n",
    "        \n",
    "        for regime in regimes:\n",
    "            self.factor_weights[regime] = {factor: 1/len(self.factors) for factor in self.factors}\n",
    "    \n",
    "    def get_sp500_tickers(self):\n",
    "        \"\"\"Obtiene la lista de tickers del S&P 500 desde Wikipedia.\"\"\"\n",
    "        try:\n",
    "            url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find the first table on the page (should be the S&P 500 table)\n",
    "            table = soup.find('table', {'class': 'wikitable'})\n",
    "            \n",
    "            if not table:\n",
    "                logging.error(\"No se encontr√≥ la tabla en la p√°gina de Wikipedia\")\n",
    "                raise ValueError(\"No se encontr√≥ la tabla en la p√°gina de Wikipedia\")\n",
    "            \n",
    "            # Print some debug info about the table\n",
    "            print(f\"Tabla encontrada. Filas: {len(table.findAll('tr'))}\")\n",
    "            \n",
    "            # Examine table headers to find the ticker and sector columns\n",
    "            headers = table.find('tr')\n",
    "            if not headers:\n",
    "                logging.error(\"No se encontraron encabezados en la tabla\")\n",
    "                raise ValueError(\"No se encontraron encabezados en la tabla\")\n",
    "            \n",
    "            header_cells = headers.findAll(['th'])\n",
    "            header_texts = [cell.text.strip() for cell in header_cells]\n",
    "            print(f\"Encabezados de tabla: {header_texts}\")\n",
    "            \n",
    "            # Try to find ticker and sector column indices\n",
    "            ticker_col = next((i for i, h in enumerate(header_texts) if 'Symbol' in h or 'Ticker' in h), 0)\n",
    "            sector_col = next((i for i, h in enumerate(header_texts) if 'Sector' in h), 1)\n",
    "            \n",
    "            print(f\"Usando columna {ticker_col} para tickers y columna {sector_col} para sectores\")\n",
    "            \n",
    "            tickers = []\n",
    "            sectors = {}\n",
    "            \n",
    "            # Skip header row\n",
    "            for row in table.findAll('tr')[1:]:\n",
    "                cells = row.findAll('td')\n",
    "                if len(cells) > max(ticker_col, sector_col):\n",
    "                    # Extract and clean ticker (sometimes in a link)\n",
    "                    ticker_cell = cells[ticker_col]\n",
    "                    ticker_a = ticker_cell.find('a')\n",
    "                    ticker = ticker_a.text.strip() if ticker_a else ticker_cell.text.strip()\n",
    "                    ticker = ticker.replace('\\n', '').replace('.', '-')  # Clean up ticker\n",
    "                    \n",
    "                    # Check if ticker looks valid (not empty, not a date, etc.)\n",
    "                    if ticker and not any(month in ticker for month in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']):\n",
    "                        sector = cells[sector_col].text.strip()\n",
    "                        tickers.append(ticker)\n",
    "                        sectors[ticker] = sector\n",
    "            \n",
    "            print(f\"Tickers extra√≠dos: {len(tickers)}\")\n",
    "            if len(tickers) < 10:\n",
    "                print(f\"Muestra de tickers: {tickers}\")\n",
    "                raise ValueError(f\"Se extrajeron muy pocos tickers: {len(tickers)}\")\n",
    "            \n",
    "            self.sp500_tickers = tickers\n",
    "            self.sector_data = pd.Series(sectors)\n",
    "            \n",
    "            # Guardar datos para referencia\n",
    "            pd.DataFrame({'Ticker': tickers, 'Sector': [sectors[t] for t in tickers]}).to_csv(\n",
    "                './artifacts/results/data/sp500_components.csv', index=False)\n",
    "            \n",
    "            return tickers\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error obteniendo tickers del S&P 500: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "    \n",
    "    def download_data_in_batches(self, tickers, start_date, end_date, batch_size=100):\n",
    "        \"\"\"Descarga datos en lotes para evitar limitaciones de yfinance.\"\"\"\n",
    "        all_data = {}\n",
    "        \n",
    "        # A√±adir SPY y VIX a la primera descarga\n",
    "        first_batch = tickers[:batch_size-2] + ['^GSPC', '^VIX']\n",
    "        \n",
    "        print(f\"Comenzando descarga de datos para {len(tickers)} tickers en lotes de {batch_size}\")\n",
    "        \n",
    "        for i in range(0, len(tickers), batch_size):\n",
    "            batch = first_batch if i == 0 else tickers[i:i+batch_size]\n",
    "            print(f\"Descargando lote {i//batch_size+1} con {len(batch)} tickers\")\n",
    "            \n",
    "            # Intentar hasta 3 veces con backoff exponencial\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    data = yf.download(batch, start=start_date, end=end_date, progress=False)\n",
    "                    print(f\"Lote {i//batch_size+1}: Datos descargados, shape: {data.shape}\")\n",
    "                    \n",
    "                    # Si los datos est√°n vac√≠os, reintenta\n",
    "                    if data.empty:\n",
    "                        if attempt < 2:\n",
    "                            wait_time = 2 ** attempt\n",
    "                            print(f\"Datos vac√≠os, reintentando en {wait_time} segundos...\")\n",
    "                            time.sleep(wait_time)  # Backoff exponencial\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(f\"No se pudieron obtener datos para el lote {i//batch_size+1} despu√©s de 3 intentos\")\n",
    "                            logging.warning(f\"No se pudieron obtener datos para el lote {i//batch_size+1}\")\n",
    "                    \n",
    "                    # Si hay muy pocos datos, intenta descargas individuales\n",
    "                    if len(batch) > 1 and (isinstance(data.columns, pd.MultiIndex) and len(data.columns.levels[1]) < len(batch) * 0.5):\n",
    "                        print(f\"Solo se descargaron datos para {len(data.columns.levels[1])} de {len(batch)} tickers, intentando descargas individuales\")\n",
    "                        for ticker in batch:\n",
    "                            try:\n",
    "                                single_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "                                if not single_data.empty:\n",
    "                                    all_data[ticker] = single_data\n",
    "                                    print(f\"Descarga individual exitosa para {ticker}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error en descarga individual para {ticker}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Procesar datos por ticker\n",
    "                    if len(batch) > 1 and isinstance(data.columns, pd.MultiIndex):\n",
    "                        tickers_in_data = data.columns.levels[1]\n",
    "                        print(f\"Tickers en datos descargados: {len(tickers_in_data)}\")\n",
    "                        \n",
    "                        for ticker in batch:\n",
    "                            try:\n",
    "                                if ticker in tickers_in_data:\n",
    "                                    ticker_data = data.xs(ticker, level=1, axis=1)\n",
    "                                    if not ticker_data.empty:\n",
    "                                        all_data[ticker] = ticker_data\n",
    "                                        print(f\"Procesado correctamente: {ticker}\")\n",
    "                                    else:\n",
    "                                        print(f\"Datos vac√≠os para {ticker}\")\n",
    "                                else:\n",
    "                                    print(f\"Ticker {ticker} no encontrado en datos descargados\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error procesando {ticker}: {str(e)}\")\n",
    "                                continue\n",
    "                    elif len(batch) == 1:\n",
    "                        if not data.empty:\n",
    "                            all_data[batch[0]] = data\n",
    "                            print(f\"Datos guardados para {batch[0]}\")\n",
    "                        else:\n",
    "                            print(f\"Datos vac√≠os para √∫nico ticker {batch[0]}\")\n",
    "                    \n",
    "                    break  # Salir del bucle de intentos si fue exitoso\n",
    "                \n",
    "                except Exception as e:\n",
    "                    if attempt < 2:\n",
    "                        wait_time = 2 ** attempt\n",
    "                        print(f\"Error en intento {attempt+1}, reintentando en {wait_time} segundos: {str(e)}\")\n",
    "                        time.sleep(wait_time)  # Backoff exponencial\n",
    "                    else:\n",
    "                        print(f\"Error descargando datos para el lote {i//batch_size+1} despu√©s de 3 intentos: {str(e)}\")\n",
    "                        logging.error(f\"Error descargando datos para el lote {i//batch_size+1}: {str(e)}\")\n",
    "            \n",
    "            # Peque√±a pausa entre lotes para evitar l√≠mites de API\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(f\"Descarga completa. Tickers con datos: {len(all_data)}\")\n",
    "        return all_data\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Carga todos los datos necesarios para la estrategia.\"\"\"\n",
    "        try:\n",
    "            # Obtener tickers del S&P 500\n",
    "            if self.sp500_tickers is None:\n",
    "                self.get_sp500_tickers()\n",
    "            \n",
    "            # Descargar datos en lotes\n",
    "            data_dict = self.download_data_in_batches(\n",
    "                self.sp500_tickers, self.start_date, self.end_date)\n",
    "            \n",
    "            # Extraer datos del mercado (S&P 500) y VIX\n",
    "            if '^GSPC' in data_dict:\n",
    "                self.market_data = data_dict['^GSPC']\n",
    "                del data_dict['^GSPC']\n",
    "            else:\n",
    "                logging.error(\"No se pudieron obtener datos del S&P 500\")\n",
    "                raise ValueError(\"No se pudieron obtener datos del S&P 500\")\n",
    "            \n",
    "            if '^VIX' in data_dict:\n",
    "                self.vix_data = data_dict['^VIX']['Close']\n",
    "                del data_dict['^VIX']\n",
    "            else:\n",
    "                logging.error(\"No se pudieron obtener datos del VIX\")\n",
    "                raise ValueError(\"No se pudieron obtener datos del VIX\")\n",
    "            \n",
    "            # Crear DataFrame con precios de cierre\n",
    "            close_prices = pd.DataFrame({ticker: data['Close'] \n",
    "                                         for ticker, data in data_dict.items()\n",
    "                                         if 'Close' in data})\n",
    "            \n",
    "            # Crear DataFrame con vol√∫menes\n",
    "            volumes = pd.DataFrame({ticker: data['Volume'] \n",
    "                                   for ticker, data in data_dict.items()\n",
    "                                   if 'Volume' in data})\n",
    "            \n",
    "            # Crear DataFrame con datos fundamentales (para factores)\n",
    "            fundamentals = {}\n",
    "            for ticker, data in data_dict.items():\n",
    "                if all(col in data for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
    "                    fundamentals[ticker] = {\n",
    "                        'close': data['Close'],\n",
    "                        'high': data['High'],\n",
    "                        'low': data['Low'],\n",
    "                        'open': data['Open'],\n",
    "                        'volume': data['Volume']\n",
    "                    }\n",
    "            \n",
    "            self.stock_data = {\n",
    "                'close': close_prices,\n",
    "                'volume': volumes,\n",
    "                'fundamentals': fundamentals\n",
    "            }\n",
    "            \n",
    "            # Calcular retornos diarios\n",
    "            self.stock_data['returns'] = self.stock_data['close'].pct_change()\n",
    "            \n",
    "            # Guardar datos de mercado para referencia\n",
    "            self.market_data['Close'].to_csv('./artifacts/results/data/sp500_prices.csv')\n",
    "            self.vix_data.to_csv('./artifacts/results/data/vix_data.csv')\n",
    "            \n",
    "            print(f\"Datos cargados: {len(self.stock_data['close'].columns)} acciones\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error cargando datos: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "    \n",
    "    def calculate_factors(self):\n",
    "        \"\"\"Calcula todos los factores para cada acci√≥n.\"\"\"\n",
    "        try:\n",
    "            # Asegurarse de que los datos est√©n cargados\n",
    "            if self.stock_data is None:\n",
    "                self.load_data()\n",
    "            \n",
    "            close_prices = self.stock_data['close']\n",
    "            returns = self.stock_data['returns']\n",
    "            volumes = self.stock_data['volume']\n",
    "            \n",
    "            # 1. Factor Momentum (retornos de 12 meses excluyendo el √∫ltimo mes)\n",
    "            momentum = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                # Obtener fecha hace 12 meses y hace 1 mes\n",
    "                year_ago = close_prices.index[close_prices.index < date]\n",
    "                if len(year_ago) >= 252:  # ~1 a√±o de trading\n",
    "                    year_ago = year_ago[-252]\n",
    "                    month_ago = close_prices.index[close_prices.index < date][-21]  # ~1 mes de trading\n",
    "                    \n",
    "                    # Calcular retornos desde hace 12 meses hasta hace 1 mes\n",
    "                    prices_year_ago = close_prices.loc[year_ago]\n",
    "                    prices_month_ago = close_prices.loc[month_ago]\n",
    "                    \n",
    "                    momentum.loc[date] = (prices_month_ago / prices_year_ago) - 1\n",
    "            \n",
    "            # 2. Factor Value (inverso del P/E, simulado con precio/volumen como proxy)\n",
    "            # En una implementaci√≥n real, usar√≠amos datos fundamentales reales\n",
    "            value = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                if date in volumes.index:\n",
    "                    # Usar precio/volumen como proxy inverso de value\n",
    "                    # Valores m√°s bajos = m√°s value\n",
    "                    price_to_volume = close_prices.loc[date] / (volumes.loc[date] + 1)\n",
    "                    value.loc[date] = -price_to_volume  # Invertir para que valores altos = m√°s value\n",
    "            \n",
    "            # 3. Factor Quality (estabilidad de retornos, menor volatilidad = mayor calidad)\n",
    "            quality = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                past_dates = returns.index[returns.index < date]\n",
    "                if len(past_dates) >= 63:  # ~3 meses de trading\n",
    "                    past_dates = past_dates[-63:]\n",
    "                    # Calcular volatilidad de retornos (menor = mejor calidad)\n",
    "                    vol = returns.loc[past_dates].std()\n",
    "                    quality.loc[date] = -vol  # Invertir para que valores altos = m√°s calidad\n",
    "            \n",
    "            # 4. Factor Low Volatility\n",
    "            low_vol = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                past_dates = returns.index[returns.index < date]\n",
    "                if len(past_dates) >= 126:  # ~6 meses de trading\n",
    "                    past_dates = past_dates[-126:]\n",
    "                    # Calcular volatilidad de retornos\n",
    "                    vol = returns.loc[past_dates].std() * np.sqrt(252)  # Anualizar\n",
    "                    low_vol.loc[date] = -vol  # Invertir para que valores altos = menor volatilidad\n",
    "            \n",
    "            # 5. Factor Size (inverso de la capitalizaci√≥n de mercado, proxy con volumen)\n",
    "            size = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                if date in volumes.index:\n",
    "                    # Usar volumen como proxy de tama√±o\n",
    "                    size.loc[date] = -volumes.loc[date]  # Invertir para que valores altos = menor tama√±o\n",
    "            \n",
    "            # 6. Factor Growth (tasa de crecimiento de precios)\n",
    "            growth = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                past_dates = close_prices.index[close_prices.index < date]\n",
    "                if len(past_dates) >= 252:  # ~1 a√±o de trading\n",
    "                    # Fechas para 1 a√±o, 6 meses y 3 meses atr√°s\n",
    "                    year_ago = past_dates[-252]\n",
    "                    six_months_ago = past_dates[-126] if len(past_dates) >= 126 else past_dates[0]\n",
    "                    three_months_ago = past_dates[-63] if len(past_dates) >= 63 else past_dates[0]\n",
    "                    \n",
    "                    # Calcular tasas de crecimiento\n",
    "                    growth_1y = (close_prices.loc[date] / close_prices.loc[year_ago]) - 1\n",
    "                    growth_6m = (close_prices.loc[date] / close_prices.loc[six_months_ago]) - 1\n",
    "                    growth_3m = (close_prices.loc[date] / close_prices.loc[three_months_ago]) - 1\n",
    "                    \n",
    "                    # Promedio ponderado de tasas de crecimiento\n",
    "                    growth.loc[date] = 0.5 * growth_1y + 0.3 * growth_6m + 0.2 * growth_3m\n",
    "            \n",
    "            # 7. Factor Dividend (simulado con volatilidad baja y retornos estables)\n",
    "            # En una implementaci√≥n real, usar√≠amos datos de dividendos reales\n",
    "            dividend = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                past_dates = returns.index[returns.index < date]\n",
    "                if len(past_dates) >= 252:  # ~1 a√±o de trading\n",
    "                    past_dates = past_dates[-252:]\n",
    "                    # Combinar baja volatilidad y retornos positivos como proxy de dividendos\n",
    "                    vol = returns.loc[past_dates].std()\n",
    "                    avg_return = returns.loc[past_dates].mean()\n",
    "                    dividend.loc[date] = avg_return - vol  # Mayor retorno y menor vol = mejor\n",
    "            \n",
    "            # 8. Factor Profitability (simulado con consistencia de retornos positivos)\n",
    "            # En una implementaci√≥n real, usar√≠amos datos fundamentales reales\n",
    "            profitability = pd.DataFrame(index=close_prices.index, columns=close_prices.columns)\n",
    "            for date in close_prices.index:\n",
    "                past_dates = returns.index[returns.index < date]\n",
    "                if len(past_dates) >= 126:  # ~6 meses de trading\n",
    "                    past_dates = past_dates[-126:]\n",
    "                    # Porcentaje de d√≠as con retornos positivos\n",
    "                    positive_days = (returns.loc[past_dates] > 0).mean()\n",
    "                    profitability.loc[date] = positive_days\n",
    "            \n",
    "            # Almacenar factores calculados\n",
    "            self.factor_data = {\n",
    "                'momentum': momentum,\n",
    "                'value': value,\n",
    "                'quality': quality,\n",
    "                'low_vol': low_vol,\n",
    "                'size': size,\n",
    "                'growth': growth,\n",
    "                'dividend': dividend,\n",
    "                'profitability': profitability\n",
    "            }\n",
    "            \n",
    "            # Normalizar factores (z-score por fecha)\n",
    "            for factor_name, factor_df in self.factor_data.items():\n",
    "                for date in factor_df.index:\n",
    "                    if not factor_df.loc[date].isna().all():\n",
    "                        factor_values = factor_df.loc[date].dropna()\n",
    "                        if len(factor_values) > 0:\n",
    "                            mean = factor_values.mean()\n",
    "                            std = factor_values.std()\n",
    "                            if std > 0:\n",
    "                                factor_df.loc[date] = (factor_df.loc[date] - mean) / std\n",
    "            \n",
    "            # Guardar datos de factores para referencia\n",
    "            for factor_name, factor_df in self.factor_data.items():\n",
    "                factor_df.iloc[-252:].to_csv(f'./artifacts/results/data/factor_{factor_name}.csv')\n",
    "            \n",
    "            print(\"Factores calculados correctamente\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando factores: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "    \n",
    "    def identify_market_regime(self, date):\n",
    "        \"\"\"\n",
    "        Identifica el r√©gimen de mercado actual basado en VIX, volatilidad y tendencias.\n",
    "        \n",
    "        Args:\n",
    "            date: Fecha para la cual identificar el r√©gimen\n",
    "        \n",
    "        Returns:\n",
    "            str: R√©gimen identificado ('low_vol', 'high_vol', 'transition')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Obtener fechas anteriores para el lookback\n",
    "            past_dates = self.market_data.index[self.market_data.index < date]\n",
    "            if len(past_dates) < self.regime_lookback:\n",
    "                return 'transition'  # Por defecto si no hay suficientes datos\n",
    "            \n",
    "            past_dates = past_dates[-self.regime_lookback:]\n",
    "            \n",
    "            # 1. Nivel del VIX\n",
    "            current_vix = self.vix_data.loc[date] if date in self.vix_data.index else None\n",
    "            vix_high = current_vix is not None and current_vix > self.vix_high_threshold\n",
    "            \n",
    "            # 2. Volatilidad del mercado\n",
    "            market_returns = self.market_data['Close'].pct_change().loc[past_dates]\n",
    "            market_vol = market_returns.std() * np.sqrt(252)  # Anualizada\n",
    "            vol_high = market_vol > self.vol_high_threshold\n",
    "            \n",
    "            # 3. Tendencia del mercado\n",
    "            market_trend = self.market_data['Close'].loc[date] / self.market_data['Close'].loc[past_dates[0]] - 1\n",
    "            trend_up = market_trend > 0.05  # 5% de subida en el per√≠odo\n",
    "            trend_down = market_trend < -0.05  # 5% de bajada en el per√≠odo\n",
    "            \n",
    "            # Determinar r√©gimen\n",
    "            if vix_high or vol_high:\n",
    "                if trend_down:\n",
    "                    return 'high_vol'  # Alta volatilidad con tendencia bajista\n",
    "                else:\n",
    "                    return 'transition'  # Alta volatilidad sin tendencia clara\n",
    "            elif trend_up and not vol_high:\n",
    "                return 'low_vol'  # Baja volatilidad con tendencia alcista\n",
    "            else:\n",
    "                return 'transition'  # Caso por defecto\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error identificando r√©gimen de mercado: {str(e)}\")\n",
    "            return 'transition'  # Valor por defecto en caso de error\n",
    "    \n",
    "    def calculate_regime_history(self):\n",
    "        \"\"\"Calcula el historial de reg√≠menes de mercado para todo el per√≠odo.\"\"\"\n",
    "        try:\n",
    "            regimes = {}\n",
    "            \n",
    "            for date in self.market_data.index:\n",
    "                regimes[date] = self.identify_market_regime(date)\n",
    "            \n",
    "            self.regime_history = pd.Series(regimes)\n",
    "            \n",
    "            # Guardar historial de reg√≠menes\n",
    "            self.regime_history.to_csv('./artifacts/results/data/regime_history.csv')\n",
    "            \n",
    "            # Visualizar distribuci√≥n de reg√≠menes\n",
    "            regime_counts = self.regime_history.value_counts()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x=regime_counts.index, y=regime_counts.values)\n",
    "            plt.title('Distribuci√≥n de Reg√≠menes de Mercado')\n",
    "            plt.ylabel('N√∫mero de d√≠as')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/regime_distribution.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Historial de reg√≠menes calculado: {regime_counts.to_dict()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando historial de reg√≠menes: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def calculate_factor_performance(self):\n",
    "        \"\"\"Calcula el rendimiento hist√≥rico de cada factor.\"\"\"\n",
    "        try:\n",
    "            # Inicializar diccionario para almacenar rendimientos\n",
    "            factor_returns = {factor: pd.Series(index=self.stock_data['returns'].index) \n",
    "                             for factor in self.factors}\n",
    "            \n",
    "            # Para cada fecha, calcular el rendimiento de cada factor\n",
    "            for date in self.stock_data['returns'].index[1:]:  # Empezar desde el segundo d√≠a\n",
    "                prev_date = self.stock_data['returns'].index[self.stock_data['returns'].index < date][-1]\n",
    "                \n",
    "                for factor in self.factors:\n",
    "                    if factor in self.factor_data and prev_date in self.factor_data[factor].index:\n",
    "                        # Obtener scores del factor para la fecha anterior\n",
    "                        factor_scores = self.factor_data[factor].loc[prev_date].dropna()\n",
    "                        \n",
    "                        if len(factor_scores) > 0:\n",
    "                            # Seleccionar top y bottom 10% de acciones por factor\n",
    "                            num_stocks = max(10, int(len(factor_scores) * 0.1))\n",
    "                            factor_scores = pd.to_numeric(factor_scores, errors='coerce')\n",
    "                            factor_scores = factor_scores.dropna()  # Remove any values that couldn't be converted\n",
    "                            \n",
    "                            # Now use nlargest/nsmallest\n",
    "                            if not factor_scores.empty:\n",
    "                                top_stocks = factor_scores.nlargest(num_stocks).index\n",
    "                                bottom_stocks = factor_scores.nsmallest(num_stocks).index\n",
    "                            else:\n",
    "                                top_stocks = []\n",
    "                                bottom_stocks = []\n",
    "                            \n",
    "                            # Calcular retornos para estas acciones\n",
    "                            if date in self.stock_data['returns'].index:\n",
    "                                top_returns = self.stock_data['returns'].loc[date, top_stocks].mean()\n",
    "                                bottom_returns = self.stock_data['returns'].loc[date, bottom_stocks].mean()\n",
    "                                \n",
    "                                # Factor return = long top stocks, short bottom stocks\n",
    "                                factor_returns[factor].loc[date] = top_returns - bottom_returns\n",
    "            \n",
    "            # Calcular rendimiento acumulado para cada factor\n",
    "            factor_cumulative = {factor: (1 + factor_returns[factor].fillna(0)).cumprod() \n",
    "                                for factor in self.factors}\n",
    "            \n",
    "            # Calcular drawdowns para cada factor\n",
    "            factor_drawdowns = {}\n",
    "            for factor in self.factors:\n",
    "                cumulative = factor_cumulative[factor]\n",
    "                running_max = cumulative.cummax()\n",
    "                drawdown = (cumulative / running_max) - 1\n",
    "                factor_drawdowns[factor] = drawdown\n",
    "            \n",
    "            # Calcular Sharpe ratio para cada factor\n",
    "            factor_sharpe = {}\n",
    "            for factor in self.factors:\n",
    "                returns_series = factor_returns[factor].dropna()\n",
    "                if len(returns_series) > 0:\n",
    "                    annual_return = returns_series.mean() * 252\n",
    "                    annual_vol = returns_series.std() * np.sqrt(252)\n",
    "                    if annual_vol > 0:\n",
    "                        factor_sharpe[factor] = annual_return / annual_vol\n",
    "                    else:\n",
    "                        factor_sharpe[factor] = 0\n",
    "                else:\n",
    "                    factor_sharpe[factor] = 0\n",
    "            \n",
    "            # Almacenar resultados\n",
    "            self.factor_performance = {\n",
    "                'returns': factor_returns,\n",
    "                'cumulative': factor_cumulative,\n",
    "                'drawdowns': factor_drawdowns,\n",
    "                'sharpe': factor_sharpe\n",
    "            }\n",
    "            \n",
    "            # Guardar rendimiento de factores\n",
    "            factor_perf_df = pd.DataFrame({f: factor_cumulative[f] for f in self.factors})\n",
    "            factor_perf_df.to_csv('./artifacts/results/data/factor_performance.csv')\n",
    "            \n",
    "            # Visualizar rendimiento de factores\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            for factor in self.factors:\n",
    "                plt.plot(factor_cumulative[factor].index, factor_cumulative[factor].values, label=factor)\n",
    "            plt.title('Rendimiento Acumulado de Factores')\n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('Rendimiento Acumulado')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/factor_performance.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Rendimiento de factores calculado correctamente\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando rendimiento de factores: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "    \n",
    "    def optimize_factor_weights(self, train_start, train_end):\n",
    "        \"\"\"\n",
    "        Optimiza los pesos de los factores para cada r√©gimen basado en datos hist√≥ricos.\n",
    "        \n",
    "        Args:\n",
    "            train_start: Fecha de inicio para entrenamiento\n",
    "            train_end: Fecha de fin para entrenamiento\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Filtrar datos de entrenamiento\n",
    "            train_dates = self.market_data.index[(self.market_data.index >= train_start) & \n",
    "                                                (self.market_data.index <= train_end)]\n",
    "            \n",
    "            if len(train_dates) < 63:  # M√≠nimo ~3 meses de datos\n",
    "                # Usar pesos predeterminados si no hay suficientes datos\n",
    "                return\n",
    "            \n",
    "            # Optimizar pesos para cada r√©gimen\n",
    "            for regime in ['low_vol', 'high_vol', 'transition']:\n",
    "                # Filtrar fechas por r√©gimen\n",
    "                regime_dates = [date for date in train_dates \n",
    "                               if date in self.regime_history.index and self.regime_history[date] == regime]\n",
    "                \n",
    "                if len(regime_dates) < 21:  # M√≠nimo ~1 mes de datos para el r√©gimen\n",
    "                    continue\n",
    "                \n",
    "                # Preparar datos para optimizaci√≥n\n",
    "                factor_returns_regime = {}\n",
    "                for factor in self.factors:\n",
    "                    if factor in self.factor_performance['returns']:\n",
    "                        returns = self.factor_performance['returns'][factor].loc[regime_dates].fillna(0)\n",
    "                        if len(returns) > 0:\n",
    "                            factor_returns_regime[factor] = returns\n",
    "                \n",
    "                if len(factor_returns_regime) < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Convertir a DataFrame para c√°lculos\n",
    "                returns_df = pd.DataFrame(factor_returns_regime)\n",
    "                \n",
    "                # Calcular matriz de covarianza y vector de retornos esperados\n",
    "                cov_matrix = returns_df.cov() * 252  # Anualizada\n",
    "                exp_returns = returns_df.mean() * 252  # Anualizados\n",
    "                \n",
    "                # Aplicar penalizaci√≥n a factores con drawdowns significativos\n",
    "                for factor in self.factors:\n",
    "                    if factor in self.factor_performance['drawdowns']:\n",
    "                        max_drawdown = self.factor_performance['drawdowns'][factor].loc[regime_dates].min()\n",
    "                        if max_drawdown < -self.max_factor_drawdown:\n",
    "                            exp_returns[factor] *= (1 + max_drawdown)  # Reducir retorno esperado\n",
    "                \n",
    "                # Optimizaci√≥n simple: maximizar Sharpe ratio\n",
    "                # En una implementaci√≥n real, usar√≠amos optimizaci√≥n cuadr√°tica con restricciones\n",
    "                \n",
    "                # Generar combinaciones de pesos\n",
    "                num_factors = len(exp_returns)\n",
    "                best_sharpe = -np.inf\n",
    "                best_weights = None\n",
    "                \n",
    "                # Usar validaci√≥n cruzada para evitar overfitting\n",
    "                tscv = TimeSeriesSplit(n_splits=5)\n",
    "                for train_idx, test_idx in tscv.split(returns_df):\n",
    "                    train_returns = returns_df.iloc[train_idx]\n",
    "                    test_returns = returns_df.iloc[test_idx]\n",
    "                    \n",
    "                    # Calcular retornos esperados y covarianza en datos de entrenamiento\n",
    "                    train_exp_returns = train_returns.mean() * 252\n",
    "                    train_cov_matrix = train_returns.cov() * 252\n",
    "                    \n",
    "                    # Generar 1000 combinaciones aleatorias de pesos\n",
    "                    for _ in range(1000):\n",
    "                        weights = np.random.random(num_factors)\n",
    "                        weights /= weights.sum()  # Normalizar para que sumen 1\n",
    "                        \n",
    "                        # Calcular Sharpe ratio en datos de prueba\n",
    "                        portfolio_return = (test_returns @ weights).mean() * 252\n",
    "                        portfolio_vol = np.sqrt(weights @ train_cov_matrix @ weights)\n",
    "                        \n",
    "                        if portfolio_vol > 0:\n",
    "                            sharpe = portfolio_return / portfolio_vol\n",
    "                            if sharpe > best_sharpe:\n",
    "                                best_sharpe = sharpe\n",
    "                                best_weights = weights\n",
    "                \n",
    "                if best_weights is not None:\n",
    "                    # Actualizar pesos de factores para el r√©gimen\n",
    "                    self.factor_weights[regime] = {factor: weight \n",
    "                                                 for factor, weight in zip(exp_returns.index, best_weights)}\n",
    "            \n",
    "            # Guardar pesos optimizados\n",
    "            weights_df = pd.DataFrame(self.factor_weights)\n",
    "            weights_df.to_csv('./artifacts/results/data/factor_weights.csv')\n",
    "            \n",
    "            print(\"Pesos de factores optimizados correctamente\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error optimizando pesos de factores: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "    \n",
    "    def calculate_combined_factor_score(self, date):\n",
    "        \"\"\"\n",
    "        Calcula el score combinado de factores para cada acci√≥n en una fecha espec√≠fica.\n",
    "        \n",
    "        Args:\n",
    "            date: Fecha para calcular los scores\n",
    "        \n",
    "        Returns:\n",
    "            pd.Series: Score combinado para cada acci√≥n\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Identificar r√©gimen actual\n",
    "            regime = self.identify_market_regime(date)\n",
    "            \n",
    "            # Obtener pesos de factores para el r√©gimen\n",
    "            factor_weights = self.factor_weights.get(regime, {})\n",
    "            \n",
    "            # Inicializar scores combinados\n",
    "            all_stocks = set()\n",
    "            for factor in self.factors:\n",
    "                if factor in self.factor_data and date in self.factor_data[factor].index:\n",
    "                    stocks = self.factor_data[factor].loc[date].dropna().index\n",
    "                    all_stocks.update(stocks)\n",
    "            \n",
    "            combined_scores = pd.Series(0, index=list(all_stocks))\n",
    "            \n",
    "            # Aplicar circuit breakers: verificar drawdowns de factores\n",
    "            active_factors = []\n",
    "            for factor in self.factors:\n",
    "                if factor in self.factor_performance['drawdowns'] and date in self.factor_performance['drawdowns'][factor].index:\n",
    "                    current_drawdown = self.factor_performance['drawdowns'][factor].loc[date]\n",
    "                    if current_drawdown > -self.max_factor_drawdown:\n",
    "                        active_factors.append(factor)\n",
    "            \n",
    "            if not active_factors:\n",
    "                active_factors = self.factors  # Si todos est√°n en drawdown, usar todos\n",
    "            \n",
    "            # Calcular score combinado\n",
    "            for factor in active_factors:\n",
    "                if factor in factor_weights and factor in self.factor_data and date in self.factor_data[factor].index:\n",
    "                    weight = factor_weights[factor]\n",
    "                    factor_scores = self.factor_data[factor].loc[date].dropna()\n",
    "                    \n",
    "                    # Aplicar peso del factor a los scores\n",
    "                    for stock in factor_scores.index:\n",
    "                        if stock in combined_scores.index:\n",
    "                            combined_scores[stock] += weight * factor_scores[stock]\n",
    "            \n",
    "            return combined_scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando scores combinados: {str(e)}\")\n",
    "            return pd.Series()\n",
    "    \n",
    "    def calculate_stock_betas(self, date, lookback=126):\n",
    "        \"\"\"\n",
    "        Calcula las betas de las acciones respecto al mercado.\n",
    "        \n",
    "        Args:\n",
    "            date: Fecha para calcular las betas\n",
    "            lookback: Per√≠odo de lookback para el c√°lculo\n",
    "            \n",
    "        Returns:\n",
    "            pd.Series: Beta para cada acci√≥n\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Obtener fechas anteriores para el lookback\n",
    "            past_dates = self.stock_data['returns'].index[self.stock_data['returns'].index < date]\n",
    "            if len(past_dates) < lookback:\n",
    "                return pd.Series()\n",
    "            \n",
    "            past_dates = past_dates[-lookback:]\n",
    "            \n",
    "            # Obtener retornos del mercado\n",
    "            market_returns = self.market_data['Close'].pct_change().loc[past_dates].fillna(0)\n",
    "            \n",
    "            # Calcular beta para cada acci√≥n\n",
    "            betas = {}\n",
    "            for stock in self.stock_data['returns'].columns:\n",
    "                stock_returns = self.stock_data['returns'].loc[past_dates, stock].fillna(0)\n",
    "                \n",
    "                if len(stock_returns) == len(market_returns) and not stock_returns.isna().all():\n",
    "                    # Usar regresi√≥n lineal para calcular beta\n",
    "                    model = LinearRegression()\n",
    "                    X = market_returns.values.reshape(-1, 1)\n",
    "                    y = stock_returns.values\n",
    "                    model.fit(X, y)\n",
    "                    beta = model.coef_[0]\n",
    "                    betas[stock] = beta\n",
    "            \n",
    "            return pd.Series(betas)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando betas: {str(e)}\")\n",
    "            return pd.Series()\n",
    "    \n",
    "    def ensure_sector_neutrality(self, long_stocks, short_stocks, date):\n",
    "        \"\"\"\n",
    "        Asegura la neutralidad sectorial entre posiciones long y short.\n",
    "        \n",
    "        Args:\n",
    "            long_stocks: Lista de acciones en posici√≥n long\n",
    "            short_stocks: Lista de acciones en posici√≥n short\n",
    "            date: Fecha actual\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Listas ajustadas de acciones long y short\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Obtener sectores para las acciones\n",
    "            sectors = {}\n",
    "            for stock in long_stocks + short_stocks:\n",
    "                if stock in self.sector_data.index:\n",
    "                    sectors[stock] = self.sector_data[stock]\n",
    "            \n",
    "            # Calcular exposici√≥n sectorial\n",
    "            long_sector_exposure = {}\n",
    "            short_sector_exposure = {}\n",
    "            \n",
    "            for stock in long_stocks:\n",
    "                if stock in sectors:\n",
    "                    sector = sectors[stock]\n",
    "                    long_sector_exposure[sector] = long_sector_exposure.get(sector, 0) + 1\n",
    "            \n",
    "            for stock in short_stocks:\n",
    "                if stock in sectors:\n",
    "                    sector = sectors[stock]\n",
    "                    short_sector_exposure[sector] = short_sector_exposure.get(sector, 0) + 1\n",
    "            \n",
    "            # Identificar sectores desbalanceados\n",
    "            all_sectors = set(long_sector_exposure.keys()) | set(short_sector_exposure.keys())\n",
    "            \n",
    "            for sector in all_sectors:\n",
    "                long_count = long_sector_exposure.get(sector, 0)\n",
    "                short_count = short_sector_exposure.get(sector, 0)\n",
    "                \n",
    "                # Si hay desbalance significativo\n",
    "                if abs(long_count - short_count) > 2:\n",
    "                    if long_count > short_count:\n",
    "                        # Reducir posiciones long en este sector\n",
    "                        sector_long_stocks = [s for s in long_stocks if s in sectors and sectors[s] == sector]\n",
    "                        excess = min(len(sector_long_stocks), long_count - short_count - 2)\n",
    "                        if excess > 0:\n",
    "                            for _ in range(excess):\n",
    "                                if sector_long_stocks:\n",
    "                                    long_stocks.remove(sector_long_stocks.pop())\n",
    "                    else:\n",
    "                        # Reducir posiciones short en este sector\n",
    "                        sector_short_stocks = [s for s in short_stocks if s in sectors and sectors[s] == sector]\n",
    "                        excess = min(len(sector_short_stocks), short_count - long_count - 2)\n",
    "                        if excess > 0:\n",
    "                            for _ in range(excess):\n",
    "                                if sector_short_stocks:\n",
    "                                    short_stocks.remove(sector_short_stocks.pop())\n",
    "            \n",
    "            return long_stocks, short_stocks\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error asegurando neutralidad sectorial: {str(e)}\")\n",
    "            return long_stocks, short_stocks\n",
    "    \n",
    "    def select_portfolio(self, date, num_stocks=50):\n",
    "        \"\"\"\n",
    "        Selecciona el portfolio para una fecha espec√≠fica.\n",
    "        \n",
    "        Args:\n",
    "            date: Fecha para seleccionar el portfolio\n",
    "            num_stocks: N√∫mero de acciones a seleccionar (long + short)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Portfolio con pesos para cada acci√≥n\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Calcular scores combinados\n",
    "            combined_scores = self.calculate_combined_factor_score(date)\n",
    "            \n",
    "            if combined_scores.empty:\n",
    "                return {}\n",
    "            \n",
    "            # Calcular betas\n",
    "            stock_betas = self.calculate_stock_betas(date)\n",
    "            \n",
    "            # Filtrar acciones con datos completos\n",
    "            valid_stocks = combined_scores.index.intersection(stock_betas.index)\n",
    "            combined_scores = combined_scores.loc[valid_stocks]\n",
    "            stock_betas = stock_betas.loc[valid_stocks]\n",
    "            \n",
    "            if len(combined_scores) < num_stocks:\n",
    "                return {}\n",
    "            \n",
    "            # Seleccionar acciones long y short basadas en scores\n",
    "            num_each_side = num_stocks // 2\n",
    "            long_candidates = combined_scores.nlargest(num_each_side * 2).index.tolist()\n",
    "            short_candidates = combined_scores.nsmallest(num_each_side * 2).index.tolist()\n",
    "            \n",
    "            # Asegurar neutralidad sectorial\n",
    "            long_stocks, short_stocks = self.ensure_sector_neutrality(\n",
    "                long_candidates[:num_each_side], \n",
    "                short_candidates[:num_each_side],\n",
    "                date\n",
    "            )\n",
    "            \n",
    "            # Calcular volatilidades para ponderaci√≥n inversa\n",
    "            volatilities = {}\n",
    "            past_dates = self.stock_data['returns'].index[self.stock_data['returns'].index < date]\n",
    "            if len(past_dates) >= 63:  # ~3 meses\n",
    "                past_dates = past_dates[-63:]\n",
    "                for stock in long_stocks + short_stocks:\n",
    "                    if stock in self.stock_data['returns'].columns:\n",
    "                        vol = self.stock_data['returns'].loc[past_dates, stock].std()\n",
    "                        if vol > 0:\n",
    "                            volatilities[stock] = vol\n",
    "            \n",
    "            # Si no hay volatilidades, usar pesos iguales\n",
    "            if not volatilities:\n",
    "                long_weights = {stock: 1/len(long_stocks) for stock in long_stocks}\n",
    "                short_weights = {stock: -1/len(short_stocks) for stock in short_stocks}\n",
    "            else:\n",
    "                # Ponderaci√≥n inversa a la volatilidad\n",
    "                long_inv_vol = {stock: 1/volatilities.get(stock, 1) for stock in long_stocks}\n",
    "                short_inv_vol = {stock: 1/volatilities.get(stock, 1) for stock in short_stocks}\n",
    "                \n",
    "                # Normalizar pesos\n",
    "                long_sum = sum(long_inv_vol.values())\n",
    "                short_sum = sum(short_inv_vol.values())\n",
    "                \n",
    "                if long_sum > 0 and short_sum > 0:\n",
    "                    long_weights = {stock: weight/long_sum for stock, weight in long_inv_vol.items()}\n",
    "                    short_weights = {stock: -weight/short_sum for stock, weight in short_inv_vol.items()}\n",
    "                else:\n",
    "                    long_weights = {stock: 1/len(long_stocks) for stock in long_stocks}\n",
    "                    short_weights = {stock: -1/len(short_stocks) for stock in short_stocks}\n",
    "            \n",
    "            # Combinar pesos\n",
    "            portfolio_weights = {**long_weights, **short_weights}\n",
    "            \n",
    "            # Ajustar para neutralidad beta\n",
    "            portfolio_beta = sum(portfolio_weights.get(stock, 0) * stock_betas.get(stock, 0) \n",
    "                                for stock in portfolio_weights)\n",
    "            \n",
    "            if portfolio_beta != 0:\n",
    "                # Ajustar pesos para neutralizar beta\n",
    "                beta_adjustment = -portfolio_beta\n",
    "                \n",
    "                # Aplicar ajuste a todas las posiciones\n",
    "                for stock in portfolio_weights:\n",
    "                    if stock in stock_betas:\n",
    "                        portfolio_weights[stock] += beta_adjustment * stock_betas[stock] / len(portfolio_weights)\n",
    "            \n",
    "            # Aplicar l√≠mites de concentraci√≥n\n",
    "            for stock in list(portfolio_weights.keys()):\n",
    "                if abs(portfolio_weights[stock]) > self.max_stock_weight:\n",
    "                    if portfolio_weights[stock] > 0:\n",
    "                        portfolio_weights[stock] = self.max_stock_weight\n",
    "                    else:\n",
    "                        portfolio_weights[stock] = -self.max_stock_weight\n",
    "            \n",
    "            # Normalizar para que la suma de valores absolutos sea 2 (1 long, 1 short)\n",
    "            abs_sum = sum(abs(w) for w in portfolio_weights.values())\n",
    "            if abs_sum > 0:\n",
    "                portfolio_weights = {stock: 2 * weight / abs_sum for stock, weight in portfolio_weights.items()}\n",
    "            \n",
    "            return portfolio_weights\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error seleccionando portfolio: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "            return {}\n",
    "    \n",
    "    def calculate_portfolio_returns(self, portfolio_weights, date):\n",
    "        \"\"\"\n",
    "        Calcula el retorno del portfolio para una fecha espec√≠fica.\n",
    "        \n",
    "        Args:\n",
    "            portfolio_weights: Diccionario con pesos del portfolio\n",
    "            date: Fecha para calcular el retorno\n",
    "            \n",
    "        Returns:\n",
    "            float: Retorno del portfolio\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not portfolio_weights or date not in self.stock_data['returns'].index:\n",
    "                return 0.0\n",
    "            \n",
    "            # Obtener retornos para la fecha\n",
    "            date_returns = self.stock_data['returns'].loc[date]\n",
    "            \n",
    "            # Calcular retorno ponderado\n",
    "            portfolio_return = 0.0\n",
    "            for stock, weight in portfolio_weights.items():\n",
    "                if stock in date_returns.index and not pd.isna(date_returns[stock]):\n",
    "                    portfolio_return += weight * date_returns[stock]\n",
    "            \n",
    "            return portfolio_return\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando retorno del portfolio: {str(e)}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def run_backtest(self, start_date=None, end_date=None):\n",
    "        \"\"\"\n",
    "        Ejecuta un backtest de la estrategia.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Fecha de inicio del backtest (None = usar start_date de la clase)\n",
    "            end_date: Fecha de fin del backtest (None = usar end_date de la clase)\n",
    "            \n",
    "        Returns:\n",
    "            pd.Series: Serie con valores del portfolio\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Usar fechas predeterminadas si no se especifican\n",
    "            if start_date is None:\n",
    "                start_date = self.start_date\n",
    "            if end_date is None:\n",
    "                end_date = self.end_date\n",
    "            \n",
    "            # Asegurarse de que los datos est√©n cargados y procesados\n",
    "            if self.stock_data is None:\n",
    "                self.load_data()\n",
    "            \n",
    "            if not self.factor_data:\n",
    "                self.calculate_factors()\n",
    "            \n",
    "            if self.regime_history is None:\n",
    "                self.calculate_regime_history()\n",
    "            \n",
    "            if not self.factor_performance:\n",
    "                self.calculate_factor_performance()\n",
    "            \n",
    "            # Optimizar pesos de factores\n",
    "            self.optimize_factor_weights(start_date, end_date)\n",
    "            \n",
    "            # Filtrar fechas para el backtest\n",
    "            backtest_dates = self.stock_data['returns'].index[\n",
    "                (self.stock_data['returns'].index >= start_date) & \n",
    "                (self.stock_data['returns'].index <= end_date)\n",
    "            ]\n",
    "            \n",
    "            # Inicializar variables para el backtest\n",
    "            portfolio_values = pd.Series(100.0, index=[backtest_dates[0]])\n",
    "            current_portfolio = {}\n",
    "            last_rebalance_date = backtest_dates[0]\n",
    "            \n",
    "            # Ejecutar backtest\n",
    "            for i, date in enumerate(backtest_dates[1:], 1):\n",
    "                # Verificar si es necesario rebalancear\n",
    "                days_since_rebalance = len(self.stock_data['returns'].index[\n",
    "                    (self.stock_data['returns'].index > last_rebalance_date) & \n",
    "                    (self.stock_data['returns'].index <= date)\n",
    "                ])\n",
    "                \n",
    "                # Rebalancear cada rebalance_freq d√≠as o si es el primer d√≠a\n",
    "                if days_since_rebalance >= self.rebalance_freq or not current_portfolio:\n",
    "                    # Seleccionar nuevo portfolio\n",
    "                    current_portfolio = self.select_portfolio(date)\n",
    "                    last_rebalance_date = date\n",
    "                \n",
    "                # Calcular retorno del portfolio\n",
    "                daily_return = self.calculate_portfolio_returns(current_portfolio, date)\n",
    "                \n",
    "                # Actualizar valor del portfolio\n",
    "                portfolio_values[date] = portfolio_values.iloc[-1] * (1 + daily_return)\n",
    "            \n",
    "            # Guardar resultados del backtest\n",
    "            portfolio_values.to_csv('./artifacts/results/data/backtest_results.csv')\n",
    "            \n",
    "            # Calcular m√©tricas de rendimiento\n",
    "            returns = portfolio_values.pct_change().dropna()\n",
    "            \n",
    "            annual_return = returns.mean() * 252\n",
    "            annual_vol = returns.std() * np.sqrt(252)\n",
    "            sharpe_ratio = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "            \n",
    "            # Calcular drawdown\n",
    "            drawdown = (portfolio_values / portfolio_values.cummax()) - 1\n",
    "            max_drawdown = drawdown.min()\n",
    "            \n",
    "            # Calcular retorno acumulado\n",
    "            cumulative_return = (portfolio_values.iloc[-1] / portfolio_values.iloc[0]) - 1\n",
    "            \n",
    "            # Guardar m√©tricas\n",
    "            metrics = {\n",
    "                'Annual Return': annual_return,\n",
    "                'Annual Volatility': annual_vol,\n",
    "                'Sharpe Ratio': sharpe_ratio,\n",
    "                'Max Drawdown': max_drawdown,\n",
    "                'Cumulative Return': cumulative_return\n",
    "            }\n",
    "            \n",
    "            pd.Series(metrics).to_csv('./artifacts/results/data/backtest_metrics.csv')\n",
    "            \n",
    "            # Visualizar resultados\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(portfolio_values.index, portfolio_values.values)\n",
    "            plt.title('Backtest: Valor del Portfolio')\n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('Valor')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/backtest_performance.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # Visualizar drawdown\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.fill_between(drawdown.index, drawdown.values, 0, color='red', alpha=0.3)\n",
    "            plt.title('Backtest: Drawdown')\n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('Drawdown')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/backtest_drawdown.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Backtest completado. Sharpe Ratio: {sharpe_ratio:.2f}, Max Drawdown: {max_drawdown:.2%}\")\n",
    "            \n",
    "            return portfolio_values\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error ejecutando backtest: {str(e)}\")\n",
    "            import traceback\n",
    "            logging.error(traceback.format_exc())\n",
    "\n",
    "\n",
    "# Funci√≥n principal para ejecutar la estrategia\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Iniciando estrategia de factores adaptativos market-neutral...\")\n",
    "        \n",
    "        # Crear instancia de la estrategia\n",
    "        strategy = AdaptiveFactorStrategy(\n",
    "            start_date='2021-01-01',\n",
    "            end_date='2024-01-01',\n",
    "            lookback_period=30,\n",
    "            rebalance_freq=5\n",
    "        )\n",
    "        \n",
    "        # Cargar datos\n",
    "        print(\"Cargando datos...\")\n",
    "        strategy.load_data()\n",
    "        \n",
    "        # Calcular factores\n",
    "        print(\"Calculando factores...\")\n",
    "        strategy.calculate_factors()\n",
    "        \n",
    "        # Calcular historial de reg√≠menes\n",
    "        print(\"Identificando reg√≠menes de mercado...\")\n",
    "        strategy.calculate_regime_history()\n",
    "        \n",
    "        # Calcular rendimiento de factores\n",
    "        print(\"Analizando rendimiento de factores...\")\n",
    "        strategy.calculate_factor_performance()\n",
    "        \n",
    "        # Ejecutar backtest\n",
    "        print(\"Ejecutando backtest...\")\n",
    "        strategy.run_backtest()\n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"Estrategia completada con √©xito. Resultados guardados en ./artifacts/results/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la ejecuci√≥n principal: {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        print(f\"Error: {str(e)}. Ver detalles en ./artifacts/errors.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e477a5-8f23-477f-9923-9b5ce8c46530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be5f40-e505-4cb7-83da-106a4566cd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
