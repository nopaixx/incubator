{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df43ef3-1dd6-47d9-904a-04027decd99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando estrategia de momentum multi-horizonte...\n",
      "\n",
      "=== Ejecutando Backtest ===\n",
      "Iniciando backtest...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "Calculando características...\n",
      "Detectando regímenes de mercado...\n",
      "Generando señales...\n",
      "Ajustando señales por autocorrelación...\n",
      "Combinando señales...\n",
      "Construyendo portafolios...\n",
      "Calculando retornos...\n",
      "Calculando métricas de rendimiento...\n",
      "Generando gráficos...\n",
      "Backtest completado.\n",
      "\n",
      "Métricas de rendimiento del backtest:\n",
      "annualized_return: 0.5104\n",
      "annualized_volatility: 0.3757\n",
      "sharpe_ratio: 1.3053\n",
      "max_drawdown: -0.3016\n",
      "win_rate: 0.5359\n",
      "information_ratio: 1.3606\n",
      "\n",
      "=== Ejecutando Validación Walk-Forward ===\n",
      "Iniciando validación walk-forward...\n",
      "Entrenando: 2022-04-19 a 2022-12-27\n",
      "Probando: 2022-12-27 a 2023-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fad80338710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angel/.cache/pypoetry/virtualenvs/incubator-tSevgaFs-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fad80338710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angel/.cache/pypoetry/virtualenvs/incubator-tSevgaFs-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fad80338710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angel/.cache/pypoetry/virtualenvs/incubator-tSevgaFs-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fad80338710>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angel/.cache/pypoetry/virtualenvs/incubator-tSevgaFs-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Crear directorios para resultados\n",
    "os.makedirs('./artifacts/results', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/figures', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/data', exist_ok=True)\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    filename='./artifacts/errors.txt',\n",
    "    level=logging.ERROR,\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Obtiene la lista de tickers del S&P 500 desde Wikipedia.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con tickers como claves y sectores como valores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "        tables = pd.read_html(url)\n",
    "        df = tables[0]\n",
    "        \n",
    "        # Crear diccionario de ticker -> sector\n",
    "        ticker_sector_dict = dict(zip(df['Symbol'], df['GICS Sector']))\n",
    "        \n",
    "        # Limpiar tickers (algunos tienen puntos que yfinance no maneja bien)\n",
    "        ticker_sector_dict = {ticker.replace('.', '-'): sector \n",
    "                             for ticker, sector in ticker_sector_dict.items()}\n",
    "        \n",
    "        return ticker_sector_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error obteniendo tickers del S&P 500: {str(e)}\")\n",
    "        # Devolver un diccionario vacío en caso de error\n",
    "        return {}\n",
    "\n",
    "def download_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Descarga datos históricos para los tickers especificados.\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): Lista de tickers a descargar\n",
    "        start_date (str): Fecha de inicio en formato 'YYYY-MM-DD'\n",
    "        end_date (str): Fecha de fin en formato 'YYYY-MM-DD'\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (precios, volumen)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Añadir un margen de tiempo para calcular características que requieren datos históricos\n",
    "        extended_start = (pd.to_datetime(start_date) - pd.Timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Descargar datos\n",
    "        data = yf.download(tickers, start=extended_start, end=end_date, progress=False)\n",
    "        \n",
    "        # Extraer precios de cierre y volumen\n",
    "        prices = data['Close']\n",
    "        volume = data['Volume']\n",
    "        \n",
    "        # Verificar si hay datos\n",
    "        if prices.empty or volume.empty:\n",
    "            raise ValueError(\"No se pudieron obtener datos para los tickers especificados\")\n",
    "        \n",
    "        # Eliminar columnas con más del 30% de valores NaN\n",
    "        valid_columns = prices.columns[prices.isna().mean() < 0.3]\n",
    "        prices = prices[valid_columns]\n",
    "        volume = volume[valid_columns]\n",
    "        \n",
    "        # Llenar valores NaN con el último valor disponible\n",
    "        prices = prices.fillna(method='ffill')\n",
    "        volume = volume.fillna(method='ffill')\n",
    "        \n",
    "        # Filtrar para el período solicitado\n",
    "        prices = prices.loc[start_date:end_date]\n",
    "        volume = volume.loc[start_date:end_date]\n",
    "        \n",
    "        return prices, volume\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error descargando datos: {str(e)}\")\n",
    "        # Devolver DataFrames vacíos en caso de error\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def calculate_returns(prices, periods):\n",
    "    \"\"\"\n",
    "    Calcula los retornos para diferentes períodos de tiempo.\n",
    "    \n",
    "    Args:\n",
    "        prices (DataFrame): DataFrame con precios de cierre\n",
    "        periods (dict): Diccionario con nombres de períodos y número de días\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con retornos para cada período\n",
    "    \"\"\"\n",
    "    try:\n",
    "        returns = {}\n",
    "        \n",
    "        for period_name, days in periods.items():\n",
    "            # Calcular retornos para el período especificado\n",
    "            period_returns = prices.pct_change(periods=days).shift(1)\n",
    "            returns[period_name] = period_returns\n",
    "        \n",
    "        return returns\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculando retornos: {str(e)}\")\n",
    "        # Devolver un diccionario vacío en caso de error\n",
    "        return {}\n",
    "\n",
    "def calculate_features(prices, volume, returns):\n",
    "    \"\"\"\n",
    "    Calcula características para cada ticker en cada fecha.\n",
    "    \n",
    "    Args:\n",
    "        prices (DataFrame): DataFrame con precios de cierre\n",
    "        volume (DataFrame): DataFrame con volumen\n",
    "        returns (dict): Diccionario con retornos para diferentes períodos\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con características\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcular retornos diarios para volatilidad\n",
    "        daily_returns = prices.pct_change()\n",
    "        \n",
    "        # Calcular volatilidad (ventana de 21 días)\n",
    "        volatility = daily_returns.rolling(window=21).std() * np.sqrt(252)\n",
    "        \n",
    "        # Calcular cambio de volumen (21 días)\n",
    "        volume_change = volume.pct_change(periods=21)\n",
    "        \n",
    "        # Calcular volumen promedio (21 días)\n",
    "        avg_volume = volume.rolling(window=21).mean()\n",
    "        \n",
    "        # Calcular autocorrelación (21 días)\n",
    "        autocorr = pd.DataFrame(index=prices.index, columns=prices.columns)\n",
    "        \n",
    "        # Necesitamos al menos 22 días de datos para calcular autocorrelación\n",
    "        min_required_days = 22\n",
    "        if len(daily_returns) >= min_required_days:\n",
    "            for ticker in prices.columns:\n",
    "                for i in range(min_required_days, len(daily_returns)):\n",
    "                    window = daily_returns.iloc[i-21:i][ticker].dropna()\n",
    "                    if len(window) > 5:  # Necesitamos al menos algunos puntos para la autocorrelación\n",
    "                        try:\n",
    "                            autocorr.iloc[i][ticker] = window.autocorr(lag=1)\n",
    "                        except:\n",
    "                            autocorr.iloc[i][ticker] = 0\n",
    "        \n",
    "        # Asegurarse de que tenemos suficientes datos\n",
    "        valid_dates = prices.index[21:]\n",
    "        \n",
    "        # Crear lista para almacenar características\n",
    "        features_list = []\n",
    "        \n",
    "        # Para cada fecha después de tener suficientes datos\n",
    "        for date in valid_dates:\n",
    "            # Para cada ticker\n",
    "            for ticker in prices.columns:\n",
    "                # Verificar si tenemos datos para este ticker en esta fecha\n",
    "                if pd.isna(prices.loc[date, ticker]):\n",
    "                    continue\n",
    "                \n",
    "                # Extraer características para este ticker en esta fecha\n",
    "                features_dict = {\n",
    "                    'date': date,\n",
    "                    'ticker': ticker,\n",
    "                    'momentum_1m': returns['1M'].loc[date, ticker] if not pd.isna(returns['1M'].loc[date, ticker]) else 0,\n",
    "                    'momentum_3m': returns['3M'].loc[date, ticker] if not pd.isna(returns['3M'].loc[date, ticker]) else 0,\n",
    "                    'momentum_6m': returns['6M'].loc[date, ticker] if not pd.isna(returns['6M'].loc[date, ticker]) else 0,\n",
    "                    'momentum_12m': returns['12M'].loc[date, ticker] if not pd.isna(returns['12M'].loc[date, ticker]) else 0,\n",
    "                    'volatility': volatility.loc[date, ticker] if not pd.isna(volatility.loc[date, ticker]) else np.nan,\n",
    "                    'avg_volume': avg_volume.loc[date, ticker] if not pd.isna(avg_volume.loc[date, ticker]) else np.nan,\n",
    "                    'volume_change': volume_change.loc[date, ticker] if not pd.isna(volume_change.loc[date, ticker]) else 0,\n",
    "                    'autocorr': autocorr.loc[date, ticker] if not pd.isna(autocorr.loc[date, ticker]) else 0\n",
    "                }\n",
    "                \n",
    "                features_list.append(features_dict)\n",
    "        \n",
    "        # Crear DataFrame con características\n",
    "        features_df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Manejar valores NaN\n",
    "        features_df = features_df.fillna(0)\n",
    "        \n",
    "        return features_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculando características: {str(e)}\")\n",
    "        # Devolver un DataFrame vacío en caso de error\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def detect_market_regimes(prices, n_regimes=3):\n",
    "    \"\"\"\n",
    "    Detecta regímenes de mercado utilizando clustering.\n",
    "    \n",
    "    Args:\n",
    "        prices (DataFrame): DataFrame con precios de cierre\n",
    "        n_regimes (int): Número de regímenes a detectar\n",
    "        \n",
    "    Returns:\n",
    "        Series: Serie con regímenes para cada fecha\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcular retornos del mercado (promedio de todos los activos)\n",
    "        market_returns = prices.pct_change().mean(axis=1).dropna()\n",
    "        \n",
    "        # Verificar si hay suficientes datos\n",
    "        if len(market_returns) < 42:  # Necesitamos al menos 42 días para calcular volatilidad\n",
    "            logging.warning(\"Datos insuficientes para detectar regímenes. Usando régimen por defecto.\")\n",
    "            return pd.Series(0, index=prices.index)\n",
    "        \n",
    "        # Calcular volatilidad rodante (21 días)\n",
    "        rolling_vol = market_returns.rolling(window=21).std().dropna()\n",
    "        \n",
    "        # Crear características para el modelo\n",
    "        features = pd.DataFrame({\n",
    "            'returns': market_returns[rolling_vol.index],\n",
    "            'volatility': rolling_vol\n",
    "        })\n",
    "        \n",
    "        # Normalizar características\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        \n",
    "        # Aplicar K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_regimes, random_state=42)\n",
    "        regimes = kmeans.fit_predict(features_scaled)\n",
    "        \n",
    "        # Crear Serie con regímenes\n",
    "        regime_series = pd.Series(regimes, index=features.index)\n",
    "        \n",
    "        # Propagar regímenes a todas las fechas\n",
    "        full_regime_series = pd.Series(index=prices.index)\n",
    "        \n",
    "        # Para cada fecha en el índice de precios\n",
    "        for date in prices.index:\n",
    "            # Si la fecha está en el índice de regímenes, usar ese régimen\n",
    "            if date in regime_series.index:\n",
    "                full_regime_series[date] = regime_series[date]\n",
    "            # Si no, usar el último régimen disponible\n",
    "            elif date > regime_series.index[0]:\n",
    "                # Encontrar la fecha más reciente en el índice de regímenes\n",
    "                last_date = regime_series.index[regime_series.index < date][-1]\n",
    "                full_regime_series[date] = regime_series[last_date]\n",
    "            # Si la fecha es anterior al primer régimen, usar el primer régimen\n",
    "            else:\n",
    "                full_regime_series[date] = regime_series.iloc[0]\n",
    "        \n",
    "        return full_regime_series\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error detectando regímenes de mercado: {str(e)}\")\n",
    "        # Devolver una serie con régimen por defecto en caso de error\n",
    "        return pd.Series(0, index=prices.index)\n",
    "\n",
    "def generate_signals(features, market_regimes):\n",
    "    \"\"\"\n",
    "    Genera señales de trading basadas en características y regímenes de mercado.\n",
    "    \n",
    "    Args:\n",
    "        features (DataFrame): DataFrame con características\n",
    "        market_regimes (Series): Serie con regímenes de mercado\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con señales para cada ticker en cada fecha\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear DataFrame para almacenar señales\n",
    "        signals = pd.DataFrame()\n",
    "        \n",
    "        # Obtener fechas únicas\n",
    "        dates = features['date'].unique()\n",
    "        \n",
    "        # Para cada fecha\n",
    "        for date in dates:\n",
    "            # Obtener características para esta fecha\n",
    "            date_features = features[features['date'] == date]\n",
    "            \n",
    "            # Obtener régimen de mercado para esta fecha\n",
    "            regime = market_regimes.get(date, 0)  # Usar régimen 0 por defecto si no hay dato\n",
    "            \n",
    "            # Calcular señales según el régimen\n",
    "            if regime == 0:  # Régimen de baja volatilidad\n",
    "                # En régimen de baja volatilidad, dar más peso a momentum de largo plazo\n",
    "                momentum_signal = (\n",
    "                    0.1 * date_features['momentum_1m'] +\n",
    "                    0.2 * date_features['momentum_3m'] +\n",
    "                    0.3 * date_features['momentum_6m'] +\n",
    "                    0.4 * date_features['momentum_12m']\n",
    "                )\n",
    "            elif regime == 1:  # Régimen de volatilidad media\n",
    "                # En régimen de volatilidad media, equilibrar pesos\n",
    "                momentum_signal = (\n",
    "                    0.25 * date_features['momentum_1m'] +\n",
    "                    0.25 * date_features['momentum_3m'] +\n",
    "                    0.25 * date_features['momentum_6m'] +\n",
    "                    0.25 * date_features['momentum_12m']\n",
    "                )\n",
    "            else:  # Régimen de alta volatilidad\n",
    "                # En régimen de alta volatilidad, dar más peso a momentum de corto plazo\n",
    "                momentum_signal = (\n",
    "                    0.4 * date_features['momentum_1m'] +\n",
    "                    0.3 * date_features['momentum_3m'] +\n",
    "                    0.2 * date_features['momentum_6m'] +\n",
    "                    0.1 * date_features['momentum_12m']\n",
    "                )\n",
    "            \n",
    "            # Ajustar señales por volatilidad (penalizar alta volatilidad)\n",
    "            vol_adjustment = 1 / (1 + date_features['volatility'])\n",
    "            \n",
    "            # Ajustar señales por volumen (favorecer alto volumen y cambios positivos)\n",
    "            volume_adjustment = (\n",
    "                date_features['avg_volume'] / date_features['avg_volume'].mean() *\n",
    "                (1 + date_features['volume_change'])\n",
    "            )\n",
    "            volume_adjustment = volume_adjustment / volume_adjustment.mean()  # Normalizar\n",
    "            \n",
    "            # Combinar señales\n",
    "            combined_signal = momentum_signal * vol_adjustment * volume_adjustment\n",
    "            \n",
    "            # Crear DataFrame con señales para esta fecha\n",
    "            date_signals = pd.DataFrame({\n",
    "                'date': date,\n",
    "                'ticker': date_features['ticker'],\n",
    "                'signal': combined_signal,\n",
    "                'autocorr': date_features['autocorr'],\n",
    "                'regime': regime\n",
    "            })\n",
    "            \n",
    "            # Añadir a DataFrame de señales\n",
    "            signals = pd.concat([signals, date_signals], ignore_index=True)\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generando señales: {str(e)}\")\n",
    "        # Devolver un DataFrame vacío en caso de error\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def adjust_for_autocorrelation(signals):\n",
    "    \"\"\"\n",
    "    Ajusta las señales basándose en la autocorrelación de los retornos.\n",
    "    \n",
    "    Args:\n",
    "        signals (DataFrame): DataFrame con señales\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con señales ajustadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear copia para no modificar el original\n",
    "        adjusted_signals = signals.copy()\n",
    "        \n",
    "        # Para cada fecha\n",
    "        for date in adjusted_signals['date'].unique():\n",
    "            # Obtener señales para esta fecha\n",
    "            date_signals = adjusted_signals[adjusted_signals['date'] == date]\n",
    "            \n",
    "            # Para cada ticker\n",
    "            for idx, row in date_signals.iterrows():\n",
    "                # Obtener autocorrelación\n",
    "                autocorr = row['autocorr']\n",
    "                \n",
    "                # Ajustar señal según autocorrelación\n",
    "                if not pd.isna(autocorr):\n",
    "                    # Si autocorrelación es positiva, reducir la señal\n",
    "                    if autocorr > 0:\n",
    "                        adjustment_factor = 1 / (1 + 2 * autocorr)\n",
    "                    # Si autocorrelación es negativa, aumentar la señal\n",
    "                    else:\n",
    "                        adjustment_factor = 1 - 2 * autocorr\n",
    "                    \n",
    "                    # Aplicar ajuste\n",
    "                    adjusted_signals.loc[idx, 'signal'] *= adjustment_factor\n",
    "        \n",
    "        return adjusted_signals\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error ajustando por autocorrelación: {str(e)}\")\n",
    "        # Devolver señales sin ajustar en caso de error\n",
    "        return signals\n",
    "\n",
    "def combine_signals(signals, lookback_window=63):\n",
    "    \"\"\"\n",
    "    Combina señales utilizando pesos adaptativos basados en rendimiento reciente.\n",
    "    \n",
    "    Args:\n",
    "        signals (DataFrame): DataFrame con señales\n",
    "        lookback_window (int): Ventana para evaluar rendimiento de señales\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con señales combinadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear copia para no modificar el original\n",
    "        combined_signals = signals.copy()\n",
    "        \n",
    "        # Obtener fechas únicas ordenadas\n",
    "        dates = sorted(combined_signals['date'].unique())\n",
    "        \n",
    "        # Si no hay suficientes fechas, devolver señales sin combinar\n",
    "        if len(dates) <= lookback_window:\n",
    "            return combined_signals\n",
    "        \n",
    "        # Para cada fecha después de la ventana de lookback\n",
    "        for i in range(lookback_window, len(dates)):\n",
    "            current_date = dates[i]\n",
    "            \n",
    "            # Obtener fechas en la ventana de lookback\n",
    "            lookback_dates = dates[i-lookback_window:i]\n",
    "            \n",
    "            # Obtener señales para la fecha actual\n",
    "            current_signals = combined_signals[combined_signals['date'] == current_date]\n",
    "            \n",
    "            # Para cada ticker en las señales actuales\n",
    "            for ticker in current_signals['ticker'].unique():\n",
    "                # Obtener señales históricas para este ticker\n",
    "                ticker_history = combined_signals[\n",
    "                    (combined_signals['ticker'] == ticker) &\n",
    "                    (combined_signals['date'].isin(lookback_dates))\n",
    "                ]\n",
    "                \n",
    "                # Si no hay suficiente historia, continuar con el siguiente ticker\n",
    "                if len(ticker_history) < lookback_window / 2:\n",
    "                    continue\n",
    "                \n",
    "                # Calcular correlación entre señal y régimen\n",
    "                signal_regime_corr = np.corrcoef(\n",
    "                    ticker_history['signal'],\n",
    "                    ticker_history['regime']\n",
    "                )[0, 1]\n",
    "                \n",
    "                # Ajustar señal según correlación con régimen\n",
    "                if not pd.isna(signal_regime_corr):\n",
    "                    # Obtener índice de la señal actual\n",
    "                    idx = combined_signals[\n",
    "                        (combined_signals['date'] == current_date) &\n",
    "                        (combined_signals['ticker'] == ticker)\n",
    "                    ].index\n",
    "                    \n",
    "                    # Si correlación es positiva, aumentar señal en regímenes altos\n",
    "                    if signal_regime_corr > 0:\n",
    "                        regime_factor = 1 + 0.2 * current_signals.loc[\n",
    "                            current_signals['ticker'] == ticker, 'regime'\n",
    "                        ].values[0]\n",
    "                    # Si correlación es negativa, reducir señal en regímenes altos\n",
    "                    else:\n",
    "                        regime_factor = 1 - 0.2 * current_signals.loc[\n",
    "                            current_signals['ticker'] == ticker, 'regime'\n",
    "                        ].values[0]\n",
    "                    \n",
    "                    # Aplicar ajuste\n",
    "                    combined_signals.loc[idx, 'signal'] *= regime_factor\n",
    "        \n",
    "        return combined_signals\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error combinando señales: {str(e)}\")\n",
    "        # Devolver señales sin combinar en caso de error\n",
    "        return signals\n",
    "\n",
    "def construct_portfolio(signals, sectors, date, top_pct=0.1, max_sector_exposure=0.25):\n",
    "    \"\"\"\n",
    "    Construye un portafolio basado en señales para una fecha específica.\n",
    "    \n",
    "    Args:\n",
    "        signals (DataFrame): DataFrame con señales\n",
    "        sectors (dict): Diccionario con sectores para cada ticker\n",
    "        date (datetime): Fecha para la cual construir el portafolio\n",
    "        top_pct (float): Porcentaje de tickers con mejores señales a incluir\n",
    "        max_sector_exposure (float): Exposición máxima por sector\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con pesos para cada ticker\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener señales para la fecha especificada\n",
    "        date_signals = signals[signals['date'] == date].copy()\n",
    "        \n",
    "        # Si no hay señales para esta fecha, devolver diccionario vacío\n",
    "        if date_signals.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Añadir sector a cada ticker\n",
    "        date_signals['sector'] = date_signals['ticker'].map(lambda x: sectors.get(x, 'Unknown'))\n",
    "        \n",
    "        # Ordenar por señal (de mayor a menor)\n",
    "        date_signals = date_signals.sort_values('signal', ascending=False)\n",
    "        \n",
    "        # Seleccionar top_pct% de tickers\n",
    "        n_tickers = int(len(date_signals) * top_pct)\n",
    "        top_tickers = date_signals.head(n_tickers)\n",
    "        \n",
    "        # Calcular exposición por sector\n",
    "        sector_exposure = top_tickers.groupby('sector').size() / n_tickers\n",
    "        \n",
    "        # Ajustar pesos para limitar exposición por sector\n",
    "        weights = {}\n",
    "        \n",
    "        # Para cada ticker en top_tickers\n",
    "        for _, row in top_tickers.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            sector = row['sector']\n",
    "            \n",
    "            # Si la exposición del sector excede el máximo, reducir peso\n",
    "            if sector_exposure[sector] > max_sector_exposure:\n",
    "                weight = row['signal'] * (max_sector_exposure / sector_exposure[sector])\n",
    "            else:\n",
    "                weight = row['signal']\n",
    "            \n",
    "            weights[ticker] = weight\n",
    "        \n",
    "        # Normalizar pesos para que sumen 1\n",
    "        total_weight = sum(weights.values())\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            weights = {ticker: weight / total_weight for ticker, weight in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error construyendo portafolio para {date}: {str(e)}\")\n",
    "        # Devolver diccionario vacío en caso de error\n",
    "        return {}\n",
    "\n",
    "def calculate_portfolio_returns(prices, portfolio_weights, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Calcula los retornos del portafolio.\n",
    "    \n",
    "    Args:\n",
    "        prices (DataFrame): DataFrame con precios de cierre\n",
    "        portfolio_weights (dict): Diccionario con pesos para cada fecha\n",
    "        start_date (datetime): Fecha de inicio\n",
    "        end_date (datetime): Fecha de fin\n",
    "        \n",
    "    Returns:\n",
    "        Series: Serie con retornos del portafolio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear serie para almacenar retornos\n",
    "        strategy_returns = pd.Series(index=pd.date_range(start=start_date, end=end_date, freq='B'))\n",
    "        \n",
    "        # Filtrar fechas de trading disponibles\n",
    "        trading_dates = prices.index\n",
    "        trading_dates = trading_dates[(trading_dates >= start_date) & (trading_dates <= end_date)]\n",
    "        \n",
    "        if len(trading_dates) < 2:\n",
    "            logging.warning(\"Insuficientes fechas de trading para calcular retornos\")\n",
    "            return pd.Series(index=pd.date_range(start=start_date, end=end_date, freq='B'))\n",
    "        \n",
    "        # Verificar si hay pesos para alguna fecha\n",
    "        valid_dates = [d for d in trading_dates if d in portfolio_weights]\n",
    "        if not valid_dates:\n",
    "            logging.warning(\"No hay pesos de portafolio para ninguna fecha en el período\")\n",
    "            return pd.Series(index=pd.date_range(start=start_date, end=end_date, freq='B'))\n",
    "        \n",
    "        # Calcular retornos diarios\n",
    "        daily_returns = prices.pct_change()\n",
    "        \n",
    "        # Inicializar pesos actuales\n",
    "        current_weights = None\n",
    "        last_rebalance_date = None\n",
    "        \n",
    "        # Para cada fecha de trading\n",
    "        for i in range(1, len(trading_dates)):\n",
    "            current_date = trading_dates[i]\n",
    "            previous_date = trading_dates[i-1]\n",
    "            \n",
    "            # Si es fecha de rebalanceo o primera fecha, actualizar pesos\n",
    "            if current_date in portfolio_weights:\n",
    "                current_weights = portfolio_weights[current_date]\n",
    "                last_rebalance_date = current_date\n",
    "            \n",
    "            # Si no hay pesos actuales, continuar\n",
    "            if current_weights is None:\n",
    "                continue\n",
    "            \n",
    "            # Calcular retorno del portafolio para esta fecha\n",
    "            portfolio_return = 0\n",
    "            \n",
    "            for ticker, weight in current_weights.items():\n",
    "                # Verificar si el ticker está en los datos\n",
    "                if ticker in daily_returns.columns:\n",
    "                    # Obtener retorno para este ticker\n",
    "                    ticker_return = daily_returns.loc[current_date, ticker]\n",
    "                    \n",
    "                    # Si no es NaN, añadir al retorno del portafolio\n",
    "                    if not pd.isna(ticker_return):\n",
    "                        portfolio_return += weight * ticker_return\n",
    "            \n",
    "            # Guardar retorno del portafolio\n",
    "            strategy_returns[current_date] = portfolio_return\n",
    "        \n",
    "        # Eliminar NaN\n",
    "        strategy_returns = strategy_returns.dropna()\n",
    "        \n",
    "        return strategy_returns\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculando retornos del portafolio: {str(e)}\")\n",
    "        # Devolver serie vacía en caso de error\n",
    "        return pd.Series()\n",
    "\n",
    "def calculate_performance_metrics(returns, benchmark_returns=None):\n",
    "    \"\"\"\n",
    "    Calcula métricas de rendimiento para una serie de retornos.\n",
    "    \n",
    "    Args:\n",
    "        returns (Series): Serie con retornos\n",
    "        benchmark_returns (Series, optional): Serie con retornos del benchmark\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con métricas de rendimiento\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar si hay retornos\n",
    "        if returns is None or len(returns) == 0:\n",
    "            return {\n",
    "                'annualized_return': 0,\n",
    "                'annualized_volatility': 0,\n",
    "                'sharpe_ratio': 0,\n",
    "                'max_drawdown': 0,\n",
    "                'win_rate': 0,\n",
    "                'information_ratio': 0\n",
    "            }\n",
    "        \n",
    "        # Asegurarnos de que trabajamos con una Serie unidimensional\n",
    "        if isinstance(returns, pd.DataFrame):\n",
    "            if returns.shape[1] == 1:\n",
    "                returns = returns.iloc[:, 0]\n",
    "            else:\n",
    "                returns = returns.mean(axis=1)  # Promedio si hay múltiples columnas\n",
    "        \n",
    "        # Eliminar NaNs\n",
    "        returns_clean = returns.dropna()\n",
    "        \n",
    "        # Si después de eliminar NaNs no quedan datos, devolver ceros\n",
    "        if len(returns_clean) == 0:\n",
    "            return {\n",
    "                'annualized_return': 0,\n",
    "                'annualized_volatility': 0,\n",
    "                'sharpe_ratio': 0,\n",
    "                'max_drawdown': 0,\n",
    "                'win_rate': 0,\n",
    "                'information_ratio': 0\n",
    "            }\n",
    "        \n",
    "        # Calcular retorno acumulado\n",
    "        cumulative_return = (1 + returns_clean).cumprod() - 1\n",
    "        \n",
    "        # Calcular retorno anualizado\n",
    "        n_years = len(returns_clean) / 252.0\n",
    "        annualized_return = (1 + cumulative_return.iloc[-1]) ** (1 / n_years) - 1\n",
    "        \n",
    "        # Calcular volatilidad anualizada\n",
    "        annualized_volatility = returns_clean.std() * np.sqrt(252)\n",
    "        \n",
    "        # Calcular Sharpe ratio\n",
    "        risk_free_rate = 0.02  # Tasa libre de riesgo (2%)\n",
    "        sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility if annualized_volatility > 0 else 0\n",
    "        \n",
    "        # Calcular máximo drawdown\n",
    "        peak = cumulative_return.cummax()\n",
    "        drawdown = (cumulative_return - peak) / (1 + peak)\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calcular win rate\n",
    "        win_rate = (returns_clean > 0).mean()\n",
    "        \n",
    "        # Calcular Information Ratio si hay benchmark\n",
    "        information_ratio = 0\n",
    "        if benchmark_returns is not None and hasattr(benchmark_returns, '__len__') and len(benchmark_returns) > 0:\n",
    "            # Convertir a Serie unidimensional si es necesario\n",
    "            if isinstance(benchmark_returns, pd.DataFrame):\n",
    "                if benchmark_returns.shape[1] == 1:\n",
    "                    benchmark_returns = benchmark_returns.iloc[:, 0]\n",
    "                else:\n",
    "                    benchmark_returns = benchmark_returns.mean(axis=1)\n",
    "            elif isinstance(benchmark_returns, np.ndarray):\n",
    "                if benchmark_returns.ndim > 1:\n",
    "                    # Si es un array de más de 1 dimensión, aplanarlo\n",
    "                    benchmark_returns = benchmark_returns.flatten()\n",
    "                benchmark_returns = pd.Series(benchmark_returns, index=returns.index[:len(benchmark_returns)])\n",
    "            \n",
    "            # Limpiar benchmark\n",
    "            benchmark_clean = pd.Series(benchmark_returns).dropna()\n",
    "            \n",
    "            if len(benchmark_clean) > 0:\n",
    "                # Intentar alinear índices\n",
    "                try:\n",
    "                    common_dates = returns_clean.index.intersection(benchmark_clean.index)\n",
    "                    if len(common_dates) > 0:\n",
    "                        aligned_returns = returns_clean.loc[common_dates]\n",
    "                        aligned_benchmark = benchmark_clean.loc[common_dates]\n",
    "                        \n",
    "                        # Calcular excess returns\n",
    "                        excess_returns = aligned_returns - aligned_benchmark\n",
    "                        \n",
    "                        # Calcular tracking error\n",
    "                        tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "                        \n",
    "                        # Calcular Information Ratio\n",
    "                        if tracking_error > 0:\n",
    "                            information_ratio = excess_returns.mean() * 252 / tracking_error\n",
    "                except Exception as inner_e:\n",
    "                    logging.error(f\"Error alineando benchmark: {str(inner_e)}\")\n",
    "        \n",
    "        return {\n",
    "            'annualized_return': float(annualized_return),\n",
    "            'annualized_volatility': float(annualized_volatility),\n",
    "            'sharpe_ratio': float(sharpe_ratio),\n",
    "            'max_drawdown': float(max_drawdown),\n",
    "            'win_rate': float(win_rate),\n",
    "            'information_ratio': float(information_ratio)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculando métricas de rendimiento: {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        # Devolver métricas vacías en caso de error\n",
    "        return {\n",
    "            'annualized_return': 0,\n",
    "            'annualized_volatility': 0,\n",
    "            'sharpe_ratio': 0,\n",
    "            'max_drawdown': 0,\n",
    "            'win_rate': 0,\n",
    "            'information_ratio': 0\n",
    "        }\n",
    "def plot_performance(strategy_returns, benchmark_returns=None, title='Strategy Performance'):\n",
    "    \"\"\"\n",
    "    Genera gráfico de rendimiento.\n",
    "    \n",
    "    Args:\n",
    "        strategy_returns (Series): Serie con retornos de la estrategia\n",
    "        benchmark_returns (Series, optional): Serie con retornos del benchmark\n",
    "        title (str): Título del gráfico\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Calcular retorno acumulado\n",
    "        strategy_cumulative = (1 + strategy_returns).cumprod() - 1\n",
    "        \n",
    "        # Graficar retorno acumulado de la estrategia\n",
    "        plt.plot(strategy_cumulative.index, strategy_cumulative.values, label='Strategy')\n",
    "        \n",
    "        # Si hay benchmark, graficar también\n",
    "        if benchmark_returns is not None:\n",
    "            # Alinear fechas\n",
    "            aligned_benchmark = benchmark_returns.reindex(strategy_returns.index)\n",
    "            \n",
    "            # Calcular retorno acumulado del benchmark\n",
    "            benchmark_cumulative = (1 + aligned_benchmark).cumprod() - 1\n",
    "            \n",
    "            # Graficar retorno acumulado del benchmark\n",
    "            plt.plot(benchmark_cumulative.index, benchmark_cumulative.values, label='Benchmark')\n",
    "        \n",
    "        # Añadir título y etiquetas\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Cumulative Return')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Guardar gráfico\n",
    "        plt.savefig(f'./artifacts/results/figures/{title.replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generando gráfico de rendimiento: {str(e)}\")\n",
    "\n",
    "def plot_drawdown(returns, title='Drawdown Analysis'):\n",
    "    \"\"\"\n",
    "    Genera gráfico de drawdown.\n",
    "    \n",
    "    Args:\n",
    "        returns (Series): Serie con retornos\n",
    "        title (str): Título del gráfico\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcular retorno acumulado\n",
    "        cumulative_return = (1 + returns).cumprod() - 1\n",
    "        \n",
    "        # Calcular drawdown\n",
    "        peak = cumulative_return.cummax()\n",
    "        drawdown = (cumulative_return - peak) / (1 + peak)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Graficar drawdown\n",
    "        plt.fill_between(drawdown.index, drawdown.values, 0, color='red', alpha=0.3)\n",
    "        plt.plot(drawdown.index, drawdown.values, color='red', alpha=0.5)\n",
    "        \n",
    "        # Añadir título y etiquetas\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Drawdown')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Guardar gráfico\n",
    "        plt.savefig(f'./artifacts/results/figures/{title.replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generando gráfico de drawdown: {str(e)}\")\n",
    "\n",
    "def plot_regime_performance(returns, regimes, title='Performance by Regime'):\n",
    "    \"\"\"\n",
    "    Genera gráfico de rendimiento por régimen.\n",
    "    \n",
    "    Args:\n",
    "        returns (Series): Serie con retornos\n",
    "        regimes (Series): Serie con regímenes\n",
    "        title (str): Título del gráfico\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Alinear fechas\n",
    "        aligned_regimes = regimes.reindex(returns.index)\n",
    "        \n",
    "        # Crear DataFrame con retornos y regímenes\n",
    "        df = pd.DataFrame({\n",
    "            'returns': returns,\n",
    "            'regime': aligned_regimes\n",
    "        })\n",
    "        \n",
    "        # Calcular retorno promedio por régimen\n",
    "        regime_returns = df.groupby('regime')['returns'].mean() * 252  # Anualizado\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Graficar retorno por régimen\n",
    "        bars = plt.bar(regime_returns.index, regime_returns.values)\n",
    "        \n",
    "        # Colorear barras según régimen\n",
    "        colors = ['green', 'yellow', 'red']\n",
    "        for i, bar in enumerate(bars):\n",
    "            if i < len(colors):\n",
    "                bar.set_color(colors[i])\n",
    "        \n",
    "        # Añadir título y etiquetas\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Regime')\n",
    "        plt.ylabel('Annualized Return')\n",
    "        plt.xticks(regime_returns.index)\n",
    "        plt.grid(True, axis='y')\n",
    "        \n",
    "        # Guardar gráfico\n",
    "        plt.savefig(f'./artifacts/results/figures/{title.replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generando gráfico de rendimiento por régimen: {str(e)}\")\n",
    "\n",
    "def plot_sector_exposure(portfolio_weights, sectors, date, title='Sector Exposure'):\n",
    "    \"\"\"\n",
    "    Genera gráfico de exposición por sector.\n",
    "    \n",
    "    Args:\n",
    "        portfolio_weights (dict): Diccionario con pesos para una fecha\n",
    "        sectors (dict): Diccionario con sectores para cada ticker\n",
    "        date (datetime): Fecha para la cual mostrar exposición\n",
    "        title (str): Título del gráfico\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcular exposición por sector\n",
    "        sector_exposure = {}\n",
    "        \n",
    "        for ticker, weight in portfolio_weights.items():\n",
    "            sector = sectors.get(ticker, 'Unknown')\n",
    "            sector_exposure[sector] = sector_exposure.get(sector, 0) + weight\n",
    "        \n",
    "        # Ordenar sectores por exposición\n",
    "        sorted_sectors = sorted(sector_exposure.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Extraer sectores y exposiciones\n",
    "        sector_names = [s[0] for s in sorted_sectors]\n",
    "        exposures = [s[1] for s in sorted_sectors]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Graficar exposición por sector\n",
    "        bars = plt.barh(sector_names, exposures)\n",
    "        \n",
    "        # Añadir título y etiquetas\n",
    "        plt.title(f'{title} - {date.strftime(\"%Y-%m-%d\")}')\n",
    "        plt.xlabel('Exposure')\n",
    "        plt.ylabel('Sector')\n",
    "        plt.grid(True, axis='x')\n",
    "        \n",
    "        # Guardar gráfico\n",
    "        plt.savefig(f'./artifacts/results/figures/{title.replace(\" \", \"_\")}_{date.strftime(\"%Y%m%d\")}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generando gráfico de exposición por sector: {str(e)}\")\n",
    "\n",
    "def backtest_strategy(tickers, sectors, start_date, end_date, rebalance_freq='M'):\n",
    "    \"\"\"\n",
    "    Realiza un backtest de la estrategia.\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): Lista de tickers\n",
    "        sectors (dict): Diccionario con sectores para cada ticker\n",
    "        start_date (str): Fecha de inicio en formato 'YYYY-MM-DD'\n",
    "        end_date (str): Fecha de fin en formato 'YYYY-MM-DD'\n",
    "        rebalance_freq (str): Frecuencia de rebalanceo ('D', 'W', 'M', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (retornos de la estrategia, retornos del benchmark, métricas)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Iniciando backtest...\")\n",
    "        \n",
    "        # Descargar datos\n",
    "        prices, volume = download_data(tickers, start_date, end_date)\n",
    "        \n",
    "        # Verificar si hay datos\n",
    "        if prices.empty or volume.empty:\n",
    "            raise ValueError(\"No se pudieron obtener datos para los tickers especificados\")\n",
    "        \n",
    "        # Descargar datos del benchmark (S&P 500)\n",
    "        benchmark_data = yf.download('^GSPC', start=start_date, end=end_date, progress=False)\n",
    "        benchmark_returns = benchmark_data['Close'].pct_change().dropna()\n",
    "        \n",
    "        # Calcular retornos para diferentes períodos\n",
    "        periods = {\n",
    "            '1M': 21,\n",
    "            '3M': 63,\n",
    "            '6M': 126,\n",
    "            '12M': 252\n",
    "        }\n",
    "        returns = calculate_returns(prices, periods)\n",
    "        \n",
    "        # Calcular características\n",
    "        print(\"Calculando características...\")\n",
    "        features = calculate_features(prices, volume, returns)\n",
    "        \n",
    "        # Detectar regímenes de mercado\n",
    "        print(\"Detectando regímenes de mercado...\")\n",
    "        market_regimes = detect_market_regimes(prices)\n",
    "        \n",
    "        # Generar señales\n",
    "        print(\"Generando señales...\")\n",
    "        signals = generate_signals(features, market_regimes)\n",
    "        \n",
    "        # Ajustar señales por autocorrelación\n",
    "        print(\"Ajustando señales por autocorrelación...\")\n",
    "        adjusted_signals = adjust_for_autocorrelation(signals)\n",
    "        \n",
    "        # Combinar señales\n",
    "        print(\"Combinando señales...\")\n",
    "        combined_signals = combine_signals(adjusted_signals)\n",
    "        \n",
    "        # Determinar fechas de rebalanceo\n",
    "        rebalance_dates = pd.date_range(start=start_date, end=end_date, freq=rebalance_freq)\n",
    "        rebalance_dates = rebalance_dates[rebalance_dates.isin(prices.index)]\n",
    "        \n",
    "        # Construir portafolios para cada fecha de rebalanceo\n",
    "        print(\"Construyendo portafolios...\")\n",
    "        portfolio_weights = {}\n",
    "        \n",
    "        for date in rebalance_dates:\n",
    "            # Verificar si hay señales para esta fecha\n",
    "            date_signals = combined_signals[combined_signals['date'] == date]\n",
    "            \n",
    "            if not date_signals.empty:\n",
    "                # Construir portafolio\n",
    "                weights = construct_portfolio(combined_signals, sectors, date)\n",
    "                \n",
    "                # Guardar pesos\n",
    "                portfolio_weights[date] = weights\n",
    "        \n",
    "        # Calcular retornos del portafolio\n",
    "        print(\"Calculando retornos...\")\n",
    "        strategy_returns = calculate_portfolio_returns(\n",
    "            prices,\n",
    "            portfolio_weights,\n",
    "            pd.to_datetime(start_date),\n",
    "            pd.to_datetime(end_date)\n",
    "        )\n",
    "        \n",
    "        # Calcular métricas de rendimiento\n",
    "        print(\"Calculando métricas de rendimiento...\")\n",
    "        metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "        \n",
    "        # Generar gráficos\n",
    "        print(\"Generando gráficos...\")\n",
    "        plot_performance(strategy_returns, benchmark_returns, title='Strategy vs Benchmark')\n",
    "        plot_drawdown(strategy_returns, title='Strategy Drawdown')\n",
    "        plot_regime_performance(strategy_returns, market_regimes, title='Performance by Regime')\n",
    "        \n",
    "        # Guardar métricas en CSV\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv('./artifacts/results/data/performance_metrics.csv', index=False)\n",
    "        \n",
    "        # Guardar retornos en CSV\n",
    "        strategy_returns.to_csv('./artifacts/results/data/strategy_returns.csv')\n",
    "        benchmark_returns.to_csv('./artifacts/results/data/benchmark_returns.csv')\n",
    "        \n",
    "        # Guardar exposición sectorial para la última fecha de rebalanceo\n",
    "        if rebalance_dates.size > 0:\n",
    "            last_rebalance = rebalance_dates[-1]\n",
    "            if last_rebalance in portfolio_weights:\n",
    "                plot_sector_exposure(\n",
    "                    portfolio_weights[last_rebalance],\n",
    "                    sectors,\n",
    "                    last_rebalance,\n",
    "                    title='Last Rebalance Sector Exposure'\n",
    "                )\n",
    "        \n",
    "        print(\"Backtest completado.\")\n",
    "        \n",
    "        return strategy_returns, benchmark_returns, metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en backtest: {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        # Devolver valores vacíos en caso de error\n",
    "        return pd.Series(), pd.Series(), {}\n",
    "\n",
    "def walk_forward_validation(tickers, sectors, start_date, end_date, train_window=252, test_window=63):\n",
    "    \"\"\"\n",
    "    Realiza validación walk-forward de la estrategia.\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): Lista de tickers\n",
    "        sectors (dict): Diccionario con sectores para cada ticker\n",
    "        start_date (str): Fecha de inicio en formato 'YYYY-MM-DD'\n",
    "        end_date (str): Fecha de fin en formato 'YYYY-MM-DD'\n",
    "        train_window (int): Tamaño de la ventana de entrenamiento en días\n",
    "        test_window (int): Tamaño de la ventana de prueba en días\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (retornos de la estrategia, retornos del benchmark, métricas)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Iniciando validación walk-forward...\")\n",
    "        \n",
    "        # Convertir fechas a datetime\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "        \n",
    "        # Descargar datos para todo el período\n",
    "        prices, volume = download_data(tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        # Verificar si hay datos\n",
    "        if prices.empty or volume.empty:\n",
    "            raise ValueError(\"No se pudieron obtener datos para los tickers especificados\")\n",
    "        \n",
    "        # Descargar datos del benchmark (S&P 500)\n",
    "        benchmark_data = yf.download('^GSPC', start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'), progress=False)\n",
    "        benchmark_returns = benchmark_data['Close'].pct_change().dropna()\n",
    "        \n",
    "        # Obtener fechas de trading\n",
    "        trading_dates = prices.index\n",
    "        \n",
    "        # Inicializar variables para almacenar resultados\n",
    "        all_strategy_returns = pd.Series()\n",
    "        all_portfolio_weights = {}\n",
    "        \n",
    "        # Para cada ventana de validación\n",
    "        current_start = start_date\n",
    "        \n",
    "        while current_start + pd.Timedelta(days=train_window + test_window) <= end_date:\n",
    "            # Definir ventanas de entrenamiento y prueba\n",
    "            train_end = current_start + pd.Timedelta(days=train_window)\n",
    "            test_end = train_end + pd.Timedelta(days=test_window)\n",
    "            \n",
    "            # Ajustar a fechas de trading disponibles\n",
    "            train_end = trading_dates[trading_dates <= train_end][-1]\n",
    "            test_end = trading_dates[trading_dates <= test_end][-1]\n",
    "            \n",
    "            print(f\"Entrenando: {current_start.strftime('%Y-%m-%d')} a {train_end.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"Probando: {train_end.strftime('%Y-%m-%d')} a {test_end.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Calcular retornos para diferentes períodos\n",
    "            periods = {\n",
    "                '1M': 21,\n",
    "                '3M': 63,\n",
    "                '6M': 126,\n",
    "                '12M': 252\n",
    "            }\n",
    "            returns = calculate_returns(prices, periods)\n",
    "            \n",
    "            # Calcular características para el período de entrenamiento\n",
    "            train_features = calculate_features(\n",
    "                prices.loc[:train_end],\n",
    "                volume.loc[:train_end],\n",
    "                {k: v.loc[:train_end] for k, v in returns.items()}\n",
    "            )\n",
    "            \n",
    "            # Detectar regímenes de mercado para el período de entrenamiento\n",
    "            market_regimes = detect_market_regimes(prices.loc[:train_end])\n",
    "            \n",
    "            # Generar señales para el período de entrenamiento\n",
    "            signals = generate_signals(train_features, market_regimes)\n",
    "            \n",
    "            # Ajustar señales por autocorrelación\n",
    "            adjusted_signals = adjust_for_autocorrelation(signals)\n",
    "            \n",
    "            # Combinar señales\n",
    "            combined_signals = combine_signals(adjusted_signals)\n",
    "            \n",
    "            # Determinar fechas de rebalanceo para el período de prueba\n",
    "            test_dates = trading_dates[(trading_dates > train_end) & (trading_dates <= test_end)]\n",
    "            \n",
    "            # Construir portafolios para cada fecha de prueba\n",
    "            for date in test_dates:\n",
    "                # Obtener último régimen conocido\n",
    "                last_regime = market_regimes.iloc[-1] if not market_regimes.empty else 0\n",
    "                \n",
    "                # Calcular características para esta fecha\n",
    "                date_features = calculate_features(\n",
    "                    prices.loc[:date],\n",
    "                    volume.loc[:date],\n",
    "                    {k: v.loc[:date] for k, v in returns.items()}\n",
    "                )\n",
    "                \n",
    "                # Filtrar características para esta fecha\n",
    "                date_features = date_features[date_features['date'] == date]\n",
    "                \n",
    "                # Si no hay características, continuar con la siguiente fecha\n",
    "                if date_features.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Generar señales para esta fecha\n",
    "                date_signals = pd.DataFrame({\n",
    "                    'date': date,\n",
    "                    'ticker': date_features['ticker'],\n",
    "                    'signal': (\n",
    "                        0.25 * date_features['momentum_1m'] +\n",
    "                        0.25 * date_features['momentum_3m'] +\n",
    "                        0.25 * date_features['momentum_6m'] +\n",
    "                        0.25 * date_features['momentum_12m']\n",
    "                    ),\n",
    "                    'autocorr': date_features['autocorr'],\n",
    "                    'regime': last_regime\n",
    "                })\n",
    "                \n",
    "                # Ajustar señales por autocorrelación\n",
    "                for idx, row in date_signals.iterrows():\n",
    "                    autocorr = row['autocorr']\n",
    "                    if not pd.isna(autocorr) and autocorr != 0:\n",
    "                        if autocorr > 0:\n",
    "                            adjustment_factor = 1 / (1 + 2 * autocorr)\n",
    "                        else:\n",
    "                            adjustment_factor = 1 - 2 * autocorr\n",
    "                        date_signals.loc[idx, 'signal'] *= adjustment_factor\n",
    "                \n",
    "                # Construir portafolio\n",
    "                weights = construct_portfolio(date_signals, sectors, date)\n",
    "                \n",
    "                # Guardar pesos\n",
    "                all_portfolio_weights[date] = weights\n",
    "            \n",
    "            # Calcular retornos del portafolio para el período de prueba\n",
    "            test_returns = calculate_portfolio_returns(\n",
    "                prices,\n",
    "                all_portfolio_weights,\n",
    "                train_end,\n",
    "                test_end\n",
    "            )\n",
    "            \n",
    "            # Añadir a los retornos totales\n",
    "            all_strategy_returns = pd.concat([all_strategy_returns, test_returns])\n",
    "            \n",
    "            # Avanzar a la siguiente ventana\n",
    "            current_start = train_end\n",
    "        \n",
    "        # Calcular métricas de rendimiento\n",
    "        metrics = calculate_performance_metrics(all_strategy_returns, benchmark_returns)\n",
    "        \n",
    "        # Generar gráficos\n",
    "        plot_performance(all_strategy_returns, benchmark_returns, title='Walk-Forward Strategy vs Benchmark')\n",
    "        plot_drawdown(all_strategy_returns, title='Walk-Forward Strategy Drawdown')\n",
    "        \n",
    "        # Guardar métricas en CSV\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        metrics_df.to_csv('./artifacts/results/data/walk_forward_metrics.csv', index=False)\n",
    "        \n",
    "        # Guardar retornos en CSV\n",
    "        all_strategy_returns.to_csv('./artifacts/results/data/walk_forward_returns.csv')\n",
    "        \n",
    "        print(\"Validación walk-forward completada.\")\n",
    "        \n",
    "        return all_strategy_returns, benchmark_returns, metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en validación walk-forward: {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        # Devolver valores vacíos en caso de error\n",
    "        return pd.Series(), pd.Series(), {}\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta la estrategia.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Iniciando estrategia de momentum multi-horizonte...\")\n",
    "        \n",
    "        # Obtener tickers y sectores del S&P 500\n",
    "        sectors = get_sp500_tickers()\n",
    "        tickers = list(sectors.keys())\n",
    "        \n",
    "        # Si hay demasiados tickers, limitar para evitar errores de API\n",
    "        if len(tickers) > 10000:\n",
    "            tickers = tickers[:1000]\n",
    "            sectors = {ticker: sectors[ticker] for ticker in tickers}\n",
    "        \n",
    "        # Definir fechas\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        start_date = (datetime.now() - timedelta(days=3*365)).strftime('%Y-%m-%d')  # 3 años\n",
    "        \n",
    "        # Realizar backtest\n",
    "        print(\"\\n=== Ejecutando Backtest ===\")\n",
    "        strategy_returns, benchmark_returns, metrics = backtest_strategy(\n",
    "            tickers,\n",
    "            sectors,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            rebalance_freq='M'  # Rebalanceo mensual\n",
    "        )\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(\"\\nMétricas de rendimiento del backtest:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Realizar validación walk-forward\n",
    "        print(\"\\n=== Ejecutando Validación Walk-Forward ===\")\n",
    "        wf_returns, wf_benchmark, wf_metrics = walk_forward_validation(\n",
    "            tickers,\n",
    "            sectors,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            train_window=252,  # 1 año de entrenamiento\n",
    "            test_window=63     # 3 meses de prueba\n",
    "        )\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(\"\\nMétricas de rendimiento de la validación walk-forward:\")\n",
    "        for metric, value in wf_metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nEstrategia completada. Resultados guardados en ./artifacts/results/\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en función principal: {str(e)}\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54628685-7286-4000-843e-6353ff7e45dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
