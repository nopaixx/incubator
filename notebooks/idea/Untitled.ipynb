{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d5e8e9-9b61-4e92-8e99-857c00bc00ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando estrategia de ranking adaptativo multifactorial...\n",
      "\n",
      "1. Obteniendo datos de mercado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verificando datos existentes: 100%|███████████| 50/50 [00:00<00:00, 1558.32it/s]\n",
      "Descargando datos de mercado:   0%|                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando datos de mercado: 100%|█████████████| 50/50 [00:12<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de mercado obtenidos para 52 tickers\n",
      "\n",
      "2. Generando características adaptativas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando características:  23%|███▋            | 12/52 [00:00<00:00, 88.68it/s]/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ABNB: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "Generando características:  46%|███████▍        | 24/52 [00:15<00:21,  1.30it/s]/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMD: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ABT: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ADBE: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AES: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para MMM: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AOS: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AFL: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para A: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ACN: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para APD: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ABBV: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AKAM: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "Generando características:  69%|███████████     | 36/52 [00:46<00:25,  1.57s/it]/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ALB: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ALLE: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ARE: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "ERROR:root:Error generando características para AMCR: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ALGN: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para GOOGL: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ALL: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para LNT: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para MO: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para GOOG: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMZN: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AEE: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "Generando características: 100%|████████████████| 52/52 [01:16<00:00,  1.47s/it]\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AEP: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AXP: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AIG: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMP: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMT: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AWK: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AME: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ADI: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMGN: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ANSS: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para APH: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AON: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para APA: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para APO: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para APTV: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ADM: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AAPL: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AMAT: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ACGL: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ANET: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AJG: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para AIZ: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para T: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ^VIX: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ATO: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para ADSK: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/angel/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "ERROR:root:Error generando características para SPY: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 21 and the array at index 1 has size 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características generadas para 52 tickers\n",
      "\n",
      "3. Normalizando características...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizando características:   0%|                      | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ejecutando estrategia: 'dict' object has no attribute 'empty'\n",
      "Error en ejecución principal: 'dict' object has no attribute 'empty'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats, signal, optimize\n",
    "from scipy.fft import fft\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.metrics import information_coefficient\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "# Crear directorios para resultados\n",
    "os.makedirs('./artifacts/results', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/figures', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/data', exist_ok=True)\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    filename='./artifacts/errors.txt',\n",
    "    level=logging.ERROR,\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "class AdaptiveMultifactorRankingSystem:\n",
    "    def __init__(self, start_date='2010-01-01', end_date=None, db_path='./artifacts/results/data/market_data.db'):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema de ranking adaptativo multifactorial\n",
    "        \n",
    "        Args:\n",
    "            start_date: Fecha de inicio para datos históricos\n",
    "            end_date: Fecha de fin para datos históricos (None = hoy)\n",
    "            db_path: Ruta a la base de datos SQLite\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date if end_date else datetime.now().strftime('%Y-%m-%d')\n",
    "        self.db_path = db_path\n",
    "        self.tickers = self._get_sp500_tickers()\n",
    "        self.market_data = {}\n",
    "        self.features = {}\n",
    "        self.rankings = {}\n",
    "        self.portfolio = {}\n",
    "        self.performance = {}\n",
    "        \n",
    "        # Parámetros de la estrategia\n",
    "        self.rebalance_frequency = 5  # días (semanal)\n",
    "        self.recalibration_frequency = 21  # días (mensual)\n",
    "        self.position_limit = 0.03  # 3% máximo por posición\n",
    "        self.min_volume = 500000  # Volumen mínimo diario\n",
    "        self.min_market_cap = 2e9  # Capitalización mínima ($2B)\n",
    "        self.sector_limit = 0.25  # 25% máximo por sector\n",
    "        \n",
    "        # Inicializar base de datos\n",
    "        self._init_database()\n",
    "    \n",
    "    def _get_sp500_tickers(self):\n",
    "        \"\"\"Obtiene los tickers actuales del S&P 500\"\"\"\n",
    "        try:\n",
    "            # En una implementación real, se usaría una fuente point-in-time\n",
    "            # Para simplificar, usamos los componentes actuales\n",
    "            sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "            tables = pd.read_html(sp500_url)\n",
    "            sp500_table = tables[0]\n",
    "            tickers = sp500_table['Symbol'].str.replace('.', '-').tolist()\n",
    "            \n",
    "            # Para este ejemplo, limitamos a 50 tickers para reducir tiempo de ejecución\n",
    "            return tickers[:50]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error obteniendo tickers del S&P 500: {str(e)}\")\n",
    "            # Fallback a algunos tickers principales\n",
    "            return ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "    \n",
    "    def _init_database(self):\n",
    "        \"\"\"Inicializa la base de datos SQLite para almacenar datos históricos\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Crear tabla para datos de precios\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS price_data (\n",
    "                ticker TEXT,\n",
    "                date TEXT,\n",
    "                open REAL,\n",
    "                high REAL,\n",
    "                low REAL,\n",
    "                close REAL,\n",
    "                volume REAL,\n",
    "                PRIMARY KEY (ticker, date)\n",
    "            )\n",
    "            ''')\n",
    "            \n",
    "            # Crear tabla para features calculadas\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS features (\n",
    "                ticker TEXT,\n",
    "                date TEXT,\n",
    "                feature_name TEXT,\n",
    "                value REAL,\n",
    "                PRIMARY KEY (ticker, date, feature_name)\n",
    "            )\n",
    "            ''')\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error inicializando base de datos: {str(e)}\")\n",
    "    \n",
    "    def fetch_market_data(self, force_update=False):\n",
    "        \"\"\"\n",
    "        Obtiene datos de mercado para todos los tickers\n",
    "        \n",
    "        Args:\n",
    "            force_update: Si es True, fuerza la actualización desde la fuente\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            \n",
    "            # Verificar datos existentes en la base de datos\n",
    "            if not force_update:\n",
    "                for ticker in tqdm(self.tickers, desc=\"Verificando datos existentes\"):\n",
    "                    query = f\"SELECT date, open, high, low, close, volume FROM price_data WHERE ticker = '{ticker}' ORDER BY date\"\n",
    "                    df = pd.read_sql_query(query, conn)\n",
    "                    \n",
    "                    if not df.empty:\n",
    "                        df['date'] = pd.to_datetime(df['date'])\n",
    "                        df.set_index('date', inplace=True)\n",
    "                        self.market_data[ticker] = df\n",
    "            \n",
    "            # Obtener datos faltantes\n",
    "            missing_tickers = [t for t in self.tickers if t not in self.market_data]\n",
    "            if missing_tickers or force_update:\n",
    "                tickers_to_fetch = self.tickers if force_update else missing_tickers\n",
    "                \n",
    "                for ticker in tqdm(tickers_to_fetch, desc=\"Descargando datos de mercado\"):\n",
    "                    try:\n",
    "                        # Obtener datos de yfinance\n",
    "                        data = yf.download(ticker, start=self.start_date, end=self.end_date, progress=False)\n",
    "                        \n",
    "                        if data.empty:\n",
    "                            continue\n",
    "                        \n",
    "                        # Guardar en la base de datos\n",
    "                        data_to_save = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "                        data_to_save.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                        data_to_save.index.name = 'date'\n",
    "                        data_to_save.reset_index(inplace=True)\n",
    "                        data_to_save['ticker'] = ticker\n",
    "                        \n",
    "                        data_to_save.to_sql('price_data', conn, if_exists='replace', index=False)\n",
    "                        \n",
    "                        # Guardar en memoria\n",
    "                        self.market_data[ticker] = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "                        self.market_data[ticker].columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error descargando datos para {ticker}: {str(e)}\")\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            # Obtener datos del índice S&P 500\n",
    "            if 'SPY' not in self.market_data:\n",
    "                spy_data = yf.download('SPY', start=self.start_date, end=self.end_date, progress=False)\n",
    "                self.market_data['SPY'] = spy_data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "                self.market_data['SPY'].columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "            \n",
    "            # Obtener datos del VIX\n",
    "            if '^VIX' not in self.market_data:\n",
    "                vix_data = yf.download('^VIX', start=self.start_date, end=self.end_date, progress=False)\n",
    "                self.market_data['^VIX'] = vix_data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "                self.market_data['^VIX'].columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "            \n",
    "            # Calcular retornos diarios para todos los tickers\n",
    "            for ticker in self.market_data:\n",
    "                self.market_data[ticker]['returns'] = self.market_data[ticker]['close'].pct_change()\n",
    "                self.market_data[ticker]['log_returns'] = np.log(self.market_data[ticker]['close']).diff()\n",
    "                self.market_data[ticker]['true_range'] = np.maximum(\n",
    "                    self.market_data[ticker]['high'] - self.market_data[ticker]['low'],\n",
    "                    np.maximum(\n",
    "                        abs(self.market_data[ticker]['high'] - self.market_data[ticker]['close'].shift(1)),\n",
    "                        abs(self.market_data[ticker]['low'] - self.market_data[ticker]['close'].shift(1))\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            print(f\"Datos de mercado obtenidos para {len(self.market_data)} tickers\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en fetch_market_data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _calculate_dominant_cycle(self, ticker, window=252):\n",
    "        \"\"\"\n",
    "        Calcula el ciclo dominante específico para un ticker\n",
    "        \n",
    "        Args:\n",
    "            ticker: Símbolo del ticker\n",
    "            window: Ventana para análisis espectral\n",
    "            \n",
    "        Returns:\n",
    "            Período del ciclo dominante en días\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if ticker not in self.market_data:\n",
    "                return 21  # valor por defecto\n",
    "            \n",
    "            prices = self.market_data[ticker]['close'].dropna()\n",
    "            if len(prices) < window:\n",
    "                return 21\n",
    "            \n",
    "            # Aplicar ventana deslizante\n",
    "            cycles = []\n",
    "            \n",
    "            for i in range(len(prices) - window + 1):\n",
    "                segment = prices.iloc[i:i+window].values\n",
    "                segment = segment - np.mean(segment)  # Eliminar tendencia\n",
    "                \n",
    "                # Aplicar ventana Hamming para reducir leakage espectral\n",
    "                windowed = segment * np.hamming(len(segment))\n",
    "                \n",
    "                # Calcular FFT\n",
    "                spectrum = np.abs(fft(windowed))\n",
    "                \n",
    "                # Solo considerar la primera mitad (frecuencias positivas)\n",
    "                half_spectrum = spectrum[1:window//2]\n",
    "                frequencies = np.fft.fftfreq(window, 1)[1:window//2]\n",
    "                \n",
    "                # Encontrar frecuencia dominante\n",
    "                if len(half_spectrum) > 0:\n",
    "                    dominant_idx = np.argmax(half_spectrum)\n",
    "                    dominant_freq = frequencies[dominant_idx]\n",
    "                    if dominant_freq > 0:\n",
    "                        dominant_period = abs(1.0 / dominant_freq)\n",
    "                        cycles.append(min(max(dominant_period, 5), 252))  # Limitar entre 5 y 252 días\n",
    "            \n",
    "            if not cycles:\n",
    "                return 21\n",
    "            \n",
    "            # Usar mediana para robustez\n",
    "            dominant_cycle = int(np.median(cycles))\n",
    "            return dominant_cycle\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando ciclo dominante para {ticker}: {str(e)}\")\n",
    "            return 21  # valor por defecto\n",
    "    \n",
    "    def _calculate_hurst_exponent(self, ticker, min_scale=5, max_scale=100):\n",
    "        \"\"\"\n",
    "        Calcula el exponente de Hurst adaptativo para un ticker\n",
    "        \n",
    "        Args:\n",
    "            ticker: Símbolo del ticker\n",
    "            min_scale: Escala mínima para análisis R/S\n",
    "            max_scale: Escala máxima para análisis R/S\n",
    "            \n",
    "        Returns:\n",
    "            Exponente de Hurst\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if ticker not in self.market_data:\n",
    "                return 0.5  # valor por defecto (paseo aleatorio)\n",
    "            \n",
    "            returns = self.market_data[ticker]['log_returns'].dropna()\n",
    "            if len(returns) < max_scale:\n",
    "                return 0.5\n",
    "            \n",
    "            # Escalas para análisis R/S\n",
    "            scales = np.logspace(np.log10(min_scale), np.log10(max_scale), num=4).astype(int)\n",
    "            scales = np.unique(scales)\n",
    "            \n",
    "            rs_values = []\n",
    "            \n",
    "            for scale in scales:\n",
    "                # Dividir la serie en segmentos\n",
    "                segments = len(returns) // scale\n",
    "                if segments == 0:\n",
    "                    continue\n",
    "                \n",
    "                rs_segment = []\n",
    "                \n",
    "                for i in range(segments):\n",
    "                    segment = returns.iloc[i*scale:(i+1)*scale].values\n",
    "                    \n",
    "                    # Calcular perfil acumulativo\n",
    "                    profile = segment.cumsum() - segment.mean()\n",
    "                    \n",
    "                    # Rango rescalado\n",
    "                    r = np.max(profile) - np.min(profile)\n",
    "                    s = np.std(segment)\n",
    "                    \n",
    "                    if s > 0:\n",
    "                        rs_segment.append(r/s)\n",
    "                \n",
    "                if rs_segment:\n",
    "                    rs_values.append((scale, np.mean(rs_segment)))\n",
    "            \n",
    "            if len(rs_values) < 2:\n",
    "                return 0.5\n",
    "            \n",
    "            # Regresión log-log\n",
    "            x = np.log10([t[0] for t in rs_values])\n",
    "            y = np.log10([t[1] for t in rs_values])\n",
    "            \n",
    "            slope, _, _, _, _ = stats.linregress(x, y)\n",
    "            \n",
    "            return slope\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando exponente de Hurst para {ticker}: {str(e)}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def _calculate_lempel_ziv_complexity(self, ticker, window=126):\n",
    "        \"\"\"\n",
    "        Calcula la complejidad de Lempel-Ziv para un ticker\n",
    "        \n",
    "        Args:\n",
    "            ticker: Símbolo del ticker\n",
    "            window: Ventana para el cálculo\n",
    "            \n",
    "        Returns:\n",
    "            Valor de complejidad normalizado\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if ticker not in self.market_data:\n",
    "                return 0.5  # valor por defecto\n",
    "            \n",
    "            returns = self.market_data[ticker]['returns'].dropna().iloc[-window:]\n",
    "            if len(returns) < window:\n",
    "                return 0.5\n",
    "            \n",
    "            # Calcular volatilidad para umbral adaptativo\n",
    "            volatility = returns.std()\n",
    "            threshold = 0.5 * volatility\n",
    "            \n",
    "            # Convertir retornos a secuencia binaria\n",
    "            binary_seq = ''.join(['1' if r > threshold else '0' if r < -threshold else '1' if np.random.random() > 0.5 else '0' for r in returns])\n",
    "            \n",
    "            # Calcular complejidad de Lempel-Ziv\n",
    "            sub_strings = set()\n",
    "            i, complexity = 0, 1\n",
    "            \n",
    "            while i < len(binary_seq):\n",
    "                sub_str = binary_seq[i]\n",
    "                i += 1\n",
    "                while i < len(binary_seq) and sub_str + binary_seq[i] in sub_strings:\n",
    "                    sub_str += binary_seq[i]\n",
    "                    i += 1\n",
    "                \n",
    "                if i < len(binary_seq):\n",
    "                    sub_str += binary_seq[i]\n",
    "                    sub_strings.add(sub_str)\n",
    "                    complexity += 1\n",
    "            \n",
    "            # Normalizar por la complejidad máxima teórica\n",
    "            max_complexity = len(binary_seq) / np.log2(len(binary_seq))\n",
    "            normalized_complexity = complexity / max_complexity\n",
    "            \n",
    "            return normalized_complexity\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando complejidad LZ para {ticker}: {str(e)}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def _calculate_sample_entropy(self, ticker, scales=[5, 10, 20], m=2, r=0.2):\n",
    "        \"\"\"\n",
    "        Calcula la entropía de muestra multiescala para un ticker\n",
    "        \n",
    "        Args:\n",
    "            ticker: Símbolo del ticker\n",
    "            scales: Escalas temporales para el cálculo\n",
    "            m: Dimensión de embedding\n",
    "            r: Tolerancia\n",
    "            \n",
    "        Returns:\n",
    "            Entropía de muestra promedio ponderada\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if ticker not in self.market_data:\n",
    "                return 0.5  # valor por defecto\n",
    "            \n",
    "            returns = self.market_data[ticker]['returns'].dropna().iloc[-252:]\n",
    "            if len(returns) < 50:\n",
    "                return 0.5\n",
    "            \n",
    "            # Función para calcular entropía de muestra en una escala\n",
    "            def sample_entropy(data, m, r):\n",
    "                N = len(data)\n",
    "                if N < 2*m+1:\n",
    "                    return 0\n",
    "                \n",
    "                # Normalizar r por la desviación estándar\n",
    "                r = r * np.std(data)\n",
    "                \n",
    "                # Contar coincidencias para dimensiones m y m+1\n",
    "                count_m = 0\n",
    "                count_m1 = 0\n",
    "                \n",
    "                for i in range(N-m):\n",
    "                    template_m = data[i:i+m]\n",
    "                    template_m1 = data[i:i+m+1]\n",
    "                    \n",
    "                    # Contar coincidencias para dimensión m\n",
    "                    for j in range(i+1, N-m+1):\n",
    "                        if np.max(np.abs(template_m - data[j:j+m])) < r:\n",
    "                            count_m += 1\n",
    "                            \n",
    "                            # Verificar si también coincide para dimensión m+1\n",
    "                            if j <= N-m-1 and np.max(np.abs(template_m1 - data[j:j+m+1])) < r:\n",
    "                                count_m1 += 1\n",
    "                \n",
    "                # Calcular probabilidades\n",
    "                if count_m == 0 or count_m1 == 0:\n",
    "                    return 0\n",
    "                \n",
    "                return -np.log(count_m1 / count_m)\n",
    "            \n",
    "            # Calcular entropía para cada escala\n",
    "            entropies = []\n",
    "            weights = [0.2, 0.3, 0.5]  # Pesos para cada escala (mayor peso a escalas mayores)\n",
    "            \n",
    "            for i, scale in enumerate(scales):\n",
    "                # Coarse-graining (promedio en ventanas)\n",
    "                coarse_data = np.array([np.mean(returns.iloc[j:j+scale]) for j in range(0, len(returns)-scale+1, scale)])\n",
    "                \n",
    "                if len(coarse_data) > 2*m+1:\n",
    "                    entropy = sample_entropy(coarse_data, m, r)\n",
    "                    entropies.append(entropy * weights[i])\n",
    "            \n",
    "            if not entropies:\n",
    "                return 0.5\n",
    "            \n",
    "            return sum(entropies) / sum(weights[:len(entropies)])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculando entropía de muestra para {ticker}: {str(e)}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def generate_features(self):\n",
    "        \"\"\"Genera todas las características adaptativas para cada ticker\"\"\"\n",
    "        try:\n",
    "            # Inicializar diccionario de características\n",
    "            self.features = {ticker: {} for ticker in self.market_data}\n",
    "            \n",
    "            # Procesar cada ticker en paralelo\n",
    "            results = Parallel(n_jobs=-1)(\n",
    "                delayed(self._generate_ticker_features)(ticker) \n",
    "                for ticker in tqdm(self.market_data.keys(), desc=\"Generando características\")\n",
    "            )\n",
    "            \n",
    "            # Consolidar resultados\n",
    "            for ticker, features_df in results:\n",
    "                if features_df is not None:\n",
    "                    self.features[ticker] = features_df\n",
    "            \n",
    "            print(f\"Características generadas para {len(self.features)} tickers\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en generate_features: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_ticker_features(self, ticker):\n",
    "        \"\"\"\n",
    "        Genera todas las características para un ticker específico\n",
    "        \n",
    "        Args:\n",
    "            ticker: Símbolo del ticker\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (ticker, DataFrame con características)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if ticker not in self.market_data or self.market_data[ticker].empty:\n",
    "                return ticker, None\n",
    "            \n",
    "            # Obtener datos del ticker\n",
    "            data = self.market_data[ticker].copy()\n",
    "            \n",
    "            # Inicializar DataFrame para características\n",
    "            features = pd.DataFrame(index=data.index)\n",
    "            \n",
    "            # 1. Características de Dinámica Temporal (CDT)\n",
    "            \n",
    "            # 1.1 Ciclo Dominante Específico (CDE)\n",
    "            dominant_cycle = self._calculate_dominant_cycle(ticker)\n",
    "            features['CDE'] = dominant_cycle\n",
    "            \n",
    "            # 1.2 Oscilador de Momentum Adaptativo (OMA)\n",
    "            if len(data) > dominant_cycle:\n",
    "                features['OMA'] = (data['close'] - data['close'].shift(dominant_cycle)) / data['close'].rolling(dominant_cycle).std()\n",
    "                \n",
    "                # 1.3 Aceleración del Precio Adaptativa (APA)\n",
    "                features['APA'] = (features['OMA'] - features['OMA'].shift(5)) / features['OMA'].rolling(63).std()\n",
    "                features['APA'] = features['APA'].ewm(span=max(5, dominant_cycle//10)).mean()  # Filtrado\n",
    "            \n",
    "            # 2. Características de Eficiencia y Persistencia (CEP)\n",
    "            \n",
    "            # 2.1 Exponente de Hurst Adaptativo (EHA)\n",
    "            # Calculamos en ventanas rodantes\n",
    "            rolling_hurst = []\n",
    "            for i in range(max(252, len(data)-504), len(data), 5):  # Actualización semanal\n",
    "                window = data.iloc[max(0, i-504):i]  # 2 años de datos\n",
    "                if len(window) > 100:\n",
    "                    h = self._calculate_hurst_exponent(ticker)\n",
    "                    rolling_hurst.extend([h] * min(5, len(data)-i))\n",
    "            \n",
    "            if rolling_hurst:\n",
    "                features['EHA'] = pd.Series(rolling_hurst, index=data.index[-len(rolling_hurst):])\n",
    "            \n",
    "            # 2.2 Ratio de Eficiencia de Movimiento (REM)\n",
    "            n = max(21, dominant_cycle//2)\n",
    "            if len(data) > n:\n",
    "                features['REM'] = abs(np.log(data['close'] / data['close'].shift(n))) / data['true_range'].rolling(n).sum()\n",
    "            \n",
    "            # 2.3 Índice de Persistencia Direccional (IPD)\n",
    "            if len(data) > dominant_cycle:\n",
    "                signed_returns = np.sign(data['returns']) * np.abs(data['returns'])**0.5\n",
    "                features['IPD'] = signed_returns.ewm(span=max(5, dominant_cycle//4)).mean()\n",
    "                \n",
    "                # Normalización a percentiles\n",
    "                if len(features['IPD'].dropna()) > 252:\n",
    "                    rolling_percentile = []\n",
    "                    for i in range(252, len(features['IPD'])):\n",
    "                        window = features['IPD'].iloc[max(0, i-504):i]\n",
    "                        if not window.empty:\n",
    "                            perc = stats.percentileofscore(window.dropna(), features['IPD'].iloc[i]) / 100\n",
    "                            rolling_percentile.append(perc)\n",
    "                    \n",
    "                    if rolling_percentile:\n",
    "                        features['IPD_norm'] = pd.Series(rolling_percentile, index=features.index[-len(rolling_percentile):])\n",
    "            \n",
    "            # 3. Características de Microestructura (CME)\n",
    "            \n",
    "            # 3.1 Asimetría de Volumen-Precio (AVP)\n",
    "            if len(data) > 63:\n",
    "                abs_returns = abs(data['returns'])\n",
    "                norm_volume = np.log(data['volume'] / data['volume'].rolling(63).mean())\n",
    "                \n",
    "                # Correlación de Spearman en ventanas rodantes\n",
    "                rolling_corr = []\n",
    "                for i in range(21, len(data)):\n",
    "                    window_returns = abs_returns.iloc[i-21:i]\n",
    "                    window_volume = norm_volume.iloc[i-21:i]\n",
    "                    valid_data = ~(window_returns.isna() | window_volume.isna())\n",
    "                    if valid_data.sum() > 10:\n",
    "                        corr = stats.spearmanr(window_returns[valid_data], window_volume[valid_data])[0]\n",
    "                        rolling_corr.append(corr if not np.isnan(corr) else 0)\n",
    "                    else:\n",
    "                        rolling_corr.append(0)\n",
    "                \n",
    "                if rolling_corr:\n",
    "                    features['AVP'] = pd.Series(rolling_corr, index=data.index[-len(rolling_corr):])\n",
    "                    features['AVP'] = features['AVP'].ewm(span=5).mean()\n",
    "            \n",
    "            # 3.2 Elasticidad de Liquidez Estimada (ELE)\n",
    "            window_size = min(63, 3*dominant_cycle)\n",
    "            if len(data) > window_size:\n",
    "                # Usar regresión Huber para robustez\n",
    "                rolling_elasticity = []\n",
    "                for i in range(window_size, len(data)):\n",
    "                    window_returns = abs(data['returns'].iloc[i-window_size:i]).values.reshape(-1, 1)\n",
    "                    window_volume = norm_volume.iloc[i-window_size:i].values.reshape(-1, 1)\n",
    "                    valid_data = ~(np.isnan(window_returns).any(axis=1) | np.isnan(window_volume).any(axis=1))\n",
    "                    \n",
    "                    if valid_data.sum() > window_size//2:\n",
    "                        try:\n",
    "                            huber = HuberRegressor(epsilon=1.35)\n",
    "                            # Código modificado:\n",
    "                            X = window_volume[valid_data].reshape(-1, 1)\n",
    "                            y = window_returns[valid_data].ravel()  # Aplanar a 1D\n",
    "                            huber.fit(X, y)\n",
    "                            # huber.fit(window_volume[valid_data], window_returns[valid_data])\n",
    "                            elasticity = huber.coef_[0]\n",
    "                            rolling_elasticity.append(elasticity)\n",
    "                        except:\n",
    "                            rolling_elasticity.append(0)\n",
    "                    else:\n",
    "                        rolling_elasticity.append(0)\n",
    "                \n",
    "                if rolling_elasticity:\n",
    "                    features['ELE'] = pd.Series(rolling_elasticity, index=data.index[-len(rolling_elasticity):])\n",
    "            \n",
    "            # 3.3 Indicador de Presión de Compra-Venta (IPCV)\n",
    "            window_size = min(21, dominant_cycle//2)\n",
    "            if len(data) > window_size:\n",
    "                price_direction = np.sign(data['close'] - data['open'])\n",
    "                volume_pressure = data['volume'] * price_direction\n",
    "                features['IPCV'] = volume_pressure.rolling(window_size).sum() / data['volume'].rolling(window_size).sum()\n",
    "                \n",
    "                # Normalización Z-score\n",
    "                if len(features['IPCV'].dropna()) > 252:\n",
    "                    features['IPCV_norm'] = (features['IPCV'] - features['IPCV'].rolling(252).mean()) / features['IPCV'].rolling(252).std()\n",
    "            \n",
    "            # 4. Características de Complejidad y Entropía (CCE)\n",
    "            \n",
    "            # 4.1 Entropía de Muestra Multiescala (EMM)\n",
    "            # Calculamos en ventanas rodantes para reducir carga computacional\n",
    "            rolling_entropy = []\n",
    "            for i in range(max(252, len(data)-504), len(data), 5):  # Actualización semanal\n",
    "                window = data.iloc[max(0, i-252):i]  # 1 año de datos\n",
    "                if len(window) > 50:\n",
    "                    entropy = self._calculate_sample_entropy(ticker)\n",
    "                    rolling_entropy.extend([entropy] * min(5, len(data)-i))\n",
    "            \n",
    "            if rolling_entropy:\n",
    "                features['EMM'] = pd.Series(rolling_entropy, index=data.index[-len(rolling_entropy):])\n",
    "            \n",
    "            # 4.2 Complejidad de Lempel-Ziv (CLZ)\n",
    "            rolling_complexity = []\n",
    "            for i in range(max(252, len(data)-504), len(data), 5):  # Actualización semanal\n",
    "                window = data.iloc[max(0, i-252):i]  # 1 año de datos\n",
    "                if len(window) > 126:\n",
    "                    complexity = self._calculate_lempel_ziv_complexity(ticker)\n",
    "                    rolling_complexity.extend([complexity] * min(5, len(data)-i))\n",
    "            \n",
    "            if rolling_complexity:\n",
    "                features['CLZ'] = pd.Series(rolling_complexity, index=data.index[-len(rolling_complexity):])\n",
    "            \n",
    "            # 4.3 Índice de Transferencia de Información (ITI)\n",
    "            # Simplificamos usando correlación con lag como proxy\n",
    "            if 'SPY' in self.market_data and len(data) > 21:\n",
    "                spy_returns = self.market_data['SPY']['returns']\n",
    "                \n",
    "                # Alinear índices\n",
    "                common_index = data.index.intersection(spy_returns.index)\n",
    "                if len(common_index) > 21:\n",
    "                    ticker_returns = data.loc[common_index, 'returns']\n",
    "                    spy_returns = spy_returns.loc[common_index]\n",
    "                    \n",
    "                    # Calcular correlaciones con diferentes lags\n",
    "                    lags = [1, 5, 10, 21]\n",
    "                    weights = [0.1, 0.2, 0.3, 0.4]  # Mayor peso a horizontes más largos\n",
    "                    \n",
    "                    iti_values = []\n",
    "                    for i in range(max(lags), len(common_index)):\n",
    "                        iti_lag = 0\n",
    "                        for lag, weight in zip(lags, weights):\n",
    "                            corr_lag0 = np.corrcoef(ticker_returns.iloc[i-lag:i], spy_returns.iloc[i-lag:i])[0, 1]\n",
    "                            corr_lag1 = np.corrcoef(ticker_returns.iloc[i-lag:i], spy_returns.iloc[i-lag-1:i-1])[0, 1]\n",
    "                            iti_lag += weight * (corr_lag1 - corr_lag0)\n",
    "                        \n",
    "                        iti_values.append(iti_lag)\n",
    "                    \n",
    "                    if iti_values:\n",
    "                        features['ITI'] = pd.Series(iti_values, index=common_index[-len(iti_values):])\n",
    "            \n",
    "            # 5. Características de Correlación Dinámica (CCD)\n",
    "            \n",
    "            # 5.1 Beta Condicional Multirégimen (BCM)\n",
    "            if 'SPY' in self.market_data and '^VIX' in self.market_data and len(data) > 63:\n",
    "                # Alinear índices\n",
    "                common_index = data.index.intersection(self.market_data['SPY'].index).intersection(self.market_data['^VIX'].index)\n",
    "                \n",
    "                if len(common_index) > 63:\n",
    "                    ticker_returns = data.loc[common_index, 'returns']\n",
    "                    spy_returns = self.market_data['SPY'].loc[common_index, 'returns']\n",
    "                    vix_values = self.market_data['^VIX'].loc[common_index, 'close']\n",
    "                    \n",
    "                    # Definir regímenes basados en VIX\n",
    "                    vix_quantiles = vix_values.rolling(252).quantile([0.33, 0.67])\n",
    "                    \n",
    "                    # Calcular beta condicional\n",
    "                    rolling_beta = []\n",
    "                    for i in range(63, len(common_index)):\n",
    "                        window_ticker = ticker_returns.iloc[i-63:i]\n",
    "                        window_spy = spy_returns.iloc[i-63:i]\n",
    "                        current_vix = vix_values.iloc[i]\n",
    "                        \n",
    "                        # Determinar régimen\n",
    "                        if pd.notna(vix_quantiles.iloc[i-1, 0]) and pd.notna(vix_quantiles.iloc[i-1, 1]):\n",
    "                            if current_vix <= vix_quantiles.iloc[i-1, 0]:\n",
    "                                regime = 'low'\n",
    "                                weights = np.ones(63) * 0.8  # Menor peso en régimen de baja volatilidad\n",
    "                            elif current_vix <= vix_quantiles.iloc[i-1, 1]:\n",
    "                                regime = 'medium'\n",
    "                                weights = np.ones(63)  # Peso normal en régimen medio\n",
    "                            else:\n",
    "                                regime = 'high'\n",
    "                                weights = np.ones(63) * 1.2  # Mayor peso en régimen de alta volatilidad\n",
    "                        else:\n",
    "                            regime = 'medium'\n",
    "                            weights = np.ones(63)\n",
    "                        \n",
    "                        # Regresión ponderada\n",
    "                        valid_data = ~(window_ticker.isna() | window_spy.isna())\n",
    "                        if valid_data.sum() > 30:\n",
    "                            X = sm.add_constant(window_spy[valid_data].values)\n",
    "                            # Código modificado:\n",
    "                            y = window_ticker[valid_data].values.ravel()  # Aplanar a 1D\n",
    "                            model = sm.WLS(y, X, weights=weights[valid_data])                            \n",
    "                            # model = sm.WLS(window_ticker[valid_data].values, X, weights=weights[valid_data])\n",
    "                            results = model.fit()\n",
    "                            beta = results.params[1]\n",
    "                            rolling_beta.append(beta)\n",
    "                        else:\n",
    "                            rolling_beta.append(np.nan)\n",
    "                    \n",
    "                    if rolling_beta:\n",
    "                        features['BCM'] = pd.Series(rolling_beta, index=common_index[-len(rolling_beta):])\n",
    "            \n",
    "            # 5.2 Divergencia de Correlación Sectorial (DCS)\n",
    "            # Simplificamos usando correlación con SPY como proxy del sector\n",
    "            if 'SPY' in self.market_data and len(data) > 252:\n",
    "                # Alinear índices\n",
    "                common_index = data.index.intersection(self.market_data['SPY'].index)\n",
    "                \n",
    "                if len(common_index) > 252:\n",
    "                    ticker_returns = data.loc[common_index, 'returns']\n",
    "                    spy_returns = self.market_data['SPY'].loc[common_index, 'returns']\n",
    "                    \n",
    "                    # Calcular correlación rodante\n",
    "                    rolling_corr = ticker_returns.rolling(21).corr(spy_returns)\n",
    "                    rolling_corr_mean = rolling_corr.rolling(252).mean()\n",
    "                    rolling_corr_std = rolling_corr.rolling(252).std()\n",
    "                    \n",
    "                    # Divergencia normalizada\n",
    "                    features['DCS'] = (rolling_corr - rolling_corr_mean) / rolling_corr_std\n",
    "            \n",
    "            # 6. Características de Régimen Adaptativo (CRA)\n",
    "            \n",
    "            # 6.1 Indicador de Régimen de Volatilidad Específico (IRVE)\n",
    "            if len(data) > 252:\n",
    "                vol_21d = data['returns'].rolling(21).std() * np.sqrt(252)  # Anualizada\n",
    "                vol_25p = vol_21d.rolling(252).quantile(0.25)\n",
    "                vol_75p = vol_21d.rolling(252).quantile(0.75)\n",
    "                \n",
    "                features['IRVE'] = (vol_21d - vol_25p) / (vol_75p - vol_25p)\n",
    "            \n",
    "            # 6.2 Indicador de Cambio de Tendencia (ICT)\n",
    "            if len(data) > dominant_cycle:\n",
    "                # Osciladores en múltiples escalas\n",
    "                scales = [max(5, dominant_cycle//4), max(10, dominant_cycle//2), dominant_cycle]\n",
    "                oscillators = {}\n",
    "                \n",
    "                for scale in scales:\n",
    "                    if len(data) > scale:\n",
    "                        oscillators[scale] = (data['close'] - data['close'].rolling(scale).mean()) / data['close'].rolling(scale).std()\n",
    "                \n",
    "                # Calcular divergencias\n",
    "                if len(oscillators) > 1:\n",
    "                    scales_list = sorted(oscillators.keys())\n",
    "                    divergence = pd.Series(0, index=data.index)\n",
    "                    \n",
    "                    for i in range(1, len(scales_list)):\n",
    "                        scale_current = scales_list[i]\n",
    "                        scale_prev = scales_list[i-1]\n",
    "                        \n",
    "                        if scale_current in oscillators and scale_prev in oscillators:\n",
    "                            sign_diff = np.sign(oscillators[scale_current] - oscillators[scale_prev])\n",
    "                            divergence += sign_diff\n",
    "                    \n",
    "                    features['ICT'] = divergence / (len(scales_list) - 1)\n",
    "            \n",
    "            # Limpiar NaN y valores infinitos\n",
    "            features = features.replace([np.inf, -np.inf], np.nan)\n",
    "            \n",
    "            return ticker, features\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generando características para {ticker}: {str(e)}\")\n",
    "            return ticker, None\n",
    "    \n",
    "    def normalize_features(self):\n",
    "        \"\"\"Normaliza todas las características para cada ticker\"\"\"\n",
    "        try:\n",
    "            for ticker in tqdm(self.features.keys(), desc=\"Normalizando características\"):\n",
    "                if ticker not in self.features or self.features[ticker].empty:\n",
    "                    continue\n",
    "                \n",
    "                features_df = self.features[ticker].copy()\n",
    "                \n",
    "                # Identificar columnas numéricas\n",
    "                numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "                \n",
    "                for col in numeric_cols:\n",
    "                    # Winsorización adaptativa\n",
    "                    if features_df[col].count() > 100:\n",
    "                        lower = features_df[col].quantile(0.01)\n",
    "                        upper = features_df[col].quantile(0.99)\n",
    "                        features_df[col] = features_df[col].clip(lower, upper)\n",
    "                    \n",
    "                    # Normalización a rango [0,1] usando CDF empírica\n",
    "                    if features_df[col].count() > 10:\n",
    "                        sorted_values = features_df[col].dropna().sort_values()\n",
    "                        ranks = sorted_values.rank(method='average')\n",
    "                        normalized = (ranks - 1) / (len(ranks) - 1) if len(ranks) > 1 else ranks\n",
    "                        \n",
    "                        # Mapear valores originales a normalizados\n",
    "                        value_to_norm = dict(zip(sorted_values, normalized))\n",
    "                        features_df[col] = features_df[col].map(value_to_norm)\n",
    "                \n",
    "                self.features[ticker] = features_df\n",
    "            \n",
    "            print(\"Características normalizadas\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en normalize_features: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def reduce_dimensions(self):\n",
    "        \"\"\"Reduce dimensionalidad de características usando ICA\"\"\"\n",
    "        try:\n",
    "            # Crear DataFrame consolidado con todas las características\n",
    "            all_features = {}\n",
    "            \n",
    "            for ticker in self.features:\n",
    "                if ticker in self.features and not self.features[ticker].empty:\n",
    "                    # Usar las últimas 252 observaciones para cada ticker\n",
    "                    ticker_features = self.features[ticker].iloc[-252:].copy()\n",
    "                    \n",
    "                    # Añadir identificador de ticker\n",
    "                    ticker_features['ticker'] = ticker\n",
    "                    \n",
    "                    all_features[ticker] = ticker_features\n",
    "            \n",
    "            if not all_features:\n",
    "                print(\"No hay suficientes datos para reducción de dimensionalidad\")\n",
    "                return\n",
    "            \n",
    "            # Concatenar todos los DataFrames\n",
    "            combined_features = pd.concat(all_features.values())\n",
    "            \n",
    "            # Identificar columnas numéricas con suficientes datos\n",
    "            numeric_cols = combined_features.select_dtypes(include=[np.number]).columns\n",
    "            valid_cols = [col for col in numeric_cols if combined_features[col].count() > combined_features.shape[0] * 0.5]\n",
    "            \n",
    "            if len(valid_cols) < 3:\n",
    "                print(\"No hay suficientes características válidas para reducción de dimensionalidad\")\n",
    "                return\n",
    "            \n",
    "            # Imputar valores faltantes con la media\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X = imputer.fit_transform(combined_features[valid_cols])\n",
    "            \n",
    "            # Estandarizar datos\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Aplicar ICA\n",
    "            n_components = min(len(valid_cols), 10)  # Máximo 10 componentes\n",
    "            ica = FastICA(n_components=n_components, random_state=42)\n",
    "            X_ica = ica.fit_transform(X_scaled)\n",
    "            \n",
    "            # Crear DataFrame con componentes\n",
    "            ica_cols = [f'ICA_{i+1}' for i in range(n_components)]\n",
    "            ica_df = pd.DataFrame(X_ica, columns=ica_cols, index=combined_features.index)\n",
    "            \n",
    "            # Añadir ticker\n",
    "            ica_df['ticker'] = combined_features['ticker']\n",
    "            \n",
    "            # Separar por ticker y guardar\n",
    "            for ticker in self.features:\n",
    "                if ticker in ica_df['ticker'].values:\n",
    "                    ticker_ica = ica_df[ica_df['ticker'] == ticker].drop(columns=['ticker'])\n",
    "                    \n",
    "                    # Añadir componentes ICA a características originales\n",
    "                    self.features[ticker] = pd.concat([self.features[ticker], ticker_ica], axis=1)\n",
    "            \n",
    "            print(f\"Dimensionalidad reducida a {n_components} componentes\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en reduce_dimensions: {str(e)}\")\n",
    "            print(f\"Error en reducción de dimensionalidad: {str(e)}\")\n",
    "    \n",
    "    def calculate_rankings(self):\n",
    "        \"\"\"Calcula rankings para todos los tickers en diferentes horizontes temporales\"\"\"\n",
    "        try:\n",
    "            # Definir horizontes temporales\n",
    "            horizons = {\n",
    "                'short': 10,   # 10 días (2 semanas)\n",
    "                'medium': 21,  # 21 días (1 mes)\n",
    "                'long': 63     # 63 días (3 meses)\n",
    "            }\n",
    "            \n",
    "            # Inicializar rankings\n",
    "            self.rankings = {\n",
    "                horizon: pd.DataFrame() \n",
    "                for horizon in horizons.keys()\n",
    "            }\n",
    "            \n",
    "            # Para cada horizonte, calcular IC (Information Coefficient) de cada característica\n",
    "            for horizon_name, horizon_days in horizons.items():\n",
    "                print(f\"Calculando rankings para horizonte {horizon_name} ({horizon_days} días)\")\n",
    "                \n",
    "                # Recopilar datos de rendimiento futuro para todos los tickers\n",
    "                future_returns = {}\n",
    "                \n",
    "                for ticker in self.features:\n",
    "                    if ticker in self.market_data and not self.market_data[ticker].empty:\n",
    "                        # Calcular rendimiento futuro\n",
    "                        returns = self.market_data[ticker]['returns']\n",
    "                        future_return = returns.shift(-horizon_days).rolling(horizon_days).apply(\n",
    "                            lambda x: (1 + x).prod() - 1, raw=True\n",
    "                        )\n",
    "                        \n",
    "                        future_returns[ticker] = future_return\n",
    "                \n",
    "                # Calcular IC para cada característica\n",
    "                feature_ic = {}\n",
    "                common_features = set()\n",
    "                \n",
    "                # Identificar características comunes\n",
    "                for ticker in self.features:\n",
    "                    if ticker in self.features and not self.features[ticker].empty:\n",
    "                        common_features.update(self.features[ticker].columns)\n",
    "                \n",
    "                common_features = list(common_features)\n",
    "                \n",
    "                for feature in common_features:\n",
    "                    feature_values = {}\n",
    "                    feature_returns = {}\n",
    "                    \n",
    "                    # Recopilar valores de característica y rendimientos futuros\n",
    "                    for ticker in self.features:\n",
    "                        if (ticker in self.features and not self.features[ticker].empty and \n",
    "                            feature in self.features[ticker].columns and \n",
    "                            ticker in future_returns):\n",
    "                            \n",
    "                            feature_values[ticker] = self.features[ticker][feature]\n",
    "                            feature_returns[ticker] = future_returns[ticker]\n",
    "                    \n",
    "                    # Calcular IC en ventanas rodantes\n",
    "                    ic_values = []\n",
    "                    dates = []\n",
    "                    \n",
    "                    # Obtener fechas comunes\n",
    "                    all_dates = set()\n",
    "                    for ticker in feature_values:\n",
    "                        all_dates.update(feature_values[ticker].index)\n",
    "                    \n",
    "                    all_dates = sorted(all_dates)\n",
    "                    \n",
    "                    # Calcular IC para cada fecha\n",
    "                    for date in all_dates[-252:]:  # Últimos 252 días\n",
    "                        date_values = []\n",
    "                        date_returns = []\n",
    "                        \n",
    "                        for ticker in feature_values:\n",
    "                            if (date in feature_values[ticker].index and \n",
    "                                date in feature_returns[ticker].index and\n",
    "                                pd.notna(feature_values[ticker].loc[date]) and\n",
    "                                pd.notna(feature_returns[ticker].loc[date])):\n",
    "                                \n",
    "                                date_values.append(feature_values[ticker].loc[date])\n",
    "                                date_returns.append(feature_returns[ticker].loc[date])\n",
    "                        \n",
    "                        if len(date_values) > 10:  # Mínimo 10 tickers\n",
    "                            ic = np.corrcoef(date_values, date_returns)[0, 1]\n",
    "                            if not np.isnan(ic):\n",
    "                                ic_values.append(ic)\n",
    "                                dates.append(date)\n",
    "                    \n",
    "                    if ic_values:\n",
    "                        # Calcular IC promedio\n",
    "                        avg_ic = np.mean(ic_values)\n",
    "                        feature_ic[feature] = avg_ic\n",
    "                \n",
    "                # Filtrar características con IC significativo\n",
    "                significant_features = {f: ic for f, ic in feature_ic.items() if abs(ic) > 0.05}\n",
    "                \n",
    "                if not significant_features:\n",
    "                    print(f\"No se encontraron características significativas para horizonte {horizon_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Normalizar pesos por magnitud de IC\n",
    "                total_abs_ic = sum(abs(ic) for ic in significant_features.values())\n",
    "                feature_weights = {f: abs(ic)/total_abs_ic for f, ic in significant_features.items()}\n",
    "                \n",
    "                # Calcular score combinado para cada ticker\n",
    "                scores = {}\n",
    "                \n",
    "                for ticker in self.features:\n",
    "                    if ticker in self.features and not self.features[ticker].empty:\n",
    "                        ticker_scores = pd.Series(0, index=self.features[ticker].index)\n",
    "                        \n",
    "                        for feature, weight in feature_weights.items():\n",
    "                            if feature in self.features[ticker].columns:\n",
    "                                # Ajustar signo según correlación con rendimientos\n",
    "                                sign = np.sign(feature_ic.get(feature, 0))\n",
    "                                if sign != 0:\n",
    "                                    ticker_scores += sign * self.features[ticker][feature] * weight\n",
    "                        \n",
    "                        scores[ticker] = ticker_scores\n",
    "                \n",
    "                # Crear DataFrame con todos los scores\n",
    "                all_scores = pd.DataFrame(scores)\n",
    "                \n",
    "                # Calcular ranking percentil para cada fecha\n",
    "                ranking_percentile = pd.DataFrame(index=all_scores.index)\n",
    "                \n",
    "                for date in all_scores.index:\n",
    "                    date_scores = all_scores.loc[date].dropna()\n",
    "                    \n",
    "                    if len(date_scores) > 0:\n",
    "                        # Calcular percentiles (0-100)\n",
    "                        percentiles = date_scores.rank(pct=True) * 100\n",
    "                        ranking_percentile.loc[date, percentiles.index] = percentiles\n",
    "                \n",
    "                # Guardar ranking\n",
    "                self.rankings[horizon_name] = ranking_percentile\n",
    "                \n",
    "                print(f\"Ranking calculado para horizonte {horizon_name} con {len(significant_features)} características\")\n",
    "                print(f\"Top 5 características por IC: {sorted(significant_features.items(), key=lambda x: abs(x[1]), reverse=True)[:5]}\")\n",
    "            \n",
    "            # Combinar rankings de diferentes horizontes\n",
    "            self.combined_ranking = pd.DataFrame()\n",
    "            \n",
    "            # Pesos para cada horizonte\n",
    "            horizon_weights = {\n",
    "                'short': 0.3,\n",
    "                'medium': 0.4,\n",
    "                'long': 0.3\n",
    "            }\n",
    "            \n",
    "            # Obtener todas las fechas y tickers\n",
    "            all_dates = set()\n",
    "            all_tickers = set()\n",
    "            \n",
    "            for horizon in self.rankings:\n",
    "                all_dates.update(self.rankings[horizon].index)\n",
    "                all_tickers.update(self.rankings[horizon].columns)\n",
    "            \n",
    "            all_dates = sorted(all_dates)\n",
    "            \n",
    "            # Inicializar DataFrame combinado\n",
    "            self.combined_ranking = pd.DataFrame(index=all_dates, columns=list(all_tickers))\n",
    "            \n",
    "            # Combinar rankings con pesos\n",
    "            for date in all_dates:\n",
    "                for ticker in all_tickers:\n",
    "                    weighted_rank = 0\n",
    "                    total_weight = 0\n",
    "                    \n",
    "                    for horizon, weight in horizon_weights.items():\n",
    "                        if (horizon in self.rankings and \n",
    "                            date in self.rankings[horizon].index and \n",
    "                            ticker in self.rankings[horizon].columns and\n",
    "                            pd.notna(self.rankings[horizon].loc[date, ticker])):\n",
    "                            \n",
    "                            weighted_rank += self.rankings[horizon].loc[date, ticker] * weight\n",
    "                            total_weight += weight\n",
    "                    \n",
    "                    if total_weight > 0:\n",
    "                        self.combined_ranking.loc[date, ticker] = weighted_rank / total_weight\n",
    "            \n",
    "            print(\"Rankings combinados calculados\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en calculate_rankings: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_portfolio(self, strategy_type='long_only'):\n",
    "        \"\"\"\n",
    "        Genera portafolio basado en rankings\n",
    "        \n",
    "        Args:\n",
    "            strategy_type: 'long_only' o 'market_neutral'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.combined_ranking.empty:\n",
    "                print(\"No hay rankings disponibles para generar portafolio\")\n",
    "                return\n",
    "            \n",
    "            # Inicializar DataFrame de portafolio\n",
    "            self.portfolio = pd.DataFrame(index=self.combined_ranking.index)\n",
    "            self.portfolio['cash'] = 1.0  # Iniciar con 100% en efectivo\n",
    "            \n",
    "            # Parámetros de portafolio\n",
    "            n_positions = 20  # Número de posiciones\n",
    "            rebalance_days = list(range(0, len(self.portfolio), self.rebalance_frequency))\n",
    "            \n",
    "            if not rebalance_days:\n",
    "                print(\"No hay suficientes días para rebalanceo\")\n",
    "                return\n",
    "            \n",
    "            # Añadir último día si no está incluido\n",
    "            if rebalance_days[-1] != len(self.portfolio) - 1:\n",
    "                rebalance_days.append(len(self.portfolio) - 1)\n",
    "            \n",
    "            # Inicializar posiciones\n",
    "            for ticker in self.combined_ranking.columns:\n",
    "                self.portfolio[ticker] = 0.0\n",
    "            \n",
    "            # Generar portafolio para cada día de rebalanceo\n",
    "            for i, rebalance_idx in enumerate(rebalance_days[:-1]):\n",
    "                rebalance_date = self.portfolio.index[rebalance_idx]\n",
    "                next_rebalance_idx = rebalance_days[i+1]\n",
    "                \n",
    "                # Obtener ranking en fecha de rebalanceo\n",
    "                ranking = self.combined_ranking.loc[rebalance_date].dropna()\n",
    "                \n",
    "                if len(ranking) < n_positions:\n",
    "                    print(f\"No hay suficientes tickers con ranking en {rebalance_date}\")\n",
    "                    continue\n",
    "                \n",
    "                # Filtrar por volumen y capitalización\n",
    "                valid_tickers = []\n",
    "                for ticker in ranking.index:\n",
    "                    if ticker in self.market_data and not self.market_data[ticker].empty:\n",
    "                        # Verificar volumen promedio\n",
    "                        avg_volume = self.market_data[ticker]['volume'].iloc[-63:].mean()\n",
    "                        \n",
    "                        if avg_volume >= self.min_volume:\n",
    "                            valid_tickers.append(ticker)\n",
    "                \n",
    "                if len(valid_tickers) < n_positions:\n",
    "                    print(f\"No hay suficientes tickers válidos en {rebalance_date}\")\n",
    "                    continue\n",
    "                \n",
    "                # Filtrar ranking por tickers válidos\n",
    "                valid_ranking = ranking[ranking.index.isin(valid_tickers)]\n",
    "                \n",
    "                # Seleccionar tickers según estrategia\n",
    "                if strategy_type == 'long_only':\n",
    "                    # Seleccionar top n_positions\n",
    "                    selected_tickers = valid_ranking.nlargest(n_positions).index\n",
    "                    weights = np.ones(len(selected_tickers)) / len(selected_tickers)\n",
    "                    \n",
    "                    # Asignar pesos\n",
    "                    self.portfolio.loc[rebalance_date, 'cash'] = 0.0\n",
    "                    for ticker, weight in zip(selected_tickers, weights):\n",
    "                        self.portfolio.loc[rebalance_date, ticker] = weight\n",
    "                \n",
    "                elif strategy_type == 'market_neutral':\n",
    "                    # Seleccionar top y bottom n_positions/2\n",
    "                    long_tickers = valid_ranking.nlargest(n_positions//2).index\n",
    "                    short_tickers = valid_ranking.nsmallest(n_positions//2).index\n",
    "                    \n",
    "                    # Pesos iguales para long y short\n",
    "                    long_weights = np.ones(len(long_tickers)) / len(long_tickers)\n",
    "                    short_weights = -np.ones(len(short_tickers)) / len(short_tickers)\n",
    "                    \n",
    "                    # Asignar pesos\n",
    "                    self.portfolio.loc[rebalance_date, 'cash'] = 0.0\n",
    "                    for ticker, weight in zip(long_tickers, long_weights):\n",
    "                        self.portfolio.loc[rebalance_date, ticker] = weight\n",
    "                    \n",
    "                    for ticker, weight in zip(short_tickers, short_weights):\n",
    "                        self.portfolio.loc[rebalance_date, ticker] = weight\n",
    "                \n",
    "                # Mantener pesos hasta próximo rebalanceo\n",
    "                for date_idx in range(rebalance_idx+1, next_rebalance_idx):\n",
    "                    if date_idx < len(self.portfolio):\n",
    "                        date = self.portfolio.index[date_idx]\n",
    "                        self.portfolio.loc[date] = self.portfolio.loc[rebalance_date]\n",
    "            \n",
    "            # Forward fill para días restantes\n",
    "            self.portfolio.fillna(method='ffill', inplace=True)\n",
    "            \n",
    "            print(f\"Portafolio generado con estrategia {strategy_type}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en generate_portfolio: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def backtest_strategy(self):\n",
    "        \"\"\"Realiza backtest de la estrategia\"\"\"\n",
    "        try:\n",
    "            if self.portfolio.empty:\n",
    "                print(\"No hay portafolio para realizar backtest\")\n",
    "                return\n",
    "            \n",
    "            # Inicializar DataFrame de rendimientos\n",
    "            self.performance = pd.DataFrame(index=self.portfolio.index)\n",
    "            self.performance['daily_return'] = 0.0\n",
    "            self.performance['equity_curve'] = 1.0\n",
    "            \n",
    "            # Calcular rendimientos diarios para cada ticker\n",
    "            ticker_returns = {}\n",
    "            for ticker in self.portfolio.columns:\n",
    "                if ticker != 'cash' and ticker in self.market_data:\n",
    "                    # Alinear fechas\n",
    "                    common_dates = self.portfolio.index.intersection(self.market_data[ticker].index)\n",
    "                    if len(common_dates) > 0:\n",
    "                        ticker_returns[ticker] = self.market_data[ticker].loc[common_dates, 'returns']\n",
    "            \n",
    "            # Calcular rendimiento del portafolio\n",
    "            for i in range(1, len(self.portfolio)):\n",
    "                date = self.portfolio.index[i]\n",
    "                prev_date = self.portfolio.index[i-1]\n",
    "                \n",
    "                # Pesos del día anterior\n",
    "                weights = self.portfolio.loc[prev_date]\n",
    "                \n",
    "                # Rendimiento del día\n",
    "                daily_return = 0.0\n",
    "                \n",
    "                for ticker, weight in weights.items():\n",
    "                    if ticker == 'cash':\n",
    "                        # Rendimiento de efectivo (0)\n",
    "                        continue\n",
    "                    elif ticker in ticker_returns and date in ticker_returns[ticker].index:\n",
    "                        # Rendimiento ponderado\n",
    "                        ticker_return = ticker_returns[ticker].loc[date]\n",
    "                        if pd.notna(ticker_return):\n",
    "                            daily_return += weight * ticker_return\n",
    "                \n",
    "                # Guardar rendimiento diario\n",
    "                self.performance.loc[date, 'daily_return'] = daily_return\n",
    "                \n",
    "                # Actualizar equity curve\n",
    "                self.performance.loc[date, 'equity_curve'] = self.performance.loc[prev_date, 'equity_curve'] * (1 + daily_return)\n",
    "            \n",
    "            # Calcular métricas de rendimiento\n",
    "            self._calculate_performance_metrics()\n",
    "            \n",
    "            print(\"Backtest completado\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en backtest_strategy: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _calculate_performance_metrics(self):\n",
    "        \"\"\"Calcula métricas de rendimiento de la estrategia\"\"\"\n",
    "        try:\n",
    "            # Rendimientos diarios\n",
    "            returns = self.performance['daily_return']\n",
    "            \n",
    "            # Rendimiento acumulado\n",
    "            cumulative_return = self.performance['equity_curve'].iloc[-1] / self.performance['equity_curve'].iloc[0] - 1\n",
    "            \n",
    "            # Rendimiento anualizado\n",
    "            years = (self.performance.index[-1] - self.performance.index[0]).days / 365.25\n",
    "            annual_return = (1 + cumulative_return) ** (1 / years) - 1\n",
    "            \n",
    "            # Volatilidad anualizada\n",
    "            annual_volatility = returns.std() * np.sqrt(252)\n",
    "            \n",
    "            # Sharpe Ratio\n",
    "            sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            # Sortino Ratio (solo considera volatilidad negativa)\n",
    "            negative_returns = returns[returns < 0]\n",
    "            downside_deviation = negative_returns.std() * np.sqrt(252)\n",
    "            sortino_ratio = annual_return / downside_deviation if downside_deviation > 0 else 0\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            equity_curve = self.performance['equity_curve']\n",
    "            rolling_max = equity_curve.cummax()\n",
    "            drawdown = (equity_curve / rolling_max - 1)\n",
    "            max_drawdown = drawdown.min()\n",
    "            \n",
    "            # Calcular rendimientos del S&P 500 (SPY) para comparación\n",
    "            if 'SPY' in self.market_data:\n",
    "                spy_returns = self.market_data['SPY']['returns']\n",
    "                common_dates = self.performance.index.intersection(spy_returns.index)\n",
    "                \n",
    "                if len(common_dates) > 0:\n",
    "                    spy_returns = spy_returns.loc[common_dates]\n",
    "                    \n",
    "                    # Equity curve del S&P 500\n",
    "                    spy_equity = (1 + spy_returns).cumprod()\n",
    "                    spy_equity = spy_equity / spy_equity.iloc[0]\n",
    "                    \n",
    "                    # Rendimiento acumulado del S&P 500\n",
    "                    spy_cumulative_return = spy_equity.iloc[-1] / spy_equity.iloc[0] - 1\n",
    "                    \n",
    "                    # Rendimiento anualizado del S&P 500\n",
    "                    spy_annual_return = (1 + spy_cumulative_return) ** (1 / years) - 1\n",
    "                    \n",
    "                    # Volatilidad anualizada del S&P 500\n",
    "                    spy_annual_volatility = spy_returns.std() * np.sqrt(252)\n",
    "                    \n",
    "                    # Sharpe Ratio del S&P 500\n",
    "                    spy_sharpe_ratio = spy_annual_return / spy_annual_volatility if spy_annual_volatility > 0 else 0\n",
    "                    \n",
    "                    # Maximum Drawdown del S&P 500\n",
    "                    spy_rolling_max = spy_equity.cummax()\n",
    "                    spy_drawdown = (spy_equity / spy_rolling_max - 1)\n",
    "                    spy_max_drawdown = spy_drawdown.min()\n",
    "                    \n",
    "                    # Information Ratio\n",
    "                    excess_returns = returns - spy_returns\n",
    "                    tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "                    information_ratio = (annual_return - spy_annual_return) / tracking_error if tracking_error > 0 else 0\n",
    "                    \n",
    "                    # Beta\n",
    "                    covariance = returns.cov(spy_returns)\n",
    "                    variance = spy_returns.var()\n",
    "                    beta = covariance / variance if variance > 0 else 0\n",
    "                    \n",
    "                    # Alpha anualizado\n",
    "                    alpha = annual_return - (0.02 + beta * (spy_annual_return - 0.02))  # Asumiendo tasa libre de riesgo de 2%\n",
    "                    \n",
    "                    # Captura alcista/bajista\n",
    "                    up_markets = spy_returns[spy_returns > 0]\n",
    "                    down_markets = spy_returns[spy_returns < 0]\n",
    "                    \n",
    "                    strategy_up = returns.loc[up_markets.index]\n",
    "                    strategy_down = returns.loc[down_markets.index]\n",
    "                    \n",
    "                    up_capture = strategy_up.mean() / up_markets.mean() if up_markets.mean() > 0 else 0\n",
    "                    down_capture = strategy_down.mean() / down_markets.mean() if down_markets.mean() < 0 else 0\n",
    "                    \n",
    "                    # Guardar métricas de comparación\n",
    "                    self.performance_metrics = {\n",
    "                        'Cumulative Return': cumulative_return,\n",
    "                        'Annual Return': annual_return,\n",
    "                        'Annual Volatility': annual_volatility,\n",
    "                        'Sharpe Ratio': sharpe_ratio,\n",
    "                        'Sortino Ratio': sortino_ratio,\n",
    "                        'Maximum Drawdown': max_drawdown,\n",
    "                        'SPY Cumulative Return': spy_cumulative_return,\n",
    "                        'SPY Annual Return': spy_annual_return,\n",
    "                        'SPY Annual Volatility': spy_annual_volatility,\n",
    "                        'SPY Sharpe Ratio': spy_sharpe_ratio,\n",
    "                        'SPY Maximum Drawdown': spy_max_drawdown,\n",
    "                        'Information Ratio': information_ratio,\n",
    "                        'Beta': beta,\n",
    "                        'Alpha': alpha,\n",
    "                        'Up Capture': up_capture,\n",
    "                        'Down Capture': down_capture\n",
    "                    }\n",
    "                else:\n",
    "                    # Métricas sin comparación con SPY\n",
    "                    self.performance_metrics = {\n",
    "                        'Cumulative Return': cumulative_return,\n",
    "                        'Annual Return': annual_return,\n",
    "                        'Annual Volatility': annual_volatility,\n",
    "                        'Sharpe Ratio': sharpe_ratio,\n",
    "                        'Sortino Ratio': sortino_ratio,\n",
    "                        'Maximum Drawdown': max_drawdown\n",
    "                    }\n",
    "            else:\n",
    "                # Métricas sin comparación con SPY\n",
    "                self.performance_metrics = {\n",
    "                    'Cumulative Return': cumulative_return,\n",
    "                    'Annual Return': annual_return,\n",
    "                    'Annual Volatility': annual_volatility,\n",
    "                    'Sharpe Ratio': sharpe_ratio,\n",
    "                    'Sortino Ratio': sortino_ratio,\n",
    "                    'Maximum Drawdown': max_drawdown\n",
    "                }\n",
    "            \n",
    "            # Guardar métricas en CSV\n",
    "            metrics_df = pd.DataFrame(list(self.performance_metrics.items()), columns=['Metric', 'Value'])\n",
    "            metrics_df.to_csv('./artifacts/results/performance_metrics.csv', index=False)\n",
    "            \n",
    "            print(\"Métricas de rendimiento calculadas y guardadas\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en _calculate_performance_metrics: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_reports(self):\n",
    "        \"\"\"Genera reportes y visualizaciones de la estrategia\"\"\"\n",
    "        try:\n",
    "            if not hasattr(self, 'performance_metrics'):\n",
    "                print(\"No hay métricas de rendimiento para generar reportes\")\n",
    "                return\n",
    "            \n",
    "            # 1. Gráfico de equity curve\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(self.performance.index, self.performance['equity_curve'], label='Estrategia')\n",
    "            \n",
    "            # Añadir SPY para comparación\n",
    "            if 'SPY' in self.market_data:\n",
    "                spy_returns = self.market_data['SPY']['returns']\n",
    "                common_dates = self.performance.index.intersection(spy_returns.index)\n",
    "                \n",
    "                if len(common_dates) > 0:\n",
    "                    spy_returns = spy_returns.loc[common_dates]\n",
    "                    spy_equity = (1 + spy_returns).cumprod()\n",
    "                    spy_equity = spy_equity / spy_equity.iloc[0]\n",
    "                    \n",
    "                    plt.plot(common_dates, spy_equity, label='S&P 500', alpha=0.7)\n",
    "            \n",
    "            plt.title('Equity Curve')\n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('Valor')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/equity_curve.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # 2. Gráfico de drawdown\n",
    "            equity_curve = self.performance['equity_curve']\n",
    "            rolling_max = equity_curve.cummax()\n",
    "            drawdown = (equity_curve / rolling_max - 1) * 100  # En porcentaje\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(self.performance.index, drawdown)\n",
    "            plt.fill_between(self.performance.index, drawdown, 0, alpha=0.3, color='red')\n",
    "            plt.title('Drawdown')\n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('Drawdown (%)')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/drawdown.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # 3. Gráfico de rendimientos mensuales\n",
    "            if len(self.performance) > 30:\n",
    "                # Convertir a rendimientos mensuales\n",
    "                monthly_returns = self.performance['daily_return'].resample('M').apply(\n",
    "                    lambda x: (1 + x).prod() - 1\n",
    "                ) * 100  # En porcentaje\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                monthly_returns.plot(kind='bar', color=np.where(monthly_returns >= 0, 'green', 'red'))\n",
    "                plt.title('Rendimientos Mensuales')\n",
    "                plt.xlabel('Fecha')\n",
    "                plt.ylabel('Rendimiento (%)')\n",
    "                plt.grid(True, axis='y')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('./artifacts/results/figures/monthly_returns.png')\n",
    "                plt.close()\n",
    "            \n",
    "            # 4. Gráfico de distribución de rendimientos diarios\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.histplot(self.performance['daily_return'] * 100, kde=True, bins=50)\n",
    "            plt.axvline(0, color='red', linestyle='--')\n",
    "            plt.title('Distribución de Rendimientos Diarios')\n",
    "            plt.xlabel('Rendimiento Diario (%)')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/return_distribution.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # 5. Gráfico de exposición por posición\n",
    "            if len(self.portfolio.columns) > 1:\n",
    "                # Calcular exposición absoluta total por día\n",
    "                self.portfolio['total_exposure'] = self.portfolio.drop(columns=['cash']).abs().sum(axis=1)\n",
    "                \n",
    "                # Seleccionar algunas fechas representativas\n",
    "                dates = self.portfolio.index[::len(self.portfolio)//10]  # 10 fechas\n",
    "                \n",
    "                exposures = []\n",
    "                for date in dates:\n",
    "                    # Normalizar pesos por exposición total\n",
    "                    weights = self.portfolio.loc[date].drop(['cash', 'total_exposure'])\n",
    "                    abs_weights = weights.abs() / self.portfolio.loc[date, 'total_exposure'] if self.portfolio.loc[date, 'total_exposure'] > 0 else weights.abs()\n",
    "                    \n",
    "                    # Ordenar por magnitud\n",
    "                    sorted_weights = abs_weights.sort_values(ascending=False)\n",
    "                    \n",
    "                    # Tomar top 10\n",
    "                    top_weights = sorted_weights.head(10)\n",
    "                    \n",
    "                    # Guardar para gráfico\n",
    "                    for ticker, weight in top_weights.items():\n",
    "                        sign = np.sign(weights[ticker])\n",
    "                        exposures.append({\n",
    "                            'Date': date,\n",
    "                            'Ticker': ticker,\n",
    "                            'Weight': weight * 100,  # En porcentaje\n",
    "                            'Direction': 'Long' if sign > 0 else 'Short'\n",
    "                        })\n",
    "                \n",
    "                if exposures:\n",
    "                    exposure_df = pd.DataFrame(exposures)\n",
    "                    \n",
    "                    plt.figure(figsize=(14, 8))\n",
    "                    for i, date in enumerate(exposure_df['Date'].unique()):\n",
    "                        date_df = exposure_df[exposure_df['Date'] == date]\n",
    "                        \n",
    "                        plt.subplot(2, 5, i+1)\n",
    "                        colors = ['green' if d == 'Long' else 'red' for d in date_df['Direction']]\n",
    "                        plt.barh(date_df['Ticker'], date_df['Weight'], color=colors)\n",
    "                        plt.title(date.strftime('%Y-%m-%d'))\n",
    "                        plt.xlabel('Peso (%)')\n",
    "                        plt.grid(True, axis='x')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig('./artifacts/results/figures/position_exposure.png')\n",
    "                    plt.close()\n",
    "                \n",
    "                # Eliminar columna auxiliar\n",
    "                self.portfolio.drop(columns=['total_exposure'], inplace=True)\n",
    "            \n",
    "            # 6. Tabla de métricas de rendimiento\n",
    "            metrics_table = pd.DataFrame(list(self.performance_metrics.items()), columns=['Metric', 'Value'])\n",
    "            metrics_table['Value'] = metrics_table['Value'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.axis('off')\n",
    "            plt.table(cellText=metrics_table.values, colLabels=metrics_table.columns, loc='center', cellLoc='center')\n",
    "            plt.title('Métricas de Rendimiento')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/performance_metrics.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # 7. Guardar datos de rendimiento\n",
    "            self.performance.to_csv('./artifacts/results/data/performance_data.csv')\n",
    "            \n",
    "            # 8. Guardar portafolio\n",
    "            self.portfolio.to_csv('./artifacts/results/data/portfolio_weights.csv')\n",
    "            \n",
    "            print(\"Reportes generados y guardados\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en generate_reports: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def run_strategy(self, strategy_type='long_only'):\n",
    "        \"\"\"\n",
    "        Ejecuta la estrategia completa\n",
    "        \n",
    "        Args:\n",
    "            strategy_type: 'long_only' o 'market_neutral'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Iniciando estrategia de ranking adaptativo multifactorial...\")\n",
    "            \n",
    "            # 1. Obtener datos de mercado\n",
    "            print(\"\\n1. Obteniendo datos de mercado...\")\n",
    "            self.fetch_market_data()\n",
    "            \n",
    "            # 2. Generar características\n",
    "            print(\"\\n2. Generando características adaptativas...\")\n",
    "            self.generate_features()\n",
    "            \n",
    "            # 3. Normalizar características\n",
    "            print(\"\\n3. Normalizando características...\")\n",
    "            self.normalize_features()\n",
    "            \n",
    "            # 4. Reducir dimensionalidad\n",
    "            print(\"\\n4. Reduciendo dimensionalidad...\")\n",
    "            self.reduce_dimensions()\n",
    "            \n",
    "            # 5. Calcular rankings\n",
    "            print(\"\\n5. Calculando rankings...\")\n",
    "            self.calculate_rankings()\n",
    "            \n",
    "            # 6. Generar portafolio\n",
    "            print(f\"\\n6. Generando portafolio ({strategy_type})...\")\n",
    "            self.generate_portfolio(strategy_type)\n",
    "            \n",
    "            # 7. Realizar backtest\n",
    "            print(\"\\n7. Realizando backtest...\")\n",
    "            self.backtest_strategy()\n",
    "            \n",
    "            # 8. Generar reportes\n",
    "            print(\"\\n8. Generando reportes...\")\n",
    "            self.generate_reports()\n",
    "            \n",
    "            print(\"\\nEstrategia completada con éxito!\")\n",
    "            \n",
    "            # Mostrar resumen de rendimiento\n",
    "            print(\"\\nResumen de rendimiento:\")\n",
    "            for metric, value in self.performance_metrics.items():\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error ejecutando estrategia: {str(e)}\")\n",
    "            print(f\"Error ejecutando estrategia: {str(e)}\")\n",
    "            raise\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def information_coefficient(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula el Information Coefficient (IC), que es la correlación de Pearson entre predicciones y valores reales.\n",
    "    \"\"\"\n",
    "    return pearsonr(y_true, y_pred)[0] \n",
    "# Ejecutar estrategia\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Definir período de backtest\n",
    "        start_date = '2018-01-01'\n",
    "        end_date = '2023-12-31'\n",
    "        \n",
    "        # Inicializar sistema\n",
    "        system = AdaptiveMultifactorRankingSystem(start_date=start_date, end_date=end_date)\n",
    "        \n",
    "        # Ejecutar estrategia\n",
    "        system.run_strategy(strategy_type='long_only')\n",
    "        \n",
    "        print(\"Estrategia ejecutada correctamente\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en ejecución principal: {str(e)}\")\n",
    "        print(f\"Error en ejecución principal: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da82095d-c28d-4f5a-a036-5c6890e35d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55eeb8-4003-4523-96db-cd71b5d1bf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
