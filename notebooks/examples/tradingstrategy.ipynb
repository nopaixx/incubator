{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c57e66-c2dc-4e52-9c0d-a0fd165c8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Añadir el directorio raíz al path para importar los módulos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbddc2b-dc89-4141-815c-dffa3a6e4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde4d36d-86d2-4c1d-a678-78b5bbce0af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Workflow contains cycles\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid workflow graph",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 229\u001b[39m\n\u001b[32m    219\u001b[39m strategy_workflow = create_trading_strategy_workflow()\n\u001b[32m    221\u001b[39m strategy_inputs = {\n\u001b[32m    222\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexplorer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[33m    I want to generate a dataset of unique and genuine features. The objective is to later train a ranking model,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    226\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    227\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m strategy_results = \u001b[43mstrategy_workflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Save configurations\u001b[39;00m\n\u001b[32m    232\u001b[39m workflow.save(\u001b[33m\"\u001b[39m\u001b[33mcontent_analysis_workflow.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/startup/incubator/incubator/wf/wf.py:125\u001b[39m, in \u001b[36mWorkflowEngine.execute\u001b[39m\u001b[34m(self, inputs, context)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03mExecute the workflow with the given inputs\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m \u001b[33;03m    Dictionary mapping output node IDs to their port outputs\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.validate():\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid workflow graph\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Check that all input keys are valid input nodes\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m inputs.keys():\n",
      "\u001b[31mValueError\u001b[39m: Invalid workflow graph"
     ]
    }
   ],
   "source": [
    "# Example: Implementation for a trading strategy workflow\n",
    "import os\n",
    "import anthropic\n",
    "from typing import List, Dict, Optional, Any, Tuple, Set, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import networkx as nx\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"../\")))\n",
    "load_dotenv()\n",
    "\n",
    "from incubator.wf.wf import WorkflowEngine, Node\n",
    "from incubator.wf.node import Node\n",
    "\n",
    "from incubator.llm.antropic import AnthropicClient\n",
    "from incubator.agents.agent import Agent\n",
    "def create_trading_strategy_workflow(api_key: Optional[str] = None) -> WorkflowEngine:\n",
    "    \"\"\"\n",
    "    Create a workflow for generating trading strategies\n",
    "    \n",
    "    Args:\n",
    "        api_key: Anthropic API key (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Configured WorkflowEngine\n",
    "    \"\"\"\n",
    "    # Create the LLM client\n",
    "    llm_client = AnthropicClient(api_key)\n",
    "    \n",
    "    # Create the workflow engine\n",
    "    workflow = WorkflowEngine()\n",
    "    \n",
    "    # Define agents\n",
    "    explorer = Agent(\n",
    "        name=\"Explorer\",\n",
    "        description=\"Generates original quantitative strategy ideas\",\n",
    "        llm_client=llm_client,\n",
    "        system_prompt=\"\"\"\n",
    "        You are the Explorer Agent in a quantitative strategy incubation system.\n",
    "        Your specialty is generating innovative algorithmic strategies focused on the S&P 500.\n",
    "        \n",
    "        IMPORTANT: Generate ONE quantitative strategy idea per iteration, not multiple.\n",
    "        \n",
    "        Your function is to:\n",
    "        \n",
    "        1. Generate ONE innovative and detailed quantitative strategy idea for trading the S&P 500\n",
    "        2. Explain the mathematical/statistical foundations and how the strategy works\n",
    "        3. Detail specific signals, timeframes, factors, and metrics to use\n",
    "        4. Highlight potential advantages of the strategy (alpha, Sharpe, drawdown, etc.)\n",
    "        5. Respond to questions or suggestions from the Curator\n",
    "        \n",
    "        Consider aspects such as:\n",
    "        - Market factors (momentum, value, volatility, etc.)\n",
    "        - Statistical analyses (cointegration, regression, clustering)\n",
    "        - Innovative technical or fundamental indicators\n",
    "        - Execution optimization and transaction cost management\n",
    "        - Risk management and strategy diversification\n",
    "        - Avoid hardcoded values\n",
    "        - Consider self-adaptation and statistical or ML predictive models\n",
    "        - Avoid thresholds or hardcoded values, use optimizations, inferences, or self-adaptive strategies\n",
    "        \n",
    "        Technical limitations:\n",
    "        - The strategy should be implementable in Python using the yfinance library for data\n",
    "        - Do not provide code, only the logic and detailed methodology\n",
    "        - The idea will move to the next development level where it will be implemented\n",
    "        \n",
    "        Be specific, technical, and detailed. Think of implementable and backtestable strategies.\n",
    "        \"\"\",\n",
    "        config={\n",
    "            \"temperature\": 0.8,\n",
    "            \"use_thinking\": False,\n",
    "            \"max_tokens\": 15000\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    curator = Agent(\n",
    "        name=\"Curator\",\n",
    "        description=\"Evaluates quantitative strategies and selects the most promising one\",\n",
    "        llm_client=llm_client,\n",
    "        system_prompt=\"\"\"\n",
    "        You are the Curator Agent in a quantitative strategy incubation system.\n",
    "        You have extensive experience evaluating algorithmic strategies focused on the S&P 500.\n",
    "        Your function is to evaluate the strategy proposed by the Explorer and suggest specific improvements. You must:\n",
    "        \n",
    "        1. Critically analyze the strategy considering:\n",
    "           - Expected Sharpe ratio and statistical robustness\n",
    "           - Ability to generate true alpha (not disguised beta)\n",
    "           - Scalability and capacity (how much capital it can handle)\n",
    "           - Implementation and transaction costs\n",
    "           - Exposure to known risk factors\n",
    "           - Risk of overoptimization or data snooping\n",
    "           - Feasibility of implementation with yfinance in Python\n",
    "           - Ease of implementation and evaluation\n",
    "        \n",
    "        2. Propose specific technical improvements such as:\n",
    "           - Backtest and walk forward analysis\n",
    "           - Avoiding look-ahead bias\n",
    "           - Parameter or signal refinement\n",
    "           - Risk management improvements\n",
    "           - Execution optimization\n",
    "           - Complements with other factors or signals\n",
    "           - Avoiding thresholds or hardcoded values, use optimizations, inferences, or self-adaptive strategies\n",
    "        \n",
    "        3. Formulate specific technical questions to clarify ambiguous aspects\n",
    "        \n",
    "        Technical limitations:\n",
    "        - The strategy should be implementable in Python using the yfinance library for data\n",
    "        - Do not provide code, only conceptual improvements and recommendations\n",
    "        - The idea will move to the next development level where it will be implemented\n",
    "        \n",
    "        Maintain a rigorous and skeptical approach, as an experienced risk manager would.\n",
    "\n",
    "        YOUR TASK IS TO ITERATE THE IDEA AND DESCRIBE THE FINAL IDEA BUT AVOID SHOWING CODE AS MUCH AS POSSIBLE.\n",
    "        DEVELOPING THE CODE IS THE TASK OF ANOTHER SPECIALIZED DEVELOPMENT AGENT.\n",
    "        \n",
    "        IMPORTANT: If this is the final iteration (you will be informed in the message), you must finish with a\n",
    "        detailed and technically sound version of the strategy, ready to be implemented in Python with yfinance.\n",
    "        In that case, include:\n",
    "           - Exact entry/exit logic\n",
    "           - Specific parameters\n",
    "           - Risk management\n",
    "           - Performance expectations\n",
    "           - Metrics\n",
    "           - Backtest and walk-forward, look-ahead bias, etc.\n",
    "           - Technical implementation considerations\n",
    "        \n",
    "        When providing the final version, start your response with \"FINAL IDEA:\".\n",
    "        \"\"\",\n",
    "        config={\n",
    "            \"temperature\": 0.5,\n",
    "            \"use_thinking\": True,\n",
    "            \"thinking_budget\": 16000,\n",
    "            \"max_tokens\": 32000\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    developer = Agent(\n",
    "        name=\"Developer\",\n",
    "        description=\"Implements the strategy in Python code using yfinance\",\n",
    "        llm_client=llm_client,\n",
    "        system_prompt=\"\"\"\n",
    "        You are the Developer Agent in a quantitative strategy implementation system.\n",
    "        Your specialty is converting strategy ideas into functional Python code using the yfinance library.\n",
    "        \n",
    "        You must implement the provided strategy as a complete and functional Python program. Your code should:\n",
    "        \n",
    "        1. Use the yfinance library to obtain S&P 500 data\n",
    "        2. Implement the exact logic described in the strategy\n",
    "        3. Generate and save performance metrics, charts, and analysis\n",
    "        4. Avoid thresholds and hardcoded parameters, use optimization or self-adaptive inference\n",
    "        5. Handle errors and validate data properly\n",
    "        6. Be well documented with clear comments\n",
    "        7. Implement all described methods including backtest and walk-forward\n",
    "        8. Avoid look-ahead bias and biases when using future data that you wouldn't have in a real implementation\n",
    "        9. Be concise in the code at this stage\n",
    "        \n",
    "        NOTE TO THE DEVELOPER\n",
    "        yfinance has auto_adjust=True by default in the installed version\n",
    "        recent example of yfinance version installed yf.download(stock, start=start_date, end=end_date)['Close'] # auto_adjust=True by default\n",
    "        \n",
    "        # Create directories for results\n",
    "        os.makedirs('./artifacts/results', exist_ok=True)\n",
    "        os.makedirs('./artifacts/results/figures', exist_ok=True)\n",
    "        os.makedirs('./artifacts/results/data', exist_ok=True)\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(\n",
    "            filename='./artifacts/errors.txt',\n",
    "            level=logging.ERROR,\n",
    "            format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        **Pay attention to typical pandas series errors with scalars and NaN**\n",
    "        \n",
    "        IMPORTANT - OUTPUT FORMAT:\n",
    "        1. Present your code within <python>CODE</python> tags\n",
    "        2. All results, charts, and output files such as metrics in csv or txt should be saved in the './artifacts/results/' folder\n",
    "        3. Capture errors and save them in the './artifacts/errors.txt' file\n",
    "        \n",
    "        Your code must ensure that:\n",
    "        - All necessary folders are created if they don't exist\n",
    "        - Performance metrics (Sharpe, drawdown, etc.) are saved in CSV files\n",
    "        - Visualizations (performance charts, signals, etc.) are generated\n",
    "        - Errors are properly handled and logged in a log file within './artifacts/errors.txt'\n",
    "        \n",
    "        **provide a full error traceback into ./artifacts/error.txt for future improvements**\n",
    "        \n",
    "        Provide a complete Python program, ready to run, that optimally implements the strategy.\n",
    "        \"\"\",\n",
    "        config={\n",
    "            \"temperature\": 0.2,\n",
    "            \"use_thinking\": False,\n",
    "            \"max_tokens\": 25000\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create nodes\n",
    "    explorer_node = Node(id=\"explorer\", agent=explorer)\n",
    "    curator_node = Node(id=\"curator\", agent=curator)\n",
    "    developer_node = Node(id=\"developer\", agent=developer)\n",
    "    \n",
    "    # Add nodes to the workflow\n",
    "    workflow.add_node(explorer_node, is_input=True, is_output=False)\n",
    "    workflow.add_node(curator_node, is_input=False, is_output=False)\n",
    "    workflow.add_node(developer_node, is_input=False, is_output=True)\n",
    "    \n",
    "    # Add edges to define the communication flow\n",
    "    workflow.add_edge(\"explorer\", \"curator\")\n",
    "    workflow.add_edge(\"curator\", \"explorer\")  # Feedback loop\n",
    "    workflow.add_edge(\"curator\", \"developer\")  # Final output goes to developer\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Example: Create and use the trading strategy workflow from before\n",
    "strategy_workflow = create_trading_strategy_workflow()\n",
    "\n",
    "strategy_inputs = {\n",
    "    \"explorer\": \"\"\"\n",
    "    I want to generate a dataset of unique and genuine features. The objective is to later train a ranking model,\n",
    "    but I want to generate a list of unique features for each stock in the S&P 500. Please design the features \n",
    "    and unique calculations.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "strategy_results = strategy_workflow.execute(strategy_inputs)\n",
    "\n",
    "# Save configurations\n",
    "workflow.save(\"content_analysis_workflow.json\")\n",
    "strategy_workflow.save(\"trading_strategy_workflow.json\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55e337f-9406-446a-9b0e-fad29c71a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando flujo de trabajo para estrategias en dominio: trading algorítmico de alta frecuencia en criptomonedas...\n",
      "[WorkflowEngine] Processing node: implementation\n",
      "[WorkflowEngine] Node implementation processed with output ports: ['default']\n",
      "[WorkflowEngine] Processing node: evaluation\n",
      "[WorkflowEngine] Node evaluation processed with output ports: ['default']\n",
      "\n",
      "Resultados guardados en el directorio 'resultados_estrategia_trading_algorítmico_de_alta_frecuencia_en_criptomonedas'\n",
      "\n",
      "=== VEREDICTO FINAL ===\n",
      "ESTRATEGIA CON AJUSTES: La estrategia muestra potencial pero necesita ajustes.**\n",
      "\n",
      "=== RESUMEN DE EVALUACIÓN ===\n",
      "# Evaluación de Estrategia Cuantitativa\n",
      "\n",
      "## 1. Calidad del código\n",
      "\n",
      "### Modularidad y organización\n",
      "- **Excelente estructura**: El código está muy bien organizado en secciones lógicas y funciones modulares.\n",
      "- **Separación de responsabilidades**: Clara distinción entre simulación de datos, cálculo de características, generación de señales, backtesting y visualización.\n",
      "- **Flujo de trabajo coherente**: La función `main()` integra todas las partes de manera limpia y secuencial.\n",
      "\n",
      "### Documentación\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Optional, Any, Tuple, Set, Callable\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "import traceback\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"../\")))\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Asegurarse de que puede encontrar el módulo incubator\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"../\")))\n",
    "\n",
    "from incubator.llm.antropic import AnthropicClient\n",
    "from incubator.agents.agent import Agent\n",
    "from incubator.wf.wf import WorkflowEngine\n",
    "from incubator.wf.dialognode import IterativeDialogNode\n",
    "from incubator.messages.message import Message\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(name)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "def setup_dialog_workflow(domain: str, api_key=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Configura un flujo de trabajo genérico con dos agentes que dialogan\n",
    "    \n",
    "    Args:\n",
    "        domain: Dominio específico para configurar los agentes\n",
    "        api_key: Clave API de Anthropic (opcional, usa la variable de entorno si no se proporciona)\n",
    "        verbose: Si se debe mostrar información detallada durante la ejecución\n",
    "        \n",
    "    Returns:\n",
    "        tuple: El motor de flujo de trabajo y el nodo de diálogo\n",
    "    \"\"\"\n",
    "    # Cargar variables de entorno para la API KEY\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Usar API key de entorno si no se proporciona\n",
    "    api_key = api_key or os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"No se encontró la variable de entorno ANTHROPIC_API_KEY\")\n",
    "    \n",
    "    # Crear cliente LLM\n",
    "    llm_client = AnthropicClient(api_key=api_key)\n",
    "    \n",
    "    # Crear agente generador\n",
    "    generator = Agent(\n",
    "        name=\"Generator\",\n",
    "        description=f\"Generador de contenido para {domain}\",\n",
    "        llm_client=llm_client,\n",
    "        system_prompt=f\"\"\"\n",
    "        Eres un generador especializado de contenido para el dominio de {domain}.\n",
    "        \n",
    "        Tu tarea es crear propuestas originales, detalladas y bien fundamentadas\n",
    "        basadas en el input inicial. Debes:\n",
    "        \n",
    "        1. Analizar el contexto y requisitos proporcionados\n",
    "        2. Generar contenido relevante con detalles específicos\n",
    "        3. Incorporar perspectivas innovadoras y consideraciones importantes\n",
    "        4. Responder constructivamente a las críticas y sugerencias del Evaluador\n",
    "        \n",
    "        Sé creativo, preciso y completo en tus propuestas.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Crear agente evaluador\n",
    "    evaluator = Agent(\n",
    "        name=\"Evaluator\",\n",
    "        description=f\"Evaluador de contenido para {domain}\",\n",
    "        llm_client=llm_client,\n",
    "        system_prompt=f\"\"\"\n",
    "        Eres un evaluador especializado de contenido para el dominio de {domain}.\n",
    "        \n",
    "        Tu tarea es analizar críticamente las propuestas del Generador y\n",
    "        proporcionar retroalimentación constructiva para mejorarlas. Debes:\n",
    "        \n",
    "        1. Evaluar la calidad, originalidad y relevancia del contenido\n",
    "        2. Identificar puntos fuertes y áreas de mejora\n",
    "        3. Sugerir modificaciones específicas y adiciones\n",
    "        4. Plantear preguntas que provoquen más desarrollo\n",
    "        \n",
    "        En la iteración final (o cuando consideres que el contenido está listo),\n",
    "        debes presentar tu conclusión marcándola claramente con \"CONCLUSIÓN:\"\n",
    "        seguida de tu evaluación final y cualquier recomendación adicional.\n",
    "        \n",
    "        Sé analítico, específico y constructivo en tus evaluaciones.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Crear nodo de diálogo\n",
    "    dialog_node = IterativeDialogNode(\n",
    "        id=\"generator_evaluator_dialog\",\n",
    "        agent_a=generator,\n",
    "        agent_b=evaluator,\n",
    "        max_iterations=3,  # Máximo 3 intercambios\n",
    "        terminate_on_keywords=[\"CONCLUSIÓN:\"],  # Terminar si se encuentra esta frase\n",
    "        content_markers={\"conclusion\": \"CONCLUSIÓN:\"},  # Definir marcadores de contenido\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Configurar flujo de trabajo\n",
    "    workflow = WorkflowEngine(debug=verbose)\n",
    "    workflow.add_node(dialog_node, is_input=True, is_output=True)\n",
    "    \n",
    "    return workflow, dialog_node\n",
    "\n",
    "def run_dialog_workflow(initial_prompt, domain=\"general\", output_dir=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Ejecuta un flujo de trabajo con diálogo entre generador y evaluador\n",
    "    \n",
    "    Args:\n",
    "        initial_prompt: Prompt inicial para el diálogo\n",
    "        domain: Dominio específico para los agentes\n",
    "        output_dir: Directorio para guardar resultados (opcional)\n",
    "        verbose: Si se debe mostrar información detallada\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultados del flujo de trabajo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Mostrar mensaje de inicio\n",
    "        if verbose:\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Iniciando diálogo en dominio '{domain}' con prompt: '{initial_prompt}'\")\n",
    "            print(f\"{'=' * 50}\\n\")\n",
    "        \n",
    "        # Configurar el flujo de trabajo\n",
    "        workflow, dialog_node = setup_dialog_workflow(domain, verbose=verbose)\n",
    "        \n",
    "        # Ejecutar el flujo de trabajo\n",
    "        if verbose:\n",
    "            print(\"Ejecutando diálogo entre Generador y Evaluador...\\n\")\n",
    "            \n",
    "        results = workflow.execute({\"generator_evaluator_dialog\": initial_prompt})\n",
    "        \n",
    "        # Procesar y mostrar resultados\n",
    "        processed_results = {}\n",
    "        \n",
    "        if \"generator_evaluator_dialog\" in results:\n",
    "            outputs = results[\"generator_evaluator_dialog\"]\n",
    "            \n",
    "            # Procesamiento de múltiples salidas\n",
    "            for port_name, port_data in outputs.items():\n",
    "                processed_results[port_name] = port_data[\"content\"]\n",
    "            \n",
    "            # Mostrar resumen de puertos disponibles\n",
    "            if verbose:\n",
    "                print(\"\\n===== PUERTOS DE SALIDA DISPONIBLES =====\")\n",
    "                for port in outputs.keys():\n",
    "                    print(f\"- {port}\")\n",
    "            \n",
    "            # Mostrar conclusión si está disponible\n",
    "            if \"conclusion\" in outputs:\n",
    "                if verbose:\n",
    "                    print(\"\\n===== CONCLUSIÓN =====\")\n",
    "                    print(outputs[\"conclusion\"][\"content\"])\n",
    "            \n",
    "            # Mostrar respuesta final del evaluador\n",
    "            if \"evaluator_final\" in outputs:\n",
    "                if verbose:\n",
    "                    print(\"\\n===== EVALUACIÓN FINAL =====\")\n",
    "                    print(outputs[\"evaluator_final\"][\"content\"])\n",
    "            \n",
    "            # Mostrar resumen del diálogo\n",
    "            if \"summary\" in outputs:\n",
    "                try:\n",
    "                    summary_data = json.loads(outputs[\"summary\"][\"content\"])\n",
    "                    if verbose:\n",
    "                        print(\"\\n===== RESUMEN DEL DIÁLOGO =====\")\n",
    "                        print(f\"Iteraciones completadas: {summary_data.get('iterations_completed', 'N/A')}\")\n",
    "                        print(f\"Mensajes intercambiados: {summary_data.get('message_count', 0)}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "        \n",
    "        # Guardar resultados si se especificó un directorio\n",
    "        if output_dir:\n",
    "            save_results(processed_results, domain, output_dir)\n",
    "        \n",
    "        return processed_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error en la ejecución del flujo de trabajo: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def save_results(results, domain, output_dir):\n",
    "    \"\"\"\n",
    "    Guarda los resultados en archivos\n",
    "    \n",
    "    Args:\n",
    "        results: Resultados a guardar\n",
    "        domain: Dominio del diálogo\n",
    "        output_dir: Directorio base para guardar los resultados\n",
    "    \"\"\"\n",
    "    # Crear directorio con timestamp para evitar sobrescribir\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    domain_safe = domain.lower().replace(\" \", \"_\")\n",
    "    full_dir = os.path.join(output_dir, f\"dialog_{domain_safe}_{timestamp}\")\n",
    "    os.makedirs(full_dir, exist_ok=True)\n",
    "    \n",
    "    # Guardar cada resultado en un archivo separado\n",
    "    for key, content in results.items():\n",
    "        # Omitir contenido no string (como diccionarios)\n",
    "        if not isinstance(content, str):\n",
    "            continue\n",
    "            \n",
    "        filename = f\"{key.replace('_', '-')}.txt\"\n",
    "        if key == \"summary\":\n",
    "            filename = \"summary.json\"\n",
    "            \n",
    "        with open(os.path.join(full_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "    \n",
    "    # Guardar todos los resultados\n",
    "    with open(os.path.join(full_dir, \"resultados_completos.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        # Filtrar para solo incluir datos serializables\n",
    "        serializable = {}\n",
    "        for k, v in results.items():\n",
    "            if isinstance(v, (str, int, float, bool, list, dict)):\n",
    "                serializable[k] = v\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    \n",
    "    print(f\"Resultados guardados en: {full_dir}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Directorio para guardar resultados\n",
    "    results_dir = \"resultados_dialogo\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Solicitar dominio y prompt inicial\n",
    "    domain = input(\"Introduce un dominio para el diálogo (por ejemplo, 'marketing', 'programación', etc.): \")\n",
    "    if not domain:\n",
    "        domain = \"estrategias de marketing digital\"\n",
    "    \n",
    "    prompt = input(\"Introduce un prompt inicial para el diálogo: \")\n",
    "    if not prompt:\n",
    "        prompt = f\"Desarrolla una estrategia innovadora de {domain} para una startup tecnológica\"\n",
    "    \n",
    "    # Ejecutar el flujo de trabajo\n",
    "    results = run_dialog_workflow(\n",
    "        initial_prompt=prompt,\n",
    "        domain=domain,\n",
    "        output_dir=results_dir,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Mostrar ruta de los resultados guardados\n",
    "    if \"error\" not in results:\n",
    "        print(\"\\nProceso completado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae2ff6-7487-473a-8214-2b7ad4048057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
