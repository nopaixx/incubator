{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676e4815-b610-49b5-bdf4-8870511358ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sistema de Arbitraje Estadístico Bayesiano Adaptativo a Múltiples Regímenes\n",
    "\n",
    "Este programa implementa una estrategia de trading de pares que:\n",
    "1. Selecciona y valida pares cointegrados del S&P 500\n",
    "2. Detecta múltiples regímenes de mercado usando HMM\n",
    "3. Genera señales de trading adaptativas según el régimen\n",
    "4. Monitorea cambios estructurales en las relaciones de cointegración\n",
    "5. Gestiona el riesgo mediante un enfoque bayesiano\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller, kpss\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.stats.diagnostic import recursive_olsresiduals\n",
    "from scipy.stats import norm, uniform\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hmmlearn import hmm\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# Suprimir advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Crear directorios para resultados\n",
    "os.makedirs('./artifacts/results', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/figures', exist_ok=True)\n",
    "os.makedirs('./artifacts/results/data', exist_ok=True)\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    filename='./artifacts/errors.txt',\n",
    "    level=logging.ERROR,\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "class BayesianPairsTrading:\n",
    "    \"\"\"\n",
    "    Implementación de un sistema de trading de pares con enfoque bayesiano\n",
    "    y adaptación a múltiples regímenes de mercado.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start_date='2018-01-01', end_date=None, cache_dir='./artifacts/cache'):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema de trading con los parámetros básicos.\n",
    "        \n",
    "        Args:\n",
    "            start_date (str): Fecha inicial para los datos históricos\n",
    "            end_date (str): Fecha final para los datos históricos (default: hoy)\n",
    "            cache_dir (str): Directorio para almacenar el caché de datos\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date if end_date else dt.datetime.now().strftime('%Y-%m-%d')\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        \n",
    "        # Conexión a la base de datos SQLite para caché\n",
    "        self.conn = sqlite3.connect(f\"{cache_dir}/pairs_data.db\")\n",
    "        \n",
    "        # Parámetros del sistema\n",
    "        self.window_train = 252  # 1 año de trading para estimación\n",
    "        self.window_hmm = 504    # 2 años para HMM\n",
    "        self.min_halflife = 1\n",
    "        self.max_halflife = 30\n",
    "        self.n_regimes = 3\n",
    "        \n",
    "        # Umbrales por régimen\n",
    "        self.entry_thresholds = {\n",
    "            1: 1.25,  # Régimen de baja volatilidad\n",
    "            2: 1.75,  # Régimen de volatilidad normal\n",
    "            3: 2.25   # Régimen de alta volatilidad\n",
    "        }\n",
    "        \n",
    "        self.exit_thresholds = {\n",
    "            1: 0.5,   # Régimen de baja volatilidad\n",
    "            2: 0.75,  # Régimen de volatilidad normal\n",
    "            3: 1.0    # Régimen de alta volatilidad\n",
    "        }\n",
    "        \n",
    "        # Scaling de posiciones por régimen\n",
    "        self.position_scaling = {\n",
    "            1: 1.0,   # 100% en régimen de baja volatilidad\n",
    "            2: 0.7,   # 70% en régimen de volatilidad normal\n",
    "            3: 0.4    # 40% en régimen de alta volatilidad\n",
    "        }\n",
    "        \n",
    "        # Inicializar atributos\n",
    "        self.sp500_symbols = []\n",
    "        self.prices_df = None\n",
    "        self.regime_indicators = None\n",
    "        self.current_regime = None\n",
    "        self.cointegrated_pairs = []\n",
    "        self.active_positions = {}\n",
    "        self.pair_params = {}\n",
    "        self.quarantine_pairs = set()\n",
    "        self.regime_model = None\n",
    "        \n",
    "        # Métricas de performance\n",
    "        self.performance = {\n",
    "            'daily_returns': [],\n",
    "            'sharpe_ratio': None,\n",
    "            'max_drawdown': None,\n",
    "            'win_rate': None,\n",
    "            'profit_factor': None,\n",
    "            'calmar_ratio': None,\n",
    "            'beta_market': None,\n",
    "            'regime_performance': {1: {}, 2: {}, 3: {}}\n",
    "        }\n",
    "        \n",
    "        logging.info(\"Sistema inicializado con fecha de inicio: %s, fecha de fin: %s\", \n",
    "                    self.start_date, self.end_date)\n",
    "\n",
    "    def get_sp500_symbols(self):\n",
    "        \"\"\"\n",
    "        Obtiene la lista de símbolos del S&P 500 desde Wikipedia.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table', {'class': 'wikitable'})\n",
    "            \n",
    "            symbols = []\n",
    "            for row in table.findAll('tr')[1:]:\n",
    "                symbol = row.findAll('td')[0].text.strip()\n",
    "                symbols.append(symbol)\n",
    "            \n",
    "            self.sp500_symbols = symbols\n",
    "            logging.info(f\"Obtenidos {len(symbols)} símbolos del S&P 500\")\n",
    "            \n",
    "            # Guardar lista de símbolos\n",
    "            pd.DataFrame(symbols, columns=['Symbol']).to_csv('./artifacts/results/data/sp500_symbols.csv', index=False)\n",
    "            \n",
    "            return symbols\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al obtener símbolos del S&P 500: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return []\n",
    "\n",
    "    def download_price_data(self, batch_size=50, max_retries=3):\n",
    "        \"\"\"\n",
    "        Descarga datos de precios para todos los símbolos del S&P 500 usando yfinance.\n",
    "        Implementa un sistema de caché y descarga por lotes para eficiencia.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Tamaño del lote para descargas\n",
    "            max_retries (int): Número máximo de reintentos\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame con los precios de cierre ajustados\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Verificar si ya existe en caché\n",
    "            cache_file = f\"{self.cache_dir}/prices_{self.start_date}_{self.end_date}.pkl\"\n",
    "            \n",
    "            if os.path.exists(cache_file):\n",
    "                self.prices_df = pd.read_pickle(cache_file)\n",
    "                logging.info(f\"Datos cargados desde caché: {cache_file}\")\n",
    "                return self.prices_df\n",
    "            \n",
    "            if not self.sp500_symbols:\n",
    "                self.get_sp500_symbols()\n",
    "            \n",
    "            all_data = []\n",
    "            \n",
    "            # Procesar por lotes para evitar límites de API\n",
    "            for i in range(0, len(self.sp500_symbols), batch_size):\n",
    "                batch = self.sp500_symbols[i:i+batch_size]\n",
    "                \n",
    "                for attempt in range(max_retries):\n",
    "                    try:\n",
    "                        # auto_adjust=True por defecto\n",
    "                        batch_data = yf.download(batch, start=self.start_date, end=self.end_date, progress=False)\n",
    "                        \n",
    "                        if 'Close' in batch_data.columns:\n",
    "                            # Si solo hay un símbolo, ajustar estructura\n",
    "                            if isinstance(batch_data.columns, pd.Index) and not isinstance(batch_data.columns, pd.MultiIndex):\n",
    "                                df = pd.DataFrame({batch[0]: batch_data['Close']})\n",
    "                            else:\n",
    "                                df = batch_data['Close']\n",
    "                            \n",
    "                            all_data.append(df)\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        logging.warning(f\"Intento {attempt+1}/{max_retries} fallido para el lote {i//batch_size+1}: {str(e)}\")\n",
    "                        time.sleep(2 ** attempt)  # backoff exponencial\n",
    "                \n",
    "                time.sleep(1)  # Pausa para no sobrecargar la API\n",
    "            \n",
    "            if all_data:\n",
    "                # Combinar todos los lotes\n",
    "                combined_data = pd.concat(all_data, axis=1)\n",
    "                combined_data = combined_data.loc[~combined_data.index.duplicated(keep='first')]\n",
    "                \n",
    "                # Filtrar columnas con demasiados valores faltantes (>30%)\n",
    "                threshold = len(combined_data) * 0.7\n",
    "                self.prices_df = combined_data.dropna(axis=1, thresh=threshold)\n",
    "                \n",
    "                # Interpolación lineal para huecos pequeños (<3 días)\n",
    "                self.prices_df = self.prices_df.interpolate(method='linear', limit=3)\n",
    "                \n",
    "                # Guardar en caché\n",
    "                self.prices_df.to_pickle(cache_file)\n",
    "                \n",
    "                # Guardar también como CSV\n",
    "                self.prices_df.to_csv('./artifacts/results/data/price_data.csv')\n",
    "                \n",
    "                logging.info(f\"Descargados y procesados datos para {self.prices_df.shape[1]} símbolos\")\n",
    "                return self.prices_df\n",
    "            \n",
    "            else:\n",
    "                logging.error(\"No se pudieron obtener datos de precios\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al descargar datos de precios: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def download_regime_indicators(self):\n",
    "        \"\"\"\n",
    "        Descarga indicadores para la detección de regímenes:\n",
    "        1. VIX (volatilidad)\n",
    "        2. Term spread (10Y-2Y Treasury)\n",
    "        3. Credit spread (BBB-Treasury)\n",
    "        4. Indicador compuesto de liquidez\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame con los indicadores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Verificar caché\n",
    "            cache_file = f\"{self.cache_dir}/regime_indicators_{self.start_date}_{self.end_date}.pkl\"\n",
    "            \n",
    "            if os.path.exists(cache_file):\n",
    "                self.regime_indicators = pd.read_pickle(cache_file)\n",
    "                return self.regime_indicators\n",
    "            \n",
    "            # Descargar VIX\n",
    "            vix = yf.download('^VIX', start=self.start_date, end=self.end_date, progress=False)['Close']\n",
    "            vix = np.log(vix)  # Transformación logarítmica\n",
    "            \n",
    "            # Descargar tasas del Tesoro para term spread\n",
    "            treasury_10y = yf.download('^TNX', start=self.start_date, end=self.end_date, progress=False)['Close'] / 100\n",
    "            treasury_2y = yf.download('^TWO', start=self.start_date, end=self.end_date, progress=False)['Close'] / 100\n",
    "            \n",
    "            # Calcular term spread\n",
    "            term_spread = pd.DataFrame({'10Y': treasury_10y, '2Y': treasury_2y})\n",
    "            term_spread = term_spread.interpolate(method='linear', limit=5)\n",
    "            term_spread['spread'] = term_spread['10Y'] - term_spread['2Y']\n",
    "            \n",
    "            # Usar un proxy para credit spread (podríamos usar ETFs como LQD-IEF)\n",
    "            investment_grade = yf.download('LQD', start=self.start_date, end=self.end_date, progress=False)['Close']\n",
    "            treasury_etf = yf.download('IEF', start=self.start_date, end=self.end_date, progress=False)['Close']\n",
    "            \n",
    "            # Normalizar y calcular credit spread proxy\n",
    "            investment_grade_norm = investment_grade / investment_grade.iloc[0]\n",
    "            treasury_etf_norm = treasury_etf / treasury_etf.iloc[0]\n",
    "            credit_spread_proxy = -(investment_grade_norm - treasury_etf_norm)  # Invertir para que valores más altos indiquen mayor spread\n",
    "            \n",
    "            # Si ya tenemos datos de precio, usarlos para el indicador de liquidez\n",
    "            if self.prices_df is None:\n",
    "                self.download_price_data()\n",
    "            \n",
    "            # Indicador compuesto de liquidez (volatilidad/volumen para SPY)\n",
    "            spy_data = yf.download('SPY', start=self.start_date, end=self.end_date, progress=False)\n",
    "            spy_data['volatility'] = spy_data['Close'].pct_change().rolling(21).std() * np.sqrt(252)\n",
    "            spy_data['volume_ma'] = spy_data['Volume'].rolling(21).mean()\n",
    "            spy_data['volume_rel'] = spy_data['Volume'] / spy_data['volume_ma']\n",
    "            spy_data['liquidity'] = spy_data['volatility'] / spy_data['volume_rel']\n",
    "            \n",
    "            # Normalizar cada indicador\n",
    "            vix_norm = (vix - vix.mean()) / vix.std()\n",
    "            term_spread_norm = (term_spread['spread'] - term_spread['spread'].mean()) / term_spread['spread'].std()\n",
    "            credit_spread_norm = (credit_spread_proxy - credit_spread_proxy.mean()) / credit_spread_proxy.std()\n",
    "            liquidity_norm = (spy_data['liquidity'] - spy_data['liquidity'].mean()) / spy_data['liquidity'].std()\n",
    "            \n",
    "            # Combinar todos los indicadores\n",
    "            indicators = pd.DataFrame({\n",
    "                'vix': vix_norm,\n",
    "                'term_spread': term_spread_norm,\n",
    "                'credit_spread': credit_spread_norm,\n",
    "                'liquidity': liquidity_norm\n",
    "            })\n",
    "            \n",
    "            indicators = indicators.dropna()\n",
    "            \n",
    "            # Guardar en caché\n",
    "            self.regime_indicators = indicators\n",
    "            indicators.to_pickle(cache_file)\n",
    "            indicators.to_csv('./artifacts/results/data/regime_indicators.csv')\n",
    "            \n",
    "            return indicators\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al descargar indicadores de régimen: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def detect_regimes(self):\n",
    "        \"\"\"\n",
    "        Implementa un modelo HMM para detectar regímenes de mercado \n",
    "        basado en los indicadores descargados.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.Series: Serie temporal con el régimen identificado para cada fecha\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.regime_indicators is None:\n",
    "                self.download_regime_indicators()\n",
    "            \n",
    "            if len(self.regime_indicators) < self.window_hmm:\n",
    "                logging.warning(f\"Datos insuficientes para HMM. Se requieren {self.window_hmm} días, disponibles: {len(self.regime_indicators)}\")\n",
    "                return pd.Series(index=self.regime_indicators.index, data=2)  # Default a régimen normal\n",
    "            \n",
    "            # Preparar datos para HMM\n",
    "            X = self.regime_indicators.dropna().values\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Inicializar modelo HMM con K-means\n",
    "            kmeans = KMeans(n_clusters=self.n_regimes, random_state=42)\n",
    "            kmeans.fit(X_scaled)\n",
    "            \n",
    "            # Ordenar clusters por volatilidad (VIX)\n",
    "            cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "            volatility_ranking = np.argsort(cluster_centers[:, 0])  # VIX es la primera columna\n",
    "            \n",
    "            # El modelo HMM con inicialización apropiada\n",
    "            model = hmm.GaussianHMM(n_components=self.n_regimes, covariance_type=\"full\", \n",
    "                                    n_iter=100, random_state=42)\n",
    "            \n",
    "            # Estimar modelo\n",
    "            model.fit(X_scaled)\n",
    "            self.regime_model = model\n",
    "            \n",
    "            # Decodificar estados\n",
    "            hidden_states = model.predict(X_scaled)\n",
    "            \n",
    "            # Mapear estados a regímenes (1=bajo, 2=medio, 3=alto) basado en volatilidad\n",
    "            state_volatility = np.zeros(self.n_regimes)\n",
    "            for i in range(self.n_regimes):\n",
    "                state_volatility[i] = np.mean(X_scaled[hidden_states == i, 0])\n",
    "            \n",
    "            regime_map = np.argsort(state_volatility) + 1\n",
    "            \n",
    "            decoded_regimes = pd.Series(index=self.regime_indicators.index, \n",
    "                                        data=[regime_map[s] for s in hidden_states])\n",
    "            \n",
    "            # Guardar resultados\n",
    "            decoded_regimes.to_csv('./artifacts/results/data/regime_detection.csv')\n",
    "            \n",
    "            # Visualizar regímenes\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Gráfico de regímenes\n",
    "            ax1 = plt.subplot(211)\n",
    "            ax1.plot(self.prices_df.index, self.prices_df['SPY'] if 'SPY' in self.prices_df.columns else self.prices_df.iloc[:, 0], 'k', alpha=0.7)\n",
    "            ax1.set_title('Detección de Regímenes de Mercado')\n",
    "            ax1.set_ylabel('Precio de Mercado')\n",
    "            \n",
    "            # Colorear fondo según régimen\n",
    "            regime_colors = {1: 'green', 2: 'blue', 3: 'red'}\n",
    "            for regime in range(1, self.n_regimes + 1):\n",
    "                mask = decoded_regimes == regime\n",
    "                ax1.fill_between(decoded_regimes.index, 0, 1, where=mask, \n",
    "                                 transform=ax1.get_xaxis_transform(), \n",
    "                                 color=regime_colors[regime], alpha=0.3, \n",
    "                                 label=f'Régimen {regime}')\n",
    "            \n",
    "            ax1.legend()\n",
    "            \n",
    "            # Gráfico de indicadores\n",
    "            ax2 = plt.subplot(212, sharex=ax1)\n",
    "            ax2.plot(self.regime_indicators.index, self.regime_indicators['vix'], 'r-', label='VIX (norm)')\n",
    "            ax2.plot(self.regime_indicators.index, self.regime_indicators['credit_spread'], 'b-', label='Credit Spread (norm)')\n",
    "            ax2.set_xlabel('Fecha')\n",
    "            ax2.set_ylabel('Valor normalizado')\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('./artifacts/results/figures/market_regimes.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # Actualizar régimen actual\n",
    "            self.current_regime = decoded_regimes.iloc[-1]\n",
    "            logging.info(f\"Régimen actual detectado: {self.current_regime}\")\n",
    "            \n",
    "            return decoded_regimes\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en la detección de regímenes: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            # Fallback a régimen normal\n",
    "            return pd.Series(index=self.regime_indicators.index if self.regime_indicators is not None else [], data=2)\n",
    "\n",
    "    def find_cointegrated_pairs(self, max_pairs=50, p_value_threshold=0.01):\n",
    "        \"\"\"\n",
    "        Identifica pares de acciones cointegrados mediante el test de Johansen.\n",
    "        \n",
    "        Args:\n",
    "            max_pairs (int): Número máximo de pares a seleccionar\n",
    "            p_value_threshold (float): Umbral de p-valor para el test de Johansen\n",
    "        \n",
    "        Returns:\n",
    "            list: Lista de tuplas (stock1, stock2) con pares cointegrados\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.prices_df is None:\n",
    "                self.download_price_data()\n",
    "            \n",
    "            if len(self.prices_df) < self.window_train:\n",
    "                logging.warning(f\"Datos insuficientes para cointegración. Se requieren {self.window_train} días\")\n",
    "                return []\n",
    "            \n",
    "            # Usamos los últimos window_train días para análisis\n",
    "            recent_prices = self.prices_df.iloc[-self.window_train:]\n",
    "            \n",
    "            # Filtrar columnas con NaN\n",
    "            recent_prices = recent_prices.dropna(axis=1)\n",
    "            \n",
    "            symbols = recent_prices.columns.tolist()\n",
    "            n = len(symbols)\n",
    "            \n",
    "            pairs_results = []\n",
    "            \n",
    "            logging.info(f\"Analizando cointegración para {n} símbolos...\")\n",
    "            \n",
    "            # Procesar en paralelo para eficiencia\n",
    "            def process_pair(i, j):\n",
    "                stock1, stock2 = symbols[i], symbols[j]\n",
    "                \n",
    "                # Extraer series de tiempo\n",
    "                stock1_prices = recent_prices[stock1].values\n",
    "                stock2_prices = recent_prices[stock2].values\n",
    "                \n",
    "                if np.any(np.isnan(stock1_prices)) or np.any(np.isnan(stock2_prices)):\n",
    "                    return None\n",
    "                \n",
    "                # Test de Johansen\n",
    "                try:\n",
    "                    result = coint_johansen(np.column_stack((stock1_prices, stock2_prices)), det_order=0, k_ar_diff=1)\n",
    "                    trace_stat = result.lr1[0]\n",
    "                    critical_value = result.cvt[0, 0]  # Valor crítico al 90%\n",
    "                    \n",
    "                    # Test de cointegración de Engle-Granger como verificación adicional\n",
    "                    _, p_value, _ = coint(stock1_prices, stock2_prices)\n",
    "                    \n",
    "                    # Estimar half-life si parece cointegrado\n",
    "                    if trace_stat > critical_value and p_value < p_value_threshold:\n",
    "                        # Regresión para estimar parámetros de cointegración\n",
    "                        model = sm.OLS(stock1_prices, sm.add_constant(stock2_prices)).fit()\n",
    "                        beta = model.params[1]\n",
    "                        alpha = model.params[0]\n",
    "                        \n",
    "                        # Calcular residuos\n",
    "                        spread = stock1_prices - beta * stock2_prices - alpha\n",
    "                        \n",
    "                        # Estimar modelo AR(1) en los residuos\n",
    "                        model_ar = AutoReg(spread, lags=1).fit()\n",
    "                        \n",
    "                        # Calcular half-life\n",
    "                        phi = model_ar.params[1]\n",
    "                        half_life = -np.log(2) / np.log(abs(phi)) if abs(phi) < 1 else np.inf\n",
    "                        \n",
    "                        # Verificar KPSS (estacionariedad) en los residuos\n",
    "                        kpss_stat, kpss_p_value, _, _ = kpss(spread)\n",
    "                        \n",
    "                        # Solo considerar si el half-life está en el rango deseado\n",
    "                        # y los residuos son estacionarios (KPSS no rechaza H0)\n",
    "                        if (self.min_halflife <= half_life <= self.max_halflife and \n",
    "                            kpss_p_value > 0.05):\n",
    "                            \n",
    "                            # Calcular intervalo de credibilidad para beta (simulación simplificada)\n",
    "                            mean_beta = beta\n",
    "                            std_beta = model.bse[1]\n",
    "                            ci_lower = mean_beta - 1.96 * std_beta\n",
    "                            ci_upper = mean_beta + 1.96 * std_beta\n",
    "                            \n",
    "                            # Verificar que 0 no está en el intervalo de credibilidad\n",
    "                            if ci_lower * ci_upper > 0:  # Mismo signo = 0 no incluido\n",
    "                                return {\n",
    "                                    'stock1': stock1,\n",
    "                                    'stock2': stock2,\n",
    "                                    'trace_stat': trace_stat,\n",
    "                                    'critical_value': critical_value,\n",
    "                                    'p_value': p_value,\n",
    "                                    'beta': beta,\n",
    "                                    'alpha': alpha,\n",
    "                                    'half_life': half_life,\n",
    "                                    'ci_lower': ci_lower,\n",
    "                                    'ci_upper': ci_upper,\n",
    "                                    'kpss_p_value': kpss_p_value\n",
    "                                }\n",
    "                except Exception as e:\n",
    "                    logging.debug(f\"Error procesando par {stock1}-{stock2}: {str(e)}\")\n",
    "                    return None\n",
    "                \n",
    "                return None\n",
    "            \n",
    "            # Ejecutar análisis de pares en paralelo\n",
    "            pairs = []\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                futures = []\n",
    "                for i in range(n):\n",
    "                    for j in range(i+1, n):\n",
    "                        futures.append(executor.submit(process_pair, i, j))\n",
    "                \n",
    "                for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Analizando pares\"):\n",
    "                    result = future.result()\n",
    "                    if result is not None:\n",
    "                        pairs.append(result)\n",
    "            \n",
    "            # Ordenar por p-valor y seleccionar los mejores pares\n",
    "            pairs.sort(key=lambda x: x['p_value'])\n",
    "            selected_pairs = pairs[:max_pairs]\n",
    "            \n",
    "            # Guardar resultados\n",
    "            pd.DataFrame(selected_pairs).to_csv('./artifacts/results/data/cointegrated_pairs.csv', index=False)\n",
    "            \n",
    "            # Actualizar lista de pares\n",
    "            self.cointegrated_pairs = [(p['stock1'], p['stock2']) for p in selected_pairs]\n",
    "            \n",
    "            # Guardar parámetros de pares\n",
    "            for p in selected_pairs:\n",
    "                key = (p['stock1'], p['stock2'])\n",
    "                self.pair_params[key] = {\n",
    "                    'beta': p['beta'],\n",
    "                    'alpha': p['alpha'],\n",
    "                    'half_life': p['half_life'],\n",
    "                    'ci_lower': p['ci_lower'],\n",
    "                    'ci_upper': p['ci_upper']\n",
    "                }\n",
    "            \n",
    "            logging.info(f\"Identificados {len(selected_pairs)} pares cointegrados\")\n",
    "            \n",
    "            # Visualizar algunos pares\n",
    "            self.visualize_pairs(selected_pairs[:5])\n",
    "            \n",
    "            return self.cointegrated_pairs\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al encontrar pares cointegrados: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return []\n",
    "\n",
    "    def visualize_pairs(self, pairs_to_plot):\n",
    "        \"\"\"\n",
    "        Visualiza los pares cointegrados seleccionados.\n",
    "        \n",
    "        Args:\n",
    "            pairs_to_plot (list): Lista de diccionarios con información de pares\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not pairs_to_plot:\n",
    "                return\n",
    "                \n",
    "            recent_prices = self.prices_df.iloc[-self.window_train:]\n",
    "            \n",
    "            for i, pair in enumerate(pairs_to_plot):\n",
    "                stock1, stock2 = pair['stock1'], pair['stock2']\n",
    "                beta, alpha = pair['beta'], pair['alpha']\n",
    "                half_life = pair['half_life']\n",
    "                \n",
    "                # Normalizar precios\n",
    "                s1 = recent_prices[stock1] / recent_prices[stock1].iloc[0]\n",
    "                s2 = recent_prices[stock2] / recent_prices[stock2].iloc[0]\n",
    "                \n",
    "                # Calcular spread\n",
    "                spread = recent_prices[stock1] - beta * recent_prices[stock2] - alpha\n",
    "                \n",
    "                # Estadísticas del spread\n",
    "                spread_mean = spread.mean()\n",
    "                spread_std = spread.std()\n",
    "                z_score = (spread - spread_mean) / spread_std\n",
    "                \n",
    "                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "                \n",
    "                # Gráfico de precios normalizados\n",
    "                ax1.plot(recent_prices.index, s1, label=stock1)\n",
    "                ax1.plot(recent_prices.index, s2, label=stock2)\n",
    "                ax1.set_title(f'Par Cointegrado: {stock1} - {stock2}')\n",
    "                ax1.set_ylabel('Precio Normalizado')\n",
    "                ax1.legend()\n",
    "                \n",
    "                # Gráfico de spread\n",
    "                ax2.plot(recent_prices.index, z_score)\n",
    "                ax2.axhline(y=0, color='r', linestyle='-')\n",
    "                ax2.axhline(y=1.0, color='g', linestyle='--')\n",
    "                ax2.axhline(y=-1.0, color='g', linestyle='--')\n",
    "                ax2.axhline(y=2.0, color='y', linestyle='--')\n",
    "                ax2.axhline(y=-2.0, color='y', linestyle='--')\n",
    "                ax2.set_title(f'Z-Score del Spread (Half-Life: {half_life:.2f} días)')\n",
    "                ax2.set_ylabel('Z-Score')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'./artifacts/results/figures/pair_{stock1}_{stock2}.png')\n",
    "                plt.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al visualizar pares: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "\n",
    "    def calculate_pair_zscore(self, stock1, stock2, lookback=None):\n",
    "        \"\"\"\n",
    "        Calcula el z-score actual para un par de acciones.\n",
    "        \n",
    "        Args:\n",
    "            stock1 (str): Primer símbolo del par\n",
    "            stock2 (str): Segundo símbolo del par\n",
    "            lookback (int): Periodo para calcular estadísticas, default es half-life*4\n",
    "            \n",
    "        Returns:\n",
    "            float: Z-score actual del par\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if (stock1, stock2) not in self.pair_params:\n",
    "                return None\n",
    "            \n",
    "            params = self.pair_params[(stock1, stock2)]\n",
    "            beta, alpha = params['beta'], params['alpha']\n",
    "            \n",
    "            if lookback is None:\n",
    "                # Por defecto, usar 4 veces el half-life\n",
    "                lookback = int(min(params['half_life'] * 4, 100))\n",
    "            \n",
    "            # Obtener datos recientes\n",
    "            recent_data = self.prices_df.iloc[-lookback:]\n",
    "            \n",
    "            # Verificar que ambos stocks existen en los datos\n",
    "            if stock1 not in recent_data.columns or stock2 not in recent_data.columns:\n",
    "                logging.warning(f\"Faltan datos para el par {stock1}-{stock2}\")\n",
    "                return None\n",
    "            \n",
    "            # Calcular spread\n",
    "            spread = recent_data[stock1] - beta * recent_data[stock2] - alpha\n",
    "            \n",
    "            # Calcular estadísticas del spread\n",
    "            spread_mean = spread.mean()\n",
    "            spread_std = spread.std()\n",
    "            \n",
    "            if spread_std == 0:\n",
    "                logging.warning(f\"Desviación estándar cero para el par {stock1}-{stock2}\")\n",
    "                return None\n",
    "            \n",
    "            # Calcular z-score actual\n",
    "            current_spread = spread.iloc[-1]\n",
    "            z_score = (current_spread - spread_mean) / spread_std\n",
    "            \n",
    "            return z_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al calcular z-score para {stock1}-{stock2}: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return None\n",
    "\n",
    "    def detect_structural_change(self, stock1, stock2, cusum_threshold=0.5, test_window=30):\n",
    "        \"\"\"\n",
    "        Detecta cambios estructurales en la relación de cointegración\n",
    "        utilizando CUSUM recursivo y pruebas secuenciales.\n",
    "        \n",
    "        Args:\n",
    "            stock1 (str): Primer símbolo del par\n",
    "            stock2 (str): Segundo símbolo del par\n",
    "            cusum_threshold (float): Umbral para detección CUSUM\n",
    "            test_window (int): Ventana para pruebas secuenciales\n",
    "            \n",
    "        Returns:\n",
    "            bool: True si se detecta cambio estructural, False en caso contrario\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if (stock1, stock2) not in self.pair_params:\n",
    "                return False\n",
    "                \n",
    "            params = self.pair_params[(stock1, stock2)]\n",
    "            beta, alpha = params['beta'], params['alpha']\n",
    "            \n",
    "            # Obtener datos recientes \n",
    "            recent_data = self.prices_df.iloc[-test_window:]\n",
    "            \n",
    "            if stock1 not in recent_data.columns or stock2 not in recent_data.columns:\n",
    "                return False\n",
    "                \n",
    "            # Calcular spread\n",
    "            spread = recent_data[stock1] - beta * recent_data[stock2] - alpha\n",
    "            \n",
    "            # CUSUM recursivo\n",
    "            cusum = np.zeros(len(spread))\n",
    "            spread_std = spread.std()\n",
    "            \n",
    "            for i in range(1, len(spread)):\n",
    "                cusum[i] = max(0, cusum[i-1] + (abs(spread.iloc[i]) - 0.5 * spread_std))\n",
    "            \n",
    "            # Normalizar CUSUM\n",
    "            if cusum.max() > 0:\n",
    "                cusum = cusum / cusum.max()\n",
    "                \n",
    "            # Prueba recursiva de OLS para cambio estructural\n",
    "            X = sm.add_constant(recent_data[stock2])\n",
    "            y = recent_data[stock1]\n",
    "            \n",
    "            try:\n",
    "                rec_resids = recursive_olsresiduals(y.values, X.values, 5)\n",
    "                cusum_test = rec_resids[0][-1]  # Último valor del test CUSUM\n",
    "                \n",
    "                # Criterio de detección: CUSUM alto o test formal significativo\n",
    "                critical_value = cusum_threshold\n",
    "                \n",
    "                if cusum[-1] > critical_value or abs(cusum_test) > 1.0:\n",
    "                    logging.info(f\"Cambio estructural detectado en par {stock1}-{stock2}: CUSUM={cusum[-1]:.2f}, Test={cusum_test:.2f}\")\n",
    "                    return True\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.debug(f\"Error en prueba recursiva para {stock1}-{stock2}: {str(e)}\")\n",
    "            \n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al detectar cambio estructural para {stock1}-{stock2}: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return False\n",
    "\n",
    "    def generate_trading_signals(self, regimes):\n",
    "        \"\"\"\n",
    "        Genera señales de trading basadas en los z-scores y el régimen actual.\n",
    "        \n",
    "        Args:\n",
    "            regimes (pandas.Series): Serie con los regímenes identificados\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame con señales de trading\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.cointegrated_pairs:\n",
    "                logging.warning(\"No hay pares cointegrados para generar señales\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            signals = []\n",
    "            current_date = self.prices_df.index[-1]\n",
    "            \n",
    "            # Obtener régimen actual\n",
    "            current_regime = regimes.iloc[-1] if not regimes.empty else 2  # Default a régimen normal\n",
    "            \n",
    "            # Umbrales según régimen\n",
    "            entry_threshold = self.entry_thresholds[current_regime]\n",
    "            exit_threshold = self.exit_thresholds[current_regime]\n",
    "            \n",
    "            for stock1, stock2 in self.cointegrated_pairs:\n",
    "                # Verificar si el par está en cuarentena\n",
    "                if (stock1, stock2) in self.quarantine_pairs:\n",
    "                    continue\n",
    "                \n",
    "                # Calcular z-score actual\n",
    "                z_score = self.calculate_pair_zscore(stock1, stock2)\n",
    "                \n",
    "                if z_score is None:\n",
    "                    continue\n",
    "                \n",
    "                # Detectar cambio estructural\n",
    "                if self.detect_structural_change(stock1, stock2):\n",
    "                    logging.info(f\"Par {stock1}-{stock2} puesto en cuarentena por cambio estructural\")\n",
    "                    self.quarantine_pairs.add((stock1, stock2))\n",
    "                    \n",
    "                    # Si hay posición abierta, cerrarla\n",
    "                    if (stock1, stock2) in self.active_positions:\n",
    "                        signals.append({\n",
    "                            'date': current_date,\n",
    "                            'pair': f\"{stock1}-{stock2}\",\n",
    "                            'stock1': stock1,\n",
    "                            'stock2': stock2,\n",
    "                            'z_score': z_score,\n",
    "                            'signal': 'close',\n",
    "                            'reason': 'structural_change',\n",
    "                            'regime': current_regime\n",
    "                        })\n",
    "                        \n",
    "                    continue\n",
    "                \n",
    "                # Verificar si ya hay posición activa para este par\n",
    "                if (stock1, stock2) in self.active_positions:\n",
    "                    position = self.active_positions[(stock1, stock2)]\n",
    "                    days_in_position = (current_date - position['entry_date']).days\n",
    "                    position_type = position['type']\n",
    "                    \n",
    "                    # Verificar condiciones de salida\n",
    "                    exit_signal = False\n",
    "                    exit_reason = None\n",
    "                    \n",
    "                    # 1. Reversión a la media\n",
    "                    if (position_type == 'long' and z_score > -exit_threshold) or \\\n",
    "                       (position_type == 'short' and z_score < exit_threshold):\n",
    "                        exit_signal = True\n",
    "                        exit_reason = 'mean_reversion'\n",
    "                    \n",
    "                    # 2. Tiempo máximo en posición (2x half-life)\n",
    "                    half_life = self.pair_params[(stock1, stock2)]['half_life']\n",
    "                    max_days = min(int(2 * half_life), 30)\n",
    "                    \n",
    "                    if days_in_position > max_days:\n",
    "                        exit_signal = True\n",
    "                        exit_reason = 'time_limit'\n",
    "                    \n",
    "                    # 3. Stop-loss (2σ del par)\n",
    "                    if position_type == 'long' and z_score < position['entry_zscore'] - 2.0:\n",
    "                        exit_signal = True\n",
    "                        exit_reason = 'stop_loss'\n",
    "                    elif position_type == 'short' and z_score > position['entry_zscore'] + 2.0:\n",
    "                        exit_signal = True\n",
    "                        exit_reason = 'stop_loss'\n",
    "                    \n",
    "                    if exit_signal:\n",
    "                        signals.append({\n",
    "                            'date': current_date,\n",
    "                            'pair': f\"{stock1}-{stock2}\",\n",
    "                            'stock1': stock1,\n",
    "                            'stock2': stock2,\n",
    "                            'z_score': z_score,\n",
    "                            'signal': 'close',\n",
    "                            'reason': exit_reason,\n",
    "                            'regime': current_regime\n",
    "                        })\n",
    "                    \n",
    "                else:\n",
    "                    # Generar señales de entrada según los umbrales del régimen\n",
    "                    if z_score < -entry_threshold:\n",
    "                        signals.append({\n",
    "                            'date': current_date,\n",
    "                            'pair': f\"{stock1}-{stock2}\",\n",
    "                            'stock1': stock1,\n",
    "                            'stock2': stock2,\n",
    "                            'z_score': z_score,\n",
    "                            'signal': 'open',\n",
    "                            'position': 'long',  # Long stock1, short stock2\n",
    "                            'regime': current_regime\n",
    "                        })\n",
    "                    \n",
    "                    elif z_score > entry_threshold:\n",
    "                        signals.append({\n",
    "                            'date': current_date,\n",
    "                            'pair': f\"{stock1}-{stock2}\",\n",
    "                            'stock1': stock1,\n",
    "                            'stock2': stock2,\n",
    "                            'z_score': z_score,\n",
    "                            'signal': 'open',\n",
    "                            'position': 'short',  # Short stock1, long stock2\n",
    "                            'regime': current_regime\n",
    "                        })\n",
    "            \n",
    "            # Convertir a DataFrame\n",
    "            signals_df = pd.DataFrame(signals)\n",
    "            \n",
    "            if not signals_df.empty:\n",
    "                # Guardar señales generadas\n",
    "                signals_df.to_csv('./artifacts/results/data/trading_signals.csv', index=False)\n",
    "                logging.info(f\"Generadas {len(signals_df)} señales de trading\")\n",
    "                \n",
    "                # Visualizar algunas señales\n",
    "                self.visualize_signals(signals_df)\n",
    "            \n",
    "            return signals_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al generar señales de trading: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    def visualize_signals(self, signals_df):\n",
    "        \"\"\"\n",
    "        Visualiza las señales de trading generadas.\n",
    "        \n",
    "        Args:\n",
    "            signals_df (pandas.DataFrame): DataFrame con señales de trading\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if signals_df.empty:\n",
    "                return\n",
    "                \n",
    "            # Seleccionar hasta 5 señales para visualizar\n",
    "            unique_pairs = signals_df['pair'].unique()[:5]\n",
    "            \n",
    "            for pair in unique_pairs:\n",
    "                pair_signals = signals_df[signals_df['pair'] == pair]\n",
    "                \n",
    "                if pair_signals.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Obtener componentes del par\n",
    "                stock1, stock2 = pair.split('-')\n",
    "                \n",
    "                # Obtener parámetros del par\n",
    "                if (stock1, stock2) not in self.pair_params:\n",
    "                    continue\n",
    "                    \n",
    "                params = self.pair_params[(stock1, stock2)]\n",
    "                beta, alpha = params['beta'], params['alpha']\n",
    "                \n",
    "                # Obtener datos recientes\n",
    "                recent_data = self.prices_df[-126:]  # Últimos ~6 meses\n",
    "                \n",
    "                if stock1 not in recent_data.columns or stock2 not in recent_data.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Calcular spread y z-score\n",
    "                spread = recent_data[stock1] - beta * recent_data[stock2] - alpha\n",
    "                \n",
    "                # Calcular estadísticas móviles para z-score\n",
    "                spread_mean = spread.rolling(window=21).mean()\n",
    "                spread_std = spread.rolling(window=21).std()\n",
    "                z_score = (spread - spread_mean) / spread_std\n",
    "                \n",
    "                # Crear gráfico\n",
    "                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "                \n",
    "                # Gráfico de precios\n",
    "                ax1.plot(recent_data.index, recent_data[stock1] / recent_data[stock1].iloc[0], label=stock1)\n",
    "                ax1.plot(recent_data.index, recent_data[stock2] / recent_data[stock2].iloc[0], label=stock2)\n",
    "                ax1.set_title(f'Señales de Trading para el Par {pair}')\n",
    "                ax1.set_ylabel('Precio Normalizado')\n",
    "                ax1.legend()\n",
    "                \n",
    "                # Gráfico de z-score con señales\n",
    "                ax2.plot(recent_data.index, z_score)\n",
    "                ax2.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "                \n",
    "                # Añadir líneas de umbral según régimen\n",
    "                for regime in range(1, 4):\n",
    "                    entry = self.entry_thresholds[regime]\n",
    "                    exit = self.exit_thresholds[regime]\n",
    "                    \n",
    "                    color = {1: 'green', 2: 'blue', 3: 'red'}[regime]\n",
    "                    alpha = 0.3 if regime != self.current_regime else 0.8\n",
    "                    \n",
    "                    ax2.axhline(y=entry, color=color, linestyle='--', alpha=alpha, \n",
    "                               label=f'Entrada Régimen {regime}' if regime == 1 else None)\n",
    "                    ax2.axhline(y=-entry, color=color, linestyle='--', alpha=alpha)\n",
    "                    ax2.axhline(y=exit, color=color, linestyle=':', alpha=alpha, \n",
    "                               label=f'Salida Régimen {regime}' if regime == 1 else None)\n",
    "                    ax2.axhline(y=-exit, color=color, linestyle=':', alpha=alpha)\n",
    "                \n",
    "                # Marcar señales en el gráfico\n",
    "                for _, signal in pair_signals.iterrows():\n",
    "                    signal_date = signal['date']\n",
    "                    \n",
    "                    if signal_date not in recent_data.index:\n",
    "                        continue\n",
    "                        \n",
    "                    if signal['signal'] == 'open':\n",
    "                        marker = '^' if signal['position'] == 'long' else 'v'\n",
    "                        color = 'g' if signal['position'] == 'long' else 'r'\n",
    "                        ax2.plot(signal_date, signal['z_score'], marker=marker, \n",
    "                                color=color, markersize=10)\n",
    "                    else:  # close\n",
    "                        ax2.plot(signal_date, signal['z_score'], marker='x', \n",
    "                                color='k', markersize=10)\n",
    "                \n",
    "                ax2.set_title(f'Z-Score con Señales de Trading (HL: {params[\"half_life\"]:.2f} días)')\n",
    "                ax2.set_ylabel('Z-Score')\n",
    "                ax2.legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'./artifacts/results/figures/signals_{stock1}_{stock2}.png')\n",
    "                plt.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al visualizar señales: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "    \n",
    "    def optimize_portfolio(self, signals_df, current_regime):\n",
    "        \"\"\"\n",
    "        Optimiza la asignación de capital a los diferentes pares.\n",
    "        \n",
    "        Args:\n",
    "            signals_df (pandas.DataFrame): DataFrame con señales de trading\n",
    "            current_regime (int): Régimen actual del mercado\n",
    "            \n",
    "        Returns:\n",
    "            dict: Diccionario con asignaciones óptimas de capital\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if signals_df.empty:\n",
    "                return {}\n",
    "                \n",
    "            # Filtrar solo señales de apertura\n",
    "            open_signals = signals_df[signals_df['signal'] == 'open']\n",
    "            \n",
    "            if open_signals.empty:\n",
    "                return {}\n",
    "                \n",
    "            # Número de pares activos\n",
    "            n_pairs = len(open_signals)\n",
    "            \n",
    "            # Base allocation: 1/sqrt(N)\n",
    "            base_allocation = 1 / np.sqrt(n_pairs)\n",
    "            \n",
    "            # Ajustes por calidad de pares y régimen\n",
    "            allocations = {}\n",
    "            \n",
    "            for _, signal in open_signals.iterrows():\n",
    "                stock1, stock2 = signal['stock1'], signal['stock2']\n",
    "                pair_key = (stock1, stock2)\n",
    "                \n",
    "                if pair_key not in self.pair_params:\n",
    "                    continue\n",
    "                \n",
    "                # Ajuste por calidad (inverso del ancho del IC)\n",
    "                ic_width = self.pair_params[pair_key]['ci_upper'] - self.pair_params[pair_key]['ci_lower']\n",
    "                quality_factor = 1.0\n",
    "                \n",
    "                if ic_width > 0:\n",
    "                    quality_factor = min(1.5, 1.0 / ic_width)  # Cap en 1.5x\n",
    "                \n",
    "                # Ajuste por régimen\n",
    "                regime_factor = self.position_scaling[current_regime]\n",
    "                \n",
    "                # Asignación final\n",
    "                allocation = base_allocation * quality_factor * regime_factor\n",
    "                \n",
    "                # Aplicar límites\n",
    "                allocation = min(0.05, allocation)  # Máximo 5% por par\n",
    "                \n",
    "                allocations[pair_key] = allocation\n",
    "            \n",
    "            # Normalizar para que sumen a un máximo según el régimen\n",
    "            max_portfolio_exposure = self.position_scaling[current_regime]\n",
    "            total_allocation = sum(allocations.values())\n",
    "            \n",
    "            if total_allocation > max_portfolio_exposure:\n",
    "                scale_factor = max_portfolio_exposure / total_allocation\n",
    "                allocations = {k: v * scale_factor for k, v in allocations.items()}\n",
    "            \n",
    "            # Guardar asignaciones\n",
    "            allocation_df = pd.DataFrame([\n",
    "                {'pair': f\"{k[0]}-{k[1]}\", 'allocation': v}\n",
    "                for k, v in allocations.items()\n",
    "            ])\n",
    "            \n",
    "            if not allocation_df.empty:\n",
    "                allocation_df.to_csv('./artifacts/results/data/portfolio_allocation.csv', index=False)\n",
    "            \n",
    "            return allocations\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en optimización de cartera: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return {}\n",
    "\n",
    "    def run_backtest(self, start_date=None, end_date=None, initial_capital=1000000):\n",
    "        \"\"\"\n",
    "        Ejecuta un backtest de la estrategia para el período especificado.\n",
    "        \n",
    "        Args:\n",
    "            start_date (str): Fecha inicial para el backtest\n",
    "            end_date (str): Fecha final para el backtest\n",
    "            initial_capital (float): Capital inicial\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame con resultados diarios del backtest\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Configurar fechas del backtest\n",
    "            if start_date is None:\n",
    "                start_date = self.start_date\n",
    "            \n",
    "            if end_date is None:\n",
    "                end_date = self.end_date\n",
    "            \n",
    "            logging.info(f\"Iniciando backtest desde {start_date} hasta {end_date}\")\n",
    "            \n",
    "            # Asegurarse de que tenemos los datos\n",
    "            if self.prices_df is None:\n",
    "                self.download_price_data()\n",
    "            \n",
    "            # Filtrar el período de backtest\n",
    "            backtest_data = self.prices_df.loc[start_date:end_date]\n",
    "            \n",
    "            if len(backtest_data) < self.window_train:\n",
    "                logging.error(f\"Datos insuficientes para backtest. Se requieren al menos {self.window_train} días\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Inicializar variables de backtest\n",
    "            portfolio_value = [initial_capital]\n",
    "            cash = initial_capital\n",
    "            current_positions = {}\n",
    "            daily_returns = []\n",
    "            daily_benchmark = []\n",
    "            daily_exposures = []\n",
    "            trade_history = []\n",
    "            regime_history = []\n",
    "            \n",
    "            # Obtener SPY como benchmark\n",
    "            spy_returns = None\n",
    "            if 'SPY' in self.prices_df.columns:\n",
    "                spy_prices = self.prices_df['SPY'].loc[backtest_data.index]\n",
    "                spy_returns = spy_prices.pct_change().fillna(0)\n",
    "            \n",
    "            # Recalibrar cada semana (5 días de trading)\n",
    "            recalibration_frequency = 5\n",
    "            \n",
    "            for i, current_date in enumerate(tqdm(backtest_data.index[self.window_train:], desc=\"Backtest\")):\n",
    "                day_index = i + self.window_train\n",
    "                \n",
    "                # Datos hasta la fecha actual (para evitar look-ahead bias)\n",
    "                data_until_today = self.prices_df.iloc[:day_index]\n",
    "                \n",
    "                # Detectar régimen actual\n",
    "                if i % recalibration_frequency == 0:\n",
    "                    # Solo recalibrar periódicamente (semanal)\n",
    "                    self.regime_indicators = self.download_regime_indicators()\n",
    "                    regimes = self.detect_regimes()\n",
    "                    current_regime = regimes.iloc[-1] if not regimes.empty else 2\n",
    "                \n",
    "                regime_history.append(current_regime)\n",
    "                \n",
    "                # Ejecutar lógica de trading solo en fechas de recalibración\n",
    "                if i % recalibration_frequency == 0:\n",
    "                    # Identificar pares cointegrados\n",
    "                    self.cointegrated_pairs = self.find_cointegrated_pairs()\n",
    "                    \n",
    "                    # Generar señales\n",
    "                    signals = self.generate_trading_signals(regimes)\n",
    "                    \n",
    "                    if not signals.empty:\n",
    "                        # Optimizar portfolio\n",
    "                        allocations = self.optimize_portfolio(signals, current_regime)\n",
    "                        \n",
    "                        # Procesar señales\n",
    "                        for _, signal in signals.iterrows():\n",
    "                            pair_key = (signal['stock1'], signal['stock2'])\n",
    "                            \n",
    "                            # Señales de cierre\n",
    "                            if signal['signal'] == 'close' and pair_key in current_positions:\n",
    "                                position = current_positions[pair_key]\n",
    "                                position_type = position['type']\n",
    "                                entry_date = position['entry_date']\n",
    "                                entry_prices = position['entry_prices']\n",
    "                                position_size = position['size']\n",
    "                                \n",
    "                                # Calcular retorno\n",
    "                                exit_prices = {\n",
    "                                    signal['stock1']: data_until_today[signal['stock1']].iloc[-1],\n",
    "                                    signal['stock2']: data_until_today[signal['stock2']].iloc[-1]\n",
    "                                }\n",
    "                                \n",
    "                                if position_type == 'long':\n",
    "                                    # Long stock1, short stock2\n",
    "                                    stock1_return = (exit_prices[signal['stock1']] / entry_prices[signal['stock1']]) - 1\n",
    "                                    stock2_return = (entry_prices[signal['stock2']] / exit_prices[signal['stock2']]) - 1\n",
    "                                else:\n",
    "                                    # Short stock1, long stock2\n",
    "                                    stock1_return = (entry_prices[signal['stock1']] / exit_prices[signal['stock1']]) - 1\n",
    "                                    stock2_return = (exit_prices[signal['stock2']] / entry_prices[signal['stock2']]) - 1\n",
    "                                \n",
    "                                # Rendimiento neto (simplificado, sin costes de transacción)\n",
    "                                net_return = (stock1_return + stock2_return) / 2\n",
    "                                pnl = position_size * net_return\n",
    "                                \n",
    "                                # Actualizar cash\n",
    "                                cash += position_size + pnl\n",
    "                                \n",
    "                                # Registrar operación\n",
    "                                trade_history.append({\n",
    "                                    'entry_date': entry_date,\n",
    "                                    'exit_date': current_date,\n",
    "                                    'pair': f\"{signal['stock1']}-{signal['stock2']}\",\n",
    "                                    'position_type': position_type,\n",
    "                                    'entry_z_score': position['z_score'],\n",
    "                                    'exit_z_score': signal['z_score'],\n",
    "                                    'exit_reason': signal.get('reason', 'unknown'),\n",
    "                                    'regime': signal['regime'],\n",
    "                                    'position_size': position_size,\n",
    "                                    'pnl': pnl,\n",
    "                                    'return_pct': net_return * 100\n",
    "                                })\n",
    "                                \n",
    "                                # Eliminar posición\n",
    "                                del current_positions[pair_key]\n",
    "                            \n",
    "                            # Señales de apertura\n",
    "                            elif signal['signal'] == 'open' and pair_key not in current_positions:\n",
    "                                # Solo abrir si tenemos capital disponible\n",
    "                                if cash > 0 and pair_key in allocations:\n",
    "                                    allocation = allocations[pair_key]\n",
    "                                    position_size = cash * allocation\n",
    "                                    \n",
    "                                    # Registrar posición\n",
    "                                    current_positions[pair_key] = {\n",
    "                                        'type': signal['position'],\n",
    "                                        'entry_date': current_date,\n",
    "                                        'entry_prices': {\n",
    "                                            signal['stock1']: data_until_today[signal['stock1']].iloc[-1],\n",
    "                                            signal['stock2']: data_until_today[signal['stock2']].iloc[-1]\n",
    "                                        },\n",
    "                                        'z_score': signal['z_score'],\n",
    "                                        'size': position_size\n",
    "                                    }\n",
    "                                    \n",
    "                                    # Actualizar cash\n",
    "                                    cash -= position_size\n",
    "                \n",
    "                # Calcular valor del portfolio para el día actual\n",
    "                current_value = cash\n",
    "                current_exposure = 0\n",
    "                \n",
    "                # Valorar posiciones abiertas\n",
    "                for pair_key, position in list(current_positions.items()):\n",
    "                    stock1, stock2 = pair_key\n",
    "                    \n",
    "                    # Verificar si tenemos precios para ambos stocks\n",
    "                    if stock1 not in data_until_today.columns or stock2 not in data_until_today.columns:\n",
    "                        continue\n",
    "                    \n",
    "                    current_prices = {\n",
    "                        stock1: data_until_today[stock1].iloc[-1],\n",
    "                        stock2: data_until_today[stock2].iloc[-1]\n",
    "                    }\n",
    "                    \n",
    "                    entry_prices = position['entry_prices']\n",
    "                    position_type = position['type']\n",
    "                    position_size = position['size']\n",
    "                    \n",
    "                    # Calcular valor actual\n",
    "                    if position_type == 'long':\n",
    "                        # Long stock1, short stock2\n",
    "                        stock1_return = (current_prices[stock1] / entry_prices[stock1]) - 1\n",
    "                        stock2_return = (entry_prices[stock2] / current_prices[stock2]) - 1\n",
    "                    else:\n",
    "                        # Short stock1, long stock2\n",
    "                        stock1_return = (entry_prices[stock1] / current_prices[stock1]) - 1\n",
    "                        stock2_return = (current_prices[stock2] / entry_prices[stock2]) - 1\n",
    "                    \n",
    "                    net_return = (stock1_return + stock2_return) / 2\n",
    "                    position_value = position_size * (1 + net_return)\n",
    "                    \n",
    "                    current_value += position_value\n",
    "                    current_exposure += position_size\n",
    "                \n",
    "                # Registrar valor y exposición\n",
    "                portfolio_value.append(current_value)\n",
    "                \n",
    "                # Calcular retorno diario\n",
    "                if len(portfolio_value) > 1:\n",
    "                    daily_return = (portfolio_value[-1] / portfolio_value[-2]) - 1\n",
    "                    daily_returns.append(daily_return)\n",
    "                    \n",
    "                    # Registrar benchmark si está disponible\n",
    "                    if spy_returns is not None and current_date in spy_returns.index:\n",
    "                        daily_benchmark.append(spy_returns.loc[current_date])\n",
    "                    else:\n",
    "                        daily_benchmark.append(0)\n",
    "                else:\n",
    "                    daily_returns.append(0)\n",
    "                    daily_benchmark.append(0)\n",
    "                \n",
    "                # Registrar exposición relativa\n",
    "                daily_exposures.append(current_exposure / current_value)\n",
    "            \n",
    "            # Crear DataFrame con resultados\n",
    "            results = pd.DataFrame({\n",
    "                'portfolio_value': portfolio_value[1:],  # Excluir valor inicial\n",
    "                'daily_return': daily_returns,\n",
    "                'benchmark_return': daily_benchmark,\n",
    "                'exposure': daily_exposures,\n",
    "                'regime': regime_history\n",
    "            }, index=backtest_data.index[self.window_train:])\n",
    "            \n",
    "            # Calcular métricas de performance\n",
    "            self.calculate_performance_metrics(results)\n",
    "            \n",
    "            # Guardar resultados de operaciones\n",
    "            if trade_history:\n",
    "                trades_df = pd.DataFrame(trade_history)\n",
    "                trades_df.to_csv('./artifacts/results/data/trade_history.csv', index=False)\n",
    "            \n",
    "            # Guardar resultados diarios\n",
    "            results.to_csv('./artifacts/results/data/backtest_results.csv')\n",
    "            \n",
    "            # Visualizar resultados\n",
    "            self.visualize_backtest_results(results)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en backtest: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def calculate_performance_metrics(self, results):\n",
    "        \"\"\"\n",
    "        Calcula métricas de rendimiento a partir de los resultados del backtest.\n",
    "        \n",
    "        Args:\n",
    "            results (pandas.DataFrame): DataFrame con resultados diarios del backtest\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if results.empty:\n",
    "                logging.warning(\"No hay resultados para calcular métricas\")\n",
    "                return\n",
    "            \n",
    "            # Métricas generales\n",
    "            daily_returns = results['daily_return']\n",
    "            \n",
    "            # Retorno total y anualizado\n",
    "            total_return = (results['portfolio_value'].iloc[-1] / results['portfolio_value'].iloc[0]) - 1\n",
    "            trading_days = len(results)\n",
    "            annual_return = (1 + total_return) ** (252 / trading_days) - 1\n",
    "            \n",
    "            # Volatilidad\n",
    "            volatility_daily = daily_returns.std()\n",
    "            volatility_annual = volatility_daily * np.sqrt(252)\n",
    "            \n",
    "            # Sharpe Ratio (asumiendo tasa libre de riesgo = 0)\n",
    "            sharpe_ratio = annual_return / volatility_annual if volatility_annual > 0 else 0\n",
    "            \n",
    "            # Drawdowns\n",
    "            cumulative_returns = (1 + daily_returns).cumprod()\n",
    "            running_max = cumulative_returns.cummax()\n",
    "            drawdowns = (cumulative_returns / running_max) - 1\n",
    "            max_drawdown = drawdowns.min()\n",
    "            \n",
    "            # Calmar Ratio\n",
    "            calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0\n",
    "            \n",
    "            # Win rate (de las operaciones completadas)\n",
    "            trades_file = './artifacts/results/data/trade_history.csv'\n",
    "            if os.path.exists(trades_file):\n",
    "                trades = pd.read_csv(trades_file)\n",
    "                if not trades.empty:\n",
    "                    win_rate = (trades['pnl'] > 0).mean()\n",
    "                    profit_factor = abs(trades[trades['pnl'] > 0]['pnl'].sum() / trades[trades['pnl'] < 0]['pnl'].sum()) if trades[trades['pnl'] < 0]['pnl'].sum() != 0 else float('inf')\n",
    "                else:\n",
    "                    win_rate = 0\n",
    "                    profit_factor = 0\n",
    "            else:\n",
    "                win_rate = 0\n",
    "                profit_factor = 0\n",
    "            \n",
    "            # Beta al mercado\n",
    "            if 'benchmark_return' in results.columns:\n",
    "                # Calcular beta usando regresión simple\n",
    "                benchmark_returns = results['benchmark_return']\n",
    "                \n",
    "                if benchmark_returns.std() > 0:\n",
    "                    model = sm.OLS(daily_returns, sm.add_constant(benchmark_returns)).fit()\n",
    "                    beta = model.params[1]\n",
    "                else:\n",
    "                    beta = 0\n",
    "            else:\n",
    "                beta = 0\n",
    "            \n",
    "            # Métricas por régimen\n",
    "            regime_metrics = {}\n",
    "            for regime in range(1, 4):\n",
    "                regime_data = results[results['regime'] == regime]\n",
    "                \n",
    "                if not regime_data.empty:\n",
    "                    regime_returns = regime_data['daily_return']\n",
    "                    regime_annual_return = (1 + regime_returns.mean()) ** 252 - 1\n",
    "                    regime_volatility = regime_returns.std() * np.sqrt(252)\n",
    "                    regime_sharpe = regime_annual_return / regime_volatility if regime_volatility > 0 else 0\n",
    "                    \n",
    "                    regime_metrics[regime] = {\n",
    "                        'return': regime_annual_return,\n",
    "                        'volatility': regime_volatility,\n",
    "                        'sharpe': regime_sharpe,\n",
    "                        'days': len(regime_data),\n",
    "                        'pct_time': len(regime_data) / len(results) if len(results) > 0 else 0\n",
    "                    }\n",
    "            \n",
    "            # Guardar métricas\n",
    "            metrics = {\n",
    "                'total_return': total_return,\n",
    "                'annual_return': annual_return,\n",
    "                'volatility': volatility_annual,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'calmar_ratio': calmar_ratio,\n",
    "                'win_rate': win_rate,\n",
    "                'profit_factor': profit_factor,\n",
    "                'beta': beta,\n",
    "                'regime_metrics': regime_metrics\n",
    "            }\n",
    "            \n",
    "            # Guardar como CSV\n",
    "            pd.DataFrame([metrics]).to_csv('./artifacts/results/data/performance_metrics.csv', index=False)\n",
    "            \n",
    "            # Actualizar performance guardada\n",
    "            self.performance = {\n",
    "                'daily_returns': daily_returns.tolist(),\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'win_rate': win_rate,\n",
    "                'profit_factor': profit_factor,\n",
    "                'calmar_ratio': calmar_ratio,\n",
    "                'beta_market': beta,\n",
    "                'regime_performance': regime_metrics\n",
    "            }\n",
    "            \n",
    "            # Imprimir resumen\n",
    "            logging.info(f\"Retorno total: {total_return:.2%}\")\n",
    "            logging.info(f\"Retorno anualizado: {annual_return:.2%}\")\n",
    "            logging.info(f\"Volatilidad anualizada: {volatility_annual:.2%}\")\n",
    "            logging.info(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "            logging.info(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "            logging.info(f\"Win Rate: {win_rate:.2%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al calcular métricas de rendimiento: {str(e)}\")\n",
    "            logging.error(f\"Traceback: {sys.exc_info()[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981370f-eb35-469f-ab33-bc2c8521677e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Backtest:   0%|                                        | 0/1579 [00:00<?, ?it/s]\n",
      "Analizando pares:   0%|                              | 0/118828 [00:00<?, ?it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 1/118828 [00:00<4:35:27,  7.19it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 79/118828 [00:00<05:41, 347.54it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 115/118828 [00:00<10:55, 180.99it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 140/118828 [00:00<13:36, 145.38it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 159/118828 [00:01<14:49, 133.35it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 175/118828 [00:01<15:50, 124.78it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 189/118828 [00:01<17:33, 112.61it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 201/118828 [00:01<18:14, 108.38it/s]\u001b[A\n",
      "Analizando pares:   0%|                   | 213/118828 [00:01<18:42, 105.68it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 224/118828 [00:01<20:27, 96.64it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 234/118828 [00:01<21:14, 93.04it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 244/118828 [00:02<21:22, 92.43it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 255/118828 [00:02<20:41, 95.53it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 265/118828 [00:02<21:05, 93.68it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 276/118828 [00:02<20:24, 96.80it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 286/118828 [00:02<20:55, 94.41it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 296/118828 [00:02<22:13, 88.88it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 305/118828 [00:02<22:14, 88.82it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 314/118828 [00:02<22:53, 86.27it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 323/118828 [00:02<23:31, 83.95it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 332/118828 [00:03<23:18, 84.74it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 341/118828 [00:03<24:23, 80.94it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 350/118828 [00:03<24:04, 82.02it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 359/118828 [00:03<23:33, 83.78it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 368/118828 [00:03<23:41, 83.31it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 377/118828 [00:03<24:11, 81.58it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 386/118828 [00:03<24:06, 81.89it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 396/118828 [00:03<23:03, 85.60it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 405/118828 [00:03<23:08, 85.28it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 415/118828 [00:03<22:05, 89.31it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 424/118828 [00:04<23:01, 85.70it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 434/118828 [00:04<22:04, 89.41it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 445/118828 [00:04<21:00, 93.94it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 455/118828 [00:04<22:04, 89.35it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 465/118828 [00:04<21:56, 89.94it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 476/118828 [00:04<20:59, 93.98it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 486/118828 [00:04<21:22, 92.30it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 496/118828 [00:04<21:41, 90.95it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 506/118828 [00:04<21:50, 90.29it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 516/118828 [00:05<22:57, 85.90it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 526/118828 [00:05<22:17, 88.42it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 535/118828 [00:05<22:39, 86.99it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 546/118828 [00:05<22:23, 88.05it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 555/118828 [00:05<23:07, 85.25it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 564/118828 [00:05<23:24, 84.21it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 574/118828 [00:05<23:16, 84.67it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 583/118828 [00:05<23:37, 83.41it/s]\u001b[A\n",
      "Analizando pares:   0%|                    | 593/118828 [00:06<22:42, 86.75it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 603/118828 [00:06<22:55, 85.92it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 614/118828 [00:06<21:53, 90.02it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 624/118828 [00:06<22:02, 89.40it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 635/118828 [00:06<21:09, 93.10it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 645/118828 [00:06<21:13, 92.83it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 655/118828 [00:06<21:04, 93.44it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 665/118828 [00:06<21:06, 93.29it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 675/118828 [00:06<21:05, 93.35it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 685/118828 [00:07<21:31, 91.48it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 695/118828 [00:07<21:47, 90.36it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 705/118828 [00:07<21:35, 91.15it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 715/118828 [00:07<22:51, 86.11it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 726/118828 [00:07<21:53, 89.95it/s]\u001b[A\n",
      "Analizando pares:   1%|                    | 736/118828 [00:07<22:10, 88.78it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 747/118828 [00:07<21:25, 91.82it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 757/118828 [00:07<21:17, 92.42it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 767/118828 [00:07<22:31, 87.33it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 777/118828 [00:08<22:03, 89.23it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 786/118828 [00:08<22:08, 88.86it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 796/118828 [00:08<22:13, 88.48it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 807/118828 [00:08<21:18, 92.29it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 817/118828 [00:08<22:05, 89.01it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 827/118828 [00:08<21:59, 89.45it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 837/118828 [00:08<21:28, 91.57it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 848/118828 [00:08<21:52, 89.87it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 860/118828 [00:08<20:30, 95.87it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 870/118828 [00:09<21:00, 93.55it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 880/118828 [00:09<21:32, 91.27it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 890/118828 [00:09<21:37, 90.87it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 900/118828 [00:09<21:44, 90.37it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 910/118828 [00:09<21:16, 92.39it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 920/118828 [00:09<21:31, 91.31it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 930/118828 [00:09<21:42, 90.51it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 940/118828 [00:09<22:32, 87.13it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 951/118828 [00:09<21:06, 93.04it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 961/118828 [00:10<22:12, 88.42it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 971/118828 [00:10<21:34, 91.02it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 981/118828 [00:10<23:07, 84.92it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 990/118828 [00:10<23:47, 82.53it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                   | 999/118828 [00:10<24:43, 79.40it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1008/118828 [00:10<25:00, 78.51it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1019/118828 [00:10<22:42, 86.49it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1029/118828 [00:10<22:22, 87.76it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1038/118828 [00:10<23:14, 84.46it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1048/118828 [00:11<22:43, 86.37it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1058/118828 [00:11<21:51, 89.79it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1069/118828 [00:11<21:22, 91.81it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1080/118828 [00:11<21:40, 90.57it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1090/118828 [00:11<21:49, 89.88it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1100/118828 [00:11<21:42, 90.39it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1110/118828 [00:11<22:17, 88.01it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1119/118828 [00:11<22:23, 87.59it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1128/118828 [00:11<22:41, 86.43it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1137/118828 [00:12<23:28, 83.56it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1147/118828 [00:12<22:40, 86.49it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1157/118828 [00:12<22:03, 88.93it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1167/118828 [00:12<22:00, 89.09it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1177/118828 [00:12<21:47, 89.98it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1188/118828 [00:12<21:20, 91.90it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1198/118828 [00:12<21:50, 89.74it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1207/118828 [00:12<21:50, 89.73it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1216/118828 [00:12<22:05, 88.70it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1226/118828 [00:13<22:07, 88.57it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1236/118828 [00:13<21:53, 89.55it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1246/118828 [00:13<21:44, 90.10it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1256/118828 [00:13<21:12, 92.38it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1266/118828 [00:13<24:37, 79.58it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1275/118828 [00:13<24:11, 80.96it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1284/118828 [00:13<24:15, 80.76it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1293/118828 [00:13<23:54, 81.91it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1303/118828 [00:14<22:58, 85.27it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1313/118828 [00:14<22:00, 88.98it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1322/118828 [00:14<22:25, 87.36it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1331/118828 [00:14<23:03, 84.95it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1340/118828 [00:14<22:45, 86.07it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1350/118828 [00:14<21:46, 89.95it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1360/118828 [00:14<22:19, 87.69it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1370/118828 [00:14<22:02, 88.81it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1380/118828 [00:14<21:35, 90.68it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1390/118828 [00:14<22:09, 88.36it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1400/118828 [00:15<21:43, 90.10it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1410/118828 [00:15<21:55, 89.23it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1419/118828 [00:15<21:59, 88.99it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1428/118828 [00:15<23:31, 83.16it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1437/118828 [00:15<23:38, 82.78it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1447/118828 [00:15<22:47, 85.81it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1456/118828 [00:15<22:35, 86.56it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1465/118828 [00:15<22:32, 86.80it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1474/118828 [00:15<23:27, 83.40it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1483/118828 [00:16<22:57, 85.21it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1492/118828 [00:16<25:55, 75.44it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1501/118828 [00:16<25:02, 78.07it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1509/118828 [00:16<25:31, 76.58it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1518/118828 [00:16<24:32, 79.66it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1530/118828 [00:16<22:31, 86.79it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1540/118828 [00:16<21:40, 90.22it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1550/118828 [00:16<22:25, 87.16it/s]\u001b[A\n",
      "Analizando pares:   1%|▏                  | 1559/118828 [00:16<22:22, 87.32it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1569/118828 [00:17<21:56, 89.04it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1579/118828 [00:17<21:28, 90.98it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1589/118828 [00:17<21:45, 89.82it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1599/118828 [00:17<22:57, 85.09it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1609/118828 [00:17<22:15, 87.74it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1619/118828 [00:17<22:28, 86.89it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1628/118828 [00:17<22:57, 85.11it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1637/118828 [00:17<22:42, 86.00it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1646/118828 [00:17<22:58, 85.04it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1656/118828 [00:18<22:15, 87.75it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1665/118828 [00:18<22:56, 85.12it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1674/118828 [00:18<22:59, 84.91it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1684/118828 [00:18<22:30, 86.75it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1693/118828 [00:18<23:08, 84.38it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1704/118828 [00:18<21:51, 89.30it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1713/118828 [00:18<25:05, 77.79it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1722/118828 [00:18<24:58, 78.12it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1732/118828 [00:19<24:11, 80.65it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1742/118828 [00:19<22:58, 84.92it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1752/118828 [00:19<22:32, 86.53it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1761/118828 [00:19<22:26, 86.92it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1771/118828 [00:19<22:13, 87.78it/s]\u001b[A\n",
      "Analizando pares:   1%|▎                  | 1781/118828 [00:19<21:53, 89.10it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1791/118828 [00:19<21:26, 91.00it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1801/118828 [00:19<21:39, 90.03it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1812/118828 [00:19<21:22, 91.21it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1823/118828 [00:20<21:25, 91.01it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1833/118828 [00:20<21:15, 91.73it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1843/118828 [00:20<21:21, 91.27it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1853/118828 [00:20<21:30, 90.62it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1863/118828 [00:20<21:30, 90.66it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1873/118828 [00:20<21:23, 91.14it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1883/118828 [00:20<21:21, 91.29it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1893/118828 [00:20<21:10, 92.03it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1903/118828 [00:20<21:30, 90.60it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1913/118828 [00:21<24:19, 80.09it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1923/118828 [00:21<23:13, 83.90it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1933/118828 [00:21<22:38, 86.04it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1943/118828 [00:21<21:48, 89.34it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1953/118828 [00:21<21:44, 89.62it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1963/118828 [00:21<22:16, 87.45it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1973/118828 [00:21<21:35, 90.18it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1984/118828 [00:21<21:22, 91.13it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 1994/118828 [00:21<22:32, 86.38it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2004/118828 [00:22<21:52, 89.01it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2014/118828 [00:22<22:10, 87.82it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2024/118828 [00:22<21:38, 89.98it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2034/118828 [00:22<21:14, 91.65it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2044/118828 [00:22<20:50, 93.37it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2054/118828 [00:22<21:18, 91.34it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2064/118828 [00:22<22:24, 86.88it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2074/118828 [00:22<22:01, 88.35it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2083/118828 [00:23<24:49, 78.36it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2092/118828 [00:23<25:03, 77.62it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2101/118828 [00:23<24:30, 79.39it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2111/118828 [00:23<23:53, 81.43it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2122/118828 [00:23<22:15, 87.38it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2131/118828 [00:23<22:08, 87.83it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2141/118828 [00:23<22:17, 87.22it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2150/118828 [00:23<22:53, 84.93it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2160/118828 [00:23<21:56, 88.61it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2169/118828 [00:23<22:19, 87.11it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2180/118828 [00:24<20:48, 93.40it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2190/118828 [00:24<21:42, 89.53it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2200/118828 [00:24<22:39, 85.81it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2209/118828 [00:24<23:44, 81.85it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2218/118828 [00:24<23:13, 83.67it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2227/118828 [00:24<23:36, 82.32it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2236/118828 [00:24<26:06, 74.45it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2244/118828 [00:24<25:43, 75.54it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2252/118828 [00:25<25:39, 75.73it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2260/118828 [00:25<25:26, 76.35it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2268/118828 [00:25<25:24, 76.48it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2277/118828 [00:25<24:42, 78.61it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2286/118828 [00:25<23:47, 81.64it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2295/118828 [00:25<23:19, 83.30it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2305/118828 [00:25<22:44, 85.41it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2314/118828 [00:25<23:25, 82.89it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2323/118828 [00:25<23:15, 83.49it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2332/118828 [00:25<23:15, 83.47it/s]\u001b[A\n",
      "Analizando pares:   2%|▎                  | 2341/118828 [00:26<23:07, 83.96it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2350/118828 [00:26<23:46, 81.63it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2359/118828 [00:26<24:05, 80.58it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2368/118828 [00:26<23:54, 81.19it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2377/118828 [00:26<26:46, 72.47it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2385/118828 [00:26<26:29, 73.25it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2393/118828 [00:26<27:19, 71.03it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2402/118828 [00:26<26:28, 73.32it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2410/118828 [00:27<25:53, 74.93it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2419/118828 [00:27<25:28, 76.14it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2427/118828 [00:27<25:19, 76.61it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2436/118828 [00:27<25:00, 77.56it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2445/118828 [00:27<24:26, 79.36it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2455/118828 [00:27<23:24, 82.86it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2465/118828 [00:27<22:46, 85.18it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2475/118828 [00:27<22:10, 87.46it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2484/118828 [00:27<22:14, 87.18it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2493/118828 [00:28<22:46, 85.14it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2502/118828 [00:28<24:31, 79.05it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2510/118828 [00:28<24:47, 78.19it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2519/118828 [00:28<24:18, 79.73it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2529/118828 [00:28<23:31, 82.41it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2538/118828 [00:28<23:13, 83.46it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2547/118828 [00:28<23:54, 81.09it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2556/118828 [00:28<23:43, 81.67it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2565/118828 [00:28<23:30, 82.43it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2574/118828 [00:29<24:12, 80.04it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2584/118828 [00:29<24:20, 79.58it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2593/118828 [00:29<23:48, 81.36it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2602/118828 [00:29<23:12, 83.46it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2611/118828 [00:29<22:58, 84.34it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2620/118828 [00:29<23:00, 84.16it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2629/118828 [00:29<23:09, 83.61it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2638/118828 [00:29<24:00, 80.69it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2647/118828 [00:29<23:46, 81.44it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2656/118828 [00:30<23:15, 83.23it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2665/118828 [00:30<24:06, 80.29it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2675/118828 [00:30<23:06, 83.76it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2684/118828 [00:30<22:55, 84.46it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2693/118828 [00:30<23:41, 81.69it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2702/118828 [00:30<24:22, 79.39it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2712/118828 [00:30<23:15, 83.23it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2721/118828 [00:30<23:20, 82.92it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2730/118828 [00:30<24:03, 80.43it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2739/118828 [00:31<23:25, 82.58it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2748/118828 [00:31<23:32, 82.16it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2757/118828 [00:31<23:21, 82.83it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2767/118828 [00:31<23:06, 83.68it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2777/118828 [00:31<22:20, 86.55it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2786/118828 [00:31<23:16, 83.09it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2796/118828 [00:31<22:26, 86.20it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2806/118828 [00:31<22:48, 84.78it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2815/118828 [00:31<22:55, 84.33it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2825/118828 [00:32<22:00, 87.86it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2834/118828 [00:32<23:06, 83.65it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2843/118828 [00:32<23:25, 82.51it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2852/118828 [00:32<23:12, 83.29it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2861/118828 [00:32<24:00, 80.53it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2870/118828 [00:32<24:18, 79.50it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2879/118828 [00:32<24:33, 78.71it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2889/118828 [00:32<23:13, 83.21it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2898/118828 [00:32<23:16, 83.00it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2907/118828 [00:33<23:07, 83.53it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2917/118828 [00:33<22:57, 84.18it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2926/118828 [00:33<22:49, 84.66it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2935/118828 [00:33<23:23, 82.59it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2944/118828 [00:33<23:23, 82.56it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2953/118828 [00:33<23:18, 82.84it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2962/118828 [00:33<24:38, 78.38it/s]\u001b[A\n",
      "Analizando pares:   2%|▍                  | 2970/118828 [00:33<25:16, 76.39it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 2978/118828 [00:33<25:49, 74.76it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 2987/118828 [00:34<24:53, 77.57it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 2995/118828 [00:34<25:03, 77.04it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3003/118828 [00:34<25:42, 75.08it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3011/118828 [00:34<26:29, 72.86it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3019/118828 [00:34<27:23, 70.47it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3028/118828 [00:34<26:40, 72.34it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3036/118828 [00:34<26:30, 72.81it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3046/118828 [00:34<24:45, 77.93it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3055/118828 [00:34<24:26, 78.93it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3063/118828 [00:35<25:28, 75.73it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3076/118828 [00:35<23:11, 83.18it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3085/118828 [00:35<23:44, 81.27it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3094/118828 [00:35<23:05, 83.55it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3103/118828 [00:35<23:49, 80.95it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3112/118828 [00:35<23:50, 80.90it/s]\u001b[A\n",
      "Analizando pares:   3%|▍                  | 3122/118828 [00:35<23:58, 80.45it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3133/118828 [00:35<22:20, 86.32it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3142/118828 [00:36<22:44, 84.76it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3151/118828 [00:36<24:17, 79.35it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3160/118828 [00:36<24:40, 78.12it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3168/118828 [00:36<26:09, 73.71it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3177/118828 [00:36<25:33, 75.42it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3185/118828 [00:36<29:23, 65.56it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3192/118828 [00:36<30:46, 62.61it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3199/118828 [00:36<31:15, 61.65it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3206/118828 [00:37<31:52, 60.45it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3213/118828 [00:37<33:10, 58.10it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3219/118828 [00:37<33:05, 58.21it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3226/118828 [00:37<32:05, 60.03it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3233/118828 [00:37<32:04, 60.06it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3240/118828 [00:37<31:01, 62.10it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3249/118828 [00:37<28:01, 68.74it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3256/118828 [00:37<28:39, 67.22it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3264/118828 [00:37<27:58, 68.85it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3273/118828 [00:38<26:17, 73.26it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3281/118828 [00:38<26:09, 73.62it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3289/118828 [00:38<27:15, 70.64it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3298/118828 [00:38<26:53, 71.59it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3307/118828 [00:38<25:24, 75.77it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3316/118828 [00:38<25:54, 74.32it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3324/118828 [00:38<25:31, 75.42it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3333/118828 [00:38<26:37, 72.29it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3343/118828 [00:38<24:42, 77.92it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3353/118828 [00:39<24:13, 79.47it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3362/118828 [00:39<25:12, 76.36it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3370/118828 [00:39<26:07, 73.65it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3379/118828 [00:39<26:04, 73.81it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3387/118828 [00:39<25:41, 74.87it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3395/118828 [00:39<25:56, 74.15it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3403/118828 [00:39<26:20, 73.01it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3411/118828 [00:39<26:05, 73.71it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3420/118828 [00:39<25:13, 76.25it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3428/118828 [00:40<25:01, 76.88it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3437/118828 [00:40<24:05, 79.82it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3446/118828 [00:40<25:15, 76.14it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3454/118828 [00:40<24:57, 77.06it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3462/118828 [00:40<24:54, 77.17it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3470/118828 [00:40<25:16, 76.07it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3478/118828 [00:40<26:23, 72.83it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3486/118828 [00:40<25:58, 74.02it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3495/118828 [00:40<24:48, 77.49it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3503/118828 [00:41<25:07, 76.48it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3511/118828 [00:41<25:11, 76.32it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3519/118828 [00:41<25:58, 74.01it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3527/118828 [00:41<26:31, 72.46it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3535/118828 [00:41<26:15, 73.17it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3543/118828 [00:41<25:57, 74.04it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3552/118828 [00:41<25:45, 74.57it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3560/118828 [00:41<25:27, 75.45it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3568/118828 [00:41<25:29, 75.38it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3576/118828 [00:42<25:45, 74.60it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3585/118828 [00:42<24:54, 77.09it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3594/118828 [00:42<26:38, 72.07it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3603/118828 [00:42<26:35, 72.21it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3612/118828 [00:42<25:28, 75.36it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3622/118828 [00:42<23:49, 80.61it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3631/118828 [00:42<24:18, 78.98it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3639/118828 [00:42<24:37, 77.98it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3648/118828 [00:42<23:59, 80.01it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3657/118828 [00:43<25:10, 76.23it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3665/118828 [00:43<25:17, 75.88it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3673/118828 [00:43<25:52, 74.16it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3681/118828 [00:43<25:29, 75.29it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3689/118828 [00:43<26:36, 72.14it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3699/118828 [00:43<25:37, 74.90it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3707/118828 [00:43<25:49, 74.29it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3715/118828 [00:43<26:37, 72.06it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3723/118828 [00:44<26:00, 73.78it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3734/118828 [00:44<24:34, 78.08it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3742/118828 [00:44<26:00, 73.76it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3750/118828 [00:44<26:11, 73.25it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3758/118828 [00:44<26:56, 71.17it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3766/118828 [00:44<27:48, 68.94it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3774/118828 [00:44<27:09, 70.61it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3784/118828 [00:44<25:04, 76.49it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3792/118828 [00:44<27:05, 70.76it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3802/118828 [00:45<25:57, 73.86it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3810/118828 [00:45<26:24, 72.57it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3818/118828 [00:45<26:44, 71.66it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3826/118828 [00:45<27:39, 69.29it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3835/118828 [00:45<27:11, 70.50it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3844/118828 [00:45<25:24, 75.44it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3852/118828 [00:45<25:45, 74.42it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3860/118828 [00:45<26:55, 71.15it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3868/118828 [00:46<28:00, 68.41it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3876/118828 [00:46<27:08, 70.59it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3884/118828 [00:46<26:25, 72.51it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3892/118828 [00:46<26:22, 72.62it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3900/118828 [00:46<25:51, 74.07it/s]\u001b[A\n",
      "Analizando pares:   3%|▌                  | 3908/118828 [00:46<25:54, 73.91it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3916/118828 [00:46<25:26, 75.29it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3924/118828 [00:46<26:32, 72.13it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3932/118828 [00:46<27:00, 70.88it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3940/118828 [00:47<26:26, 72.41it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3948/118828 [00:47<28:02, 68.28it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3957/118828 [00:47<26:27, 72.37it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3965/118828 [00:47<26:39, 71.82it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3973/118828 [00:47<27:02, 70.79it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3981/118828 [00:47<27:23, 69.89it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3989/118828 [00:47<26:25, 72.44it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 3997/118828 [00:47<27:29, 69.60it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4006/118828 [00:47<27:23, 69.87it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4014/118828 [00:48<26:56, 71.03it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4023/118828 [00:48<25:09, 76.06it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4031/118828 [00:48<25:07, 76.14it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4039/118828 [00:48<25:10, 76.01it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4047/118828 [00:48<26:02, 73.48it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4056/118828 [00:48<26:04, 73.34it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4064/118828 [00:48<27:11, 70.36it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4072/118828 [00:48<28:27, 67.21it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4080/118828 [00:48<27:33, 69.38it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4087/118828 [00:49<27:39, 69.16it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4094/118828 [00:49<28:27, 67.18it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4103/118828 [00:49<26:54, 71.05it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4111/118828 [00:49<26:17, 72.73it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4119/118828 [00:49<26:39, 71.73it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4127/118828 [00:49<27:50, 68.67it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4136/118828 [00:49<26:07, 73.18it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4144/118828 [00:49<27:18, 70.00it/s]\u001b[A\n",
      "Analizando pares:   3%|▋                  | 4152/118828 [00:49<26:32, 72.01it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4160/118828 [00:50<26:26, 72.28it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4168/118828 [00:50<25:49, 73.99it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4176/118828 [00:50<25:48, 74.06it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4185/118828 [00:50<25:22, 75.29it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4195/118828 [00:50<25:08, 76.01it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4204/118828 [00:50<24:05, 79.30it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4212/118828 [00:50<25:50, 73.90it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4220/118828 [00:50<26:51, 71.12it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4228/118828 [00:51<26:30, 72.07it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4236/118828 [00:51<26:31, 72.00it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4244/118828 [00:51<26:13, 72.83it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4252/118828 [00:51<26:55, 70.91it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4260/118828 [00:51<26:32, 71.96it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4268/118828 [00:51<26:05, 73.16it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4277/118828 [00:51<26:45, 71.35it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4286/118828 [00:51<26:09, 73.00it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4294/118828 [00:51<25:43, 74.20it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4302/118828 [00:52<25:27, 74.99it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4310/118828 [00:52<24:59, 76.39it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4318/118828 [00:52<25:22, 75.21it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4327/118828 [00:52<26:27, 72.12it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4336/118828 [00:52<25:57, 73.49it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4344/118828 [00:52<26:00, 73.35it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4352/118828 [00:52<25:32, 74.72it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4362/118828 [00:52<23:30, 81.15it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4371/118828 [00:52<23:37, 80.75it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4380/118828 [00:53<24:17, 78.51it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4390/118828 [00:53<22:46, 83.75it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4399/118828 [00:53<22:32, 84.60it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4408/118828 [00:53<23:17, 81.90it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4417/118828 [00:53<22:53, 83.32it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4426/118828 [00:53<22:40, 84.08it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4435/118828 [00:53<22:49, 83.52it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4444/118828 [00:53<22:45, 83.77it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4455/118828 [00:53<21:02, 90.60it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4465/118828 [00:54<21:36, 88.20it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4474/118828 [00:54<21:39, 87.97it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4483/118828 [00:54<21:53, 87.02it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4492/118828 [00:54<22:14, 85.66it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4501/118828 [00:54<21:55, 86.88it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4511/118828 [00:54<22:09, 85.99it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4522/118828 [00:54<21:32, 88.41it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4532/118828 [00:54<22:02, 86.44it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4542/118828 [00:54<21:40, 87.86it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4551/118828 [00:55<22:51, 83.32it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4560/118828 [00:55<22:23, 85.05it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4571/118828 [00:55<21:49, 87.26it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4581/118828 [00:55<21:30, 88.54it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4590/118828 [00:55<21:29, 88.60it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4599/118828 [00:55<21:47, 87.36it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4608/118828 [00:55<22:04, 86.24it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4617/118828 [00:55<22:38, 84.05it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4626/118828 [00:55<22:42, 83.79it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4635/118828 [00:56<23:21, 81.46it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4644/118828 [00:56<23:37, 80.57it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4653/118828 [00:56<22:53, 83.11it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4662/118828 [00:56<22:27, 84.73it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4671/118828 [00:56<22:14, 85.53it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4680/118828 [00:56<26:08, 72.77it/s]\u001b[A\n",
      "Analizando pares:   4%|▋                  | 4688/118828 [00:56<25:35, 74.33it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4696/118828 [00:56<25:25, 74.81it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4705/118828 [00:56<25:04, 75.88it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4713/118828 [00:57<25:54, 73.43it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4721/118828 [00:57<25:25, 74.78it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4730/118828 [00:57<24:31, 77.54it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4740/118828 [00:57<22:45, 83.54it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4750/118828 [00:57<23:05, 82.34it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4759/118828 [00:57<23:06, 82.29it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4768/118828 [00:57<23:17, 81.64it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4777/118828 [00:57<23:10, 82.00it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4786/118828 [00:57<23:32, 80.76it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4796/118828 [00:58<23:05, 82.32it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4805/118828 [00:58<23:18, 81.56it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4815/118828 [00:58<22:42, 83.65it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4825/118828 [00:58<22:07, 85.87it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4834/118828 [00:58<22:42, 83.69it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4846/118828 [00:58<20:58, 90.58it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4856/118828 [00:58<21:49, 87.04it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4865/118828 [00:58<22:13, 85.47it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4875/118828 [00:58<22:15, 85.34it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4884/118828 [00:59<22:36, 84.01it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4894/118828 [00:59<21:29, 88.34it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4903/118828 [00:59<22:28, 84.51it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4912/118828 [00:59<22:50, 83.13it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4922/118828 [00:59<21:38, 87.72it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4932/118828 [00:59<21:26, 88.52it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4942/118828 [00:59<21:03, 90.13it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4952/118828 [00:59<22:29, 84.39it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4962/118828 [00:59<21:53, 86.68it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4971/118828 [01:00<22:39, 83.73it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4980/118828 [01:00<22:23, 84.77it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4989/118828 [01:00<22:30, 84.30it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 4998/118828 [01:00<23:06, 82.11it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5008/118828 [01:00<22:16, 85.13it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5017/118828 [01:00<22:34, 84.02it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5026/118828 [01:00<22:12, 85.38it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5036/118828 [01:00<21:47, 87.00it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5045/118828 [01:00<22:46, 83.26it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5054/118828 [01:01<22:22, 84.75it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5063/118828 [01:01<22:58, 82.55it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5073/118828 [01:01<22:27, 84.43it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5082/118828 [01:01<22:56, 82.61it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5091/118828 [01:01<23:39, 80.13it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5101/118828 [01:01<22:58, 82.49it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5110/118828 [01:01<23:38, 80.16it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5120/118828 [01:01<22:14, 85.22it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5130/118828 [01:01<22:56, 82.62it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5139/118828 [01:02<22:24, 84.56it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5149/118828 [01:02<21:36, 87.67it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5158/118828 [01:02<21:44, 87.16it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5167/118828 [01:02<25:46, 73.48it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5175/118828 [01:02<25:19, 74.82it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5183/118828 [01:02<27:34, 68.71it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5191/118828 [01:02<29:36, 63.97it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5198/118828 [01:02<28:56, 65.42it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5205/118828 [01:03<28:45, 65.86it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5212/118828 [01:03<30:45, 61.55it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5220/118828 [01:03<28:49, 65.67it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5227/118828 [01:03<29:45, 63.63it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5234/118828 [01:03<29:26, 64.29it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5241/118828 [01:03<29:24, 64.36it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5249/118828 [01:03<28:44, 65.84it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5257/118828 [01:03<27:48, 68.06it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5265/118828 [01:03<26:56, 70.26it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5275/118828 [01:04<25:21, 74.63it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5285/118828 [01:04<23:37, 80.11it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5294/118828 [01:04<24:47, 76.34it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5303/118828 [01:04<23:45, 79.64it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5312/118828 [01:04<24:10, 78.27it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5320/118828 [01:04<24:19, 77.79it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5329/118828 [01:04<23:29, 80.53it/s]\u001b[A\n",
      "Analizando pares:   4%|▊                  | 5340/118828 [01:04<22:21, 84.61it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5349/118828 [01:04<22:28, 84.16it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5358/118828 [01:05<22:16, 84.89it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5367/118828 [01:05<22:32, 83.86it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5377/118828 [01:05<21:42, 87.09it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5386/118828 [01:05<22:28, 84.13it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5395/118828 [01:05<22:35, 83.66it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5404/118828 [01:05<23:42, 79.74it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5415/118828 [01:05<22:34, 83.72it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5424/118828 [01:05<22:41, 83.28it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5434/118828 [01:05<22:31, 83.93it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5443/118828 [01:06<22:28, 84.07it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5452/118828 [01:06<22:07, 85.39it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5461/118828 [01:06<22:13, 84.99it/s]\u001b[A\n",
      "Analizando pares:   5%|▊                  | 5470/118828 [01:06<22:04, 85.59it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5479/118828 [01:06<22:13, 85.00it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5488/118828 [01:06<23:23, 80.75it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5497/118828 [01:06<23:23, 80.74it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5506/118828 [01:06<23:38, 79.88it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5516/118828 [01:06<22:16, 84.78it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5525/118828 [01:07<22:52, 82.54it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5534/118828 [01:07<22:40, 83.28it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5543/118828 [01:07<23:02, 81.92it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5553/118828 [01:07<23:01, 82.02it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5563/118828 [01:07<22:42, 83.12it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5572/118828 [01:07<22:30, 83.87it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5581/118828 [01:07<23:00, 82.06it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5590/118828 [01:07<24:30, 76.99it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5598/118828 [01:08<27:34, 68.45it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5607/118828 [01:08<25:40, 73.51it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5615/118828 [01:08<25:48, 73.13it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5625/118828 [01:08<23:34, 80.04it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5634/118828 [01:08<23:21, 80.74it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5643/118828 [01:08<23:28, 80.37it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5652/118828 [01:08<23:47, 79.29it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5660/118828 [01:08<23:48, 79.24it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5669/118828 [01:08<23:50, 79.10it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5677/118828 [01:09<24:07, 78.17it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5685/118828 [01:09<23:59, 78.58it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5695/118828 [01:09<22:25, 84.06it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5704/118828 [01:09<22:17, 84.58it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5713/118828 [01:09<22:11, 84.93it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5722/118828 [01:09<22:52, 82.39it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5731/118828 [01:09<23:19, 80.80it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5740/118828 [01:09<24:04, 78.30it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5748/118828 [01:09<25:02, 75.28it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5758/118828 [01:09<23:27, 80.32it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5767/118828 [01:10<23:38, 79.68it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5776/118828 [01:10<23:15, 81.02it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5785/118828 [01:10<23:07, 81.46it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5794/118828 [01:10<23:18, 80.82it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5803/118828 [01:10<23:36, 79.77it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5811/118828 [01:10<24:15, 77.65it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5819/118828 [01:10<24:16, 77.61it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5827/118828 [01:10<24:39, 76.39it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5835/118828 [01:10<24:38, 76.41it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5843/118828 [01:11<24:22, 77.24it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5851/118828 [01:11<24:17, 77.50it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5859/118828 [01:11<24:49, 75.84it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5867/118828 [01:11<25:55, 72.64it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5875/118828 [01:11<26:20, 71.46it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5884/118828 [01:11<25:11, 74.70it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5894/118828 [01:11<23:21, 80.58it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5903/118828 [01:11<23:28, 80.18it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5912/118828 [01:11<24:06, 78.06it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5922/118828 [01:12<23:40, 79.51it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5931/118828 [01:12<23:12, 81.09it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5940/118828 [01:12<23:42, 79.37it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5948/118828 [01:12<24:43, 76.09it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5957/118828 [01:12<23:42, 79.35it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5965/118828 [01:12<23:55, 78.65it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5973/118828 [01:12<24:06, 78.03it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5981/118828 [01:12<24:04, 78.13it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5989/118828 [01:13<26:34, 70.78it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 5997/118828 [01:13<27:31, 68.32it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6005/118828 [01:13<26:59, 69.68it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6014/118828 [01:13<25:19, 74.26it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6022/118828 [01:13<25:24, 73.99it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6030/118828 [01:13<25:41, 73.20it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6038/118828 [01:13<25:22, 74.07it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6046/118828 [01:13<25:57, 72.42it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6055/118828 [01:13<24:24, 77.02it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6063/118828 [01:13<24:15, 77.45it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6071/118828 [01:14<25:11, 74.59it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6079/118828 [01:14<26:59, 69.63it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6088/118828 [01:14<25:21, 74.09it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6096/118828 [01:14<24:54, 75.44it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6104/118828 [01:14<25:13, 74.49it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6112/118828 [01:14<25:21, 74.07it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6122/118828 [01:14<23:14, 80.81it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6131/118828 [01:14<23:42, 79.22it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6139/118828 [01:14<24:18, 77.26it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6148/118828 [01:15<23:39, 79.37it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6156/118828 [01:15<23:48, 78.86it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6164/118828 [01:15<23:47, 78.90it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6173/118828 [01:15<23:31, 79.82it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6184/118828 [01:15<21:37, 86.82it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6193/118828 [01:15<22:48, 82.29it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6202/118828 [01:15<22:21, 83.94it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6212/118828 [01:15<21:42, 86.45it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6221/118828 [01:15<21:56, 85.51it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6230/118828 [01:16<21:46, 86.19it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6239/118828 [01:16<22:58, 81.66it/s]\u001b[A\n",
      "Analizando pares:   5%|▉                  | 6248/118828 [01:16<23:00, 81.55it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6257/118828 [01:16<24:16, 77.28it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6266/118828 [01:16<23:54, 78.46it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6275/118828 [01:16<23:50, 78.66it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6284/118828 [01:16<23:21, 80.33it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6293/118828 [01:16<22:47, 82.27it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6302/118828 [01:16<22:36, 82.97it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6311/118828 [01:17<23:01, 81.43it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6321/118828 [01:17<22:40, 82.68it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6330/118828 [01:17<22:39, 82.74it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6339/118828 [01:17<22:18, 84.02it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6349/118828 [01:17<21:55, 85.48it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6359/118828 [01:17<21:06, 88.78it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6368/118828 [01:17<22:47, 82.26it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6377/118828 [01:17<23:22, 80.18it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6386/118828 [01:18<25:27, 73.63it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6394/118828 [01:18<27:06, 69.13it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6402/118828 [01:18<26:31, 70.64it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6410/118828 [01:18<26:56, 69.56it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6418/118828 [01:18<26:16, 71.32it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6427/118828 [01:18<24:56, 75.11it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6435/118828 [01:18<24:34, 76.24it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6443/118828 [01:18<24:14, 77.29it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6451/118828 [01:18<25:15, 74.15it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6459/118828 [01:19<24:57, 75.06it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6468/118828 [01:19<24:38, 75.97it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6477/118828 [01:19<23:26, 79.87it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6487/118828 [01:19<22:25, 83.48it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6496/118828 [01:19<23:51, 78.49it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6505/118828 [01:19<23:39, 79.13it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6515/118828 [01:19<22:23, 83.60it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6524/118828 [01:19<22:05, 84.71it/s]\u001b[A\n",
      "Analizando pares:   5%|█                  | 6533/118828 [01:19<21:58, 85.18it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6542/118828 [01:20<23:25, 79.91it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6551/118828 [01:20<26:34, 70.42it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6560/118828 [01:20<25:24, 73.66it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6569/118828 [01:20<25:05, 74.58it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6577/118828 [01:20<24:54, 75.10it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6588/118828 [01:20<22:42, 82.37it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6597/118828 [01:20<22:57, 81.48it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6606/118828 [01:20<23:27, 79.76it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6615/118828 [01:20<24:06, 77.59it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6624/118828 [01:21<25:00, 74.75it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6632/118828 [01:21<24:57, 74.94it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6640/118828 [01:21<25:08, 74.36it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6649/118828 [01:21<24:34, 76.10it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6660/118828 [01:21<23:29, 79.58it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6668/118828 [01:21<24:07, 77.50it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6676/118828 [01:21<24:28, 76.36it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6685/118828 [01:21<23:50, 78.40it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6694/118828 [01:22<23:50, 78.41it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6703/118828 [01:22<22:54, 81.57it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6712/118828 [01:22<22:39, 82.48it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6722/118828 [01:22<21:23, 87.37it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6731/118828 [01:22<23:50, 78.34it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6740/118828 [01:22<23:47, 78.51it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6748/118828 [01:22<23:56, 78.00it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6756/118828 [01:22<24:11, 77.22it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6765/118828 [01:22<23:17, 80.17it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6774/118828 [01:23<26:38, 70.11it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6782/118828 [01:23<27:19, 68.32it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6790/118828 [01:23<27:21, 68.24it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6798/118828 [01:23<26:46, 69.72it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6806/118828 [01:23<27:33, 67.75it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6813/118828 [01:23<28:33, 65.39it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6820/118828 [01:23<28:51, 64.68it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6827/118828 [01:23<28:49, 64.75it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6834/118828 [01:23<28:55, 64.55it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6841/118828 [01:24<29:55, 62.36it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6848/118828 [01:24<30:03, 62.10it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6855/118828 [01:24<29:36, 63.02it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6862/118828 [01:24<29:56, 62.33it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6870/118828 [01:24<28:26, 65.61it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6878/118828 [01:24<27:07, 68.78it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6887/118828 [01:24<25:40, 72.64it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6895/118828 [01:24<24:59, 74.65it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6904/118828 [01:24<24:04, 77.49it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6912/118828 [01:25<24:14, 76.97it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6921/118828 [01:25<23:46, 78.47it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6931/118828 [01:25<22:13, 83.89it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6940/118828 [01:25<23:01, 80.98it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6949/118828 [01:25<22:36, 82.50it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6958/118828 [01:25<22:38, 82.36it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6967/118828 [01:25<23:44, 78.53it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6977/118828 [01:25<22:59, 81.07it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6986/118828 [01:25<22:57, 81.18it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 6996/118828 [01:26<22:24, 83.20it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 7005/118828 [01:26<22:17, 83.59it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 7014/118828 [01:26<24:01, 77.58it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 7024/118828 [01:26<22:46, 81.81it/s]\u001b[A\n",
      "Analizando pares:   6%|█                  | 7034/118828 [01:26<22:47, 81.75it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7043/118828 [01:26<22:47, 81.73it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7052/118828 [01:26<22:15, 83.69it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7061/118828 [01:26<22:08, 84.15it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7070/118828 [01:27<23:08, 80.51it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7079/118828 [01:27<23:47, 78.28it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7089/118828 [01:27<22:28, 82.84it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7098/118828 [01:27<22:57, 81.14it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7107/118828 [01:27<23:46, 78.34it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7115/118828 [01:27<23:43, 78.47it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7123/118828 [01:27<24:09, 77.05it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7132/118828 [01:27<23:06, 80.57it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7141/118828 [01:27<25:45, 72.25it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7149/118828 [01:28<26:19, 70.72it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7157/118828 [01:28<25:33, 72.82it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7165/118828 [01:28<24:53, 74.74it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7173/118828 [01:28<25:23, 73.31it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7181/118828 [01:28<25:05, 74.16it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7190/118828 [01:28<24:19, 76.50it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7199/118828 [01:28<23:46, 78.24it/s]\u001b[A\n",
      "Analizando pares:   6%|█▏                 | 7207/118828 [01:28<23:47, 78.18it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el sistema completo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear instancia del sistema\n",
    "        system = BayesianPairsTrading(\n",
    "            start_date='2018-01-01',  # Ajustar según necesidad\n",
    "            end_date=None  # Hasta hoy\n",
    "        )\n",
    "        \n",
    "        # Ejecutar estrategia\n",
    "        success = system.run_backtest()\n",
    "        \n",
    "        if success:\n",
    "            print(\"Estrategia ejecutada con éxito. Resultados guardados en './artifacts/results/'\")\n",
    "        else:\n",
    "            print(\"Error al ejecutar estrategia. Consultar './artifacts/errors.txt'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en función principal: {str(e)}\")\n",
    "        logging.error(f\"Traceback: {sys.exc_info()[2]}\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Para ejecutar directamente en un notebook\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d8e518-b8fe-4ae3-836d-aedc62e9965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ S&P 500: 503 tickers cargados.\n",
      "❌ Error cargando NASDAQ 100: 'Ticker'\n",
      "❌ Error cargando Euro Stoxx 50: 'Ticker'\n",
      "❌ Error cargando DAX: 'Ticker symbol'\n",
      "❌ Error cargando CAC 40: 'Ticker'\n",
      "❌ Error cargando FTSE 100: 'EPIC'\n",
      "\n",
      "🔎 Validando hasta 2000 tickers de un total de 503...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                          | 6/503 [00:03<04:24,  1.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m     stock = yf.Ticker(ticker)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     info = \u001b[43mstock\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\n\u001b[32m     73\u001b[39m     sector = info.get(\u001b[33m\"\u001b[39m\u001b[33msector\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     74\u001b[39m     industry = info.get(\u001b[33m\"\u001b[39m\u001b[33mindustry\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/ticker.py:159\u001b[39m, in \u001b[36mTicker.info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/base.py:244\u001b[39m, in \u001b[36mTickerBase.get_info\u001b[39m\u001b[34m(self, proxy)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, proxy=\u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    243\u001b[39m     \u001b[38;5;28mself\u001b[39m._quote.proxy = proxy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proxy\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_quote\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/scrapers/quote.py:509\u001b[39m, in \u001b[36mQuote.info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    508\u001b[39m     \u001b[38;5;28mself\u001b[39m._fetch_info(\u001b[38;5;28mself\u001b[39m.proxy)\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_complementary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/scrapers/quote.py:705\u001b[39m, in \u001b[36mQuote._fetch_complementary\u001b[39m\u001b[34m(self, proxy)\u001b[39m\n\u001b[32m    702\u001b[39m end = \u001b[38;5;28mint\u001b[39m(end.timestamp())\n\u001b[32m    703\u001b[39m url += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m&period1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&period2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m json_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m.text\n\u001b[32m    706\u001b[39m json_data = json.loads(json_str)\n\u001b[32m    707\u001b[39m json_result = json_data.get(\u001b[33m\"\u001b[39m\u001b[33mtimeseries\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m json_data.get(\u001b[33m\"\u001b[39m\u001b[33mfinance\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/data.py:32\u001b[39m, in \u001b[36mlru_cache_freezeargs.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m args = \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mtuple\u001b[39m(arg) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[32m     31\u001b[39m kwargs = {k: \u001b[38;5;28mtuple\u001b[39m(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/data.py:418\u001b[39m, in \u001b[36mYfData.cache_get\u001b[39m\u001b[34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;129m@lru_cache_freezeargs\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize=cache_maxsize)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcache_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, user_agent_headers=\u001b[38;5;28;01mNone\u001b[39;00m, params=\u001b[38;5;28;01mNone\u001b[39;00m, proxy=\u001b[38;5;28;01mNone\u001b[39;00m, timeout=\u001b[32m30\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/utils.py:104\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/data.py:349\u001b[39m, in \u001b[36mYfData.get\u001b[39m\u001b[34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;129m@utils\u001b[39m.log_indent_decorator\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, user_agent_headers=\u001b[38;5;28;01mNone\u001b[39;00m, params=\u001b[38;5;28;01mNone\u001b[39;00m, proxy=\u001b[38;5;28;01mNone\u001b[39;00m, timeout=\u001b[32m30\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_method\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/utils.py:104\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/yfinance/data.py:394\u001b[39m, in \u001b[36mYfData._make_request\u001b[39m\u001b[34m(self, url, request_method, user_agent_headers, body, params, proxy, timeout)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m body:\n\u001b[32m    392\u001b[39m     request_args[\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m] = body\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m response = \u001b[43mrequest_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m utils.get_yf_logger().debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mresponse code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code >= \u001b[32m400\u001b[39m:\n\u001b[32m    397\u001b[39m     \u001b[38;5;66;03m# Retry with other cookie strategy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/incubator--n0FFLYq-py3.11/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:1378\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/ssl.py:1307\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1304\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1305\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1306\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/ssl.py:1163\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1165\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Diccionario de índices con URL, columna de ticker y sufijo, tabla correspondiente\n",
    "index_urls = {\n",
    "    \"S&P 500\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\",\n",
    "        \"symbol_col\": \"Symbol\",\n",
    "        \"suffix\": \"\",\n",
    "        \"table_index\": 0\n",
    "    },\n",
    "    \"NASDAQ 100\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/NASDAQ-100\",\n",
    "        \"symbol_col\": \"Ticker\",\n",
    "        \"suffix\": \"\",\n",
    "        \"table_index\": 3\n",
    "    },\n",
    "    \"Euro Stoxx 50\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/EURO_STOXX_50\",\n",
    "        \"symbol_col\": \"Ticker\",\n",
    "        \"suffix\": \"\",\n",
    "        \"table_index\": 1\n",
    "    },\n",
    "    \"DAX\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/DAX\",\n",
    "        \"symbol_col\": \"Ticker symbol\",\n",
    "        \"suffix\": \".DE\",\n",
    "        \"table_index\": 3\n",
    "    },\n",
    "    \"CAC 40\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/CAC_40\",\n",
    "        \"symbol_col\": \"Ticker\",\n",
    "        \"suffix\": \".PA\",\n",
    "        \"table_index\": 1\n",
    "    },\n",
    "    \"FTSE 100\": {\n",
    "        \"url\": \"https://en.wikipedia.org/wiki/FTSE_100_Index\",\n",
    "        \"symbol_col\": \"EPIC\",\n",
    "        \"suffix\": \".L\",\n",
    "        \"table_index\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "# 1. Obtener y limpiar todos los tickers de los índices\n",
    "all_candidates = []\n",
    "\n",
    "for name, info in index_urls.items():\n",
    "    try:\n",
    "        df = pd.read_html(info[\"url\"])[info[\"table_index\"]]\n",
    "        symbols = df[info[\"symbol_col\"]].astype(str)\n",
    "        cleaned = symbols.str.replace(r\"\\.\", \"-\", regex=True) + info[\"suffix\"]\n",
    "        all_candidates.extend(cleaned.tolist())\n",
    "        print(f\"✅ {name}: {len(cleaned)} tickers cargados.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error cargando {name}: {e}\")\n",
    "\n",
    "# 2. Limpiar duplicados\n",
    "unique_candidates = list(set(all_candidates))[:3000]\n",
    "\n",
    "# 3. Validar en yfinance\n",
    "valid_tickers = []\n",
    "sector_map = {}\n",
    "industry_map = {}\n",
    "\n",
    "print(f\"\\n🔎 Validando hasta 2000 tickers de un total de {len(unique_candidates)}...\")\n",
    "\n",
    "for ticker in tqdm(unique_candidates):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        sector = info.get(\"sector\", None)\n",
    "        industry = info.get(\"industry\", None)\n",
    "        if sector:\n",
    "            valid_tickers.append(ticker)\n",
    "            sector_map[ticker] = sector\n",
    "            industry_map[ticker] = industry\n",
    "        if len(valid_tickers) >= 2000:\n",
    "            break\n",
    "    except Exception:\n",
    "        continue\n",
    "    time.sleep(0.2)\n",
    "\n",
    "# 4. Guardar resultados\n",
    "df = pd.DataFrame({\n",
    "    \"Ticker\": valid_tickers,\n",
    "    \"Sector\": [sector_map[t] for t in valid_tickers],\n",
    "    \"Industry\": [industry_map[t] for t in valid_tickers]\n",
    "})\n",
    "df.to_csv(\"tickers_globales_yf.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ ¡Listo! Se guardaron {len(valid_tickers)} tickers en 'tickers_globales_yf.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec07f2-9f80-4cad-bca1-8b9dcebd29fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
